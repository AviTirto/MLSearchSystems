1
00:00:00,000 --> 00:00:02,320
Rapping up one of
the major resources

2
00:00:02,320 --> 00:00:04,200
of the semester,
which is networking.

3
00:00:04,200 --> 00:00:05,500
After that, we're going to spend

4
00:00:05,500 --> 00:00:08,340
about three lectures
on memory resources,

5
00:00:08,340 --> 00:00:11,420
and then we're going to
do computed storage.

6
00:00:11,420 --> 00:00:13,280
And so I just have a
few things to wrap

7
00:00:13,280 --> 00:00:16,080
up from last time just
a few slides there.

8
00:00:16,080 --> 00:00:17,879
And then we're able to
spend most of the time

9
00:00:17,879 --> 00:00:20,539
today talking about
how we can use memory,

10
00:00:20,539 --> 00:00:24,010
and in particular, how
we can create caches.

11
00:00:24,010 --> 00:00:26,199
So I'm going to head over

12
00:00:26,199 --> 00:00:28,239
here to where we were last time.

13
00:00:28,239 --> 00:00:30,900
So last time we learned
about how we could

14
00:00:30,900 --> 00:00:33,639
spit up these Doctor
compose clusters.

15
00:00:33,639 --> 00:00:35,280
And you can imagine
doing something similar,

16
00:00:35,280 --> 00:00:36,019
where instead of having

17
00:00:36,019 --> 00:00:37,620
all the containers
on the same machine,

18
00:00:37,620 --> 00:00:39,379
you have them on
different machines.

19
00:00:39,379 --> 00:00:40,599
And once you start to do that,

20
00:00:40,599 --> 00:00:41,759
where you have
different pieces of

21
00:00:41,759 --> 00:00:43,679
your application running
a different machines,

22
00:00:43,679 --> 00:00:45,219
and you have a large data set

23
00:00:45,219 --> 00:00:46,840
that doesn't fit on
a single machine,

24
00:00:46,840 --> 00:00:49,219
you have to think, how can
I break up my dataset?

25
00:00:49,219 --> 00:00:51,459
How can I make sure that
I don't lose pieces of

26
00:00:51,459 --> 00:00:53,760
my data set even if
some machines die?

27
00:00:53,760 --> 00:00:56,260
And that leads us to
partitioning and replication.

28
00:00:56,260 --> 00:00:58,020
So I'm imagining this large data

29
00:00:58,020 --> 00:00:59,359
set with a lot of machines,

30
00:00:59,359 --> 00:01:03,640
and I'm realizing I need to
be on HDMI. Okay, great.

31
00:01:03,640 --> 00:01:05,960
And so when we break it up,

32
00:01:05,960 --> 00:01:07,480
that's called
partitioning, right?

33
00:01:07,480 --> 00:01:09,520
And when we have
multiple copies of

34
00:01:09,520 --> 00:01:10,900
the same piece for

35
00:01:10,900 --> 00:01:12,740
reliability, that's
called replication.

36
00:01:12,740 --> 00:01:14,760
Often, you might
use partitioning or

37
00:01:14,760 --> 00:01:17,740
replication or very often,
both in combination.

38
00:01:17,740 --> 00:01:20,780
These are ideas that we we
see repeatedly this semester.

39
00:01:20,780 --> 00:01:23,060
I just want to have a light
introduction early on,

40
00:01:23,060 --> 00:01:24,220
because it makes sense after

41
00:01:24,220 --> 00:01:27,540
the networking content that
we would take a look at that.

42
00:01:27,540 --> 00:01:29,619
So, let's imagine that I'm

43
00:01:29,619 --> 00:01:31,880
building an application
to help instructors.

44
00:01:31,880 --> 00:01:33,819
I love applications
like that, by the way.

45
00:01:33,819 --> 00:01:35,379
And this application is going to

46
00:01:35,379 --> 00:01:37,139
let you search for
a student's name,

47
00:01:37,139 --> 00:01:39,820
and it will tell you
their student ID.

48
00:01:39,820 --> 00:01:42,560
Very simple, right? And let's

49
00:01:42,560 --> 00:01:45,179
imagine that the dataset is
huge for whatever reason.

50
00:01:45,179 --> 00:01:47,699
And it's so big that we cannot

51
00:01:47,699 --> 00:01:50,559
store it and serve it
up on a single machine.

52
00:01:50,559 --> 00:01:51,759
So let's say we
have two machines.

53
00:01:51,759 --> 00:01:54,179
It's really kind of like the
simplest possible cluster,

54
00:01:54,179 --> 00:01:56,880
of course, you can imagine
something analogous to this.

55
00:01:56,880 --> 00:01:58,879
Maybe it's like Facebook IDs,

56
00:01:58,879 --> 00:02:01,479
and you have like 1,000
machines. Who knows, right?

57
00:02:01,479 --> 00:02:03,800
But here we're look
at a simple scenario.

58
00:02:03,800 --> 00:02:05,179
And so with the data set,

59
00:02:05,179 --> 00:02:07,420
I want to find different ways
that we could split it up.

60
00:02:07,420 --> 00:02:09,980
O is that we could just
try to cut it 50 50,

61
00:02:09,980 --> 00:02:11,460
first half on the first machine,

62
00:02:11,460 --> 00:02:12,979
second half on the
second machine,

63
00:02:12,979 --> 00:02:14,320
that that balances the data

64
00:02:14,320 --> 00:02:16,039
nicely across different places.

65
00:02:16,039 --> 00:02:18,039
But the disadvantages is that

66
00:02:18,039 --> 00:02:20,519
when I am using an
application built on this,

67
00:02:20,519 --> 00:02:22,040
I'm ready to put it a name,

68
00:02:22,040 --> 00:02:24,560
and we have to figure
out which machine

69
00:02:24,560 --> 00:02:26,774
or multiple machines
do we have to check?

70
00:02:26,774 --> 00:02:28,269
To find the student ID.

71
00:02:28,269 --> 00:02:29,669
And if we don't know anything

72
00:02:29,669 --> 00:02:32,189
about kind of the range
of values in here,

73
00:02:32,189 --> 00:02:33,629
what will happen is that
we actually have to

74
00:02:33,629 --> 00:02:35,649
send the request
to both machines,

75
00:02:35,649 --> 00:02:38,109
you know, let's say,
like it's R of.

76
00:02:38,109 --> 00:02:40,029
We can ask the first
machine, do you have R of?

77
00:02:40,029 --> 00:02:41,589
Second machine do you have RF,

78
00:02:41,589 --> 00:02:43,150
and then combine the answers.

79
00:02:43,150 --> 00:02:44,670
That's not efficient.

80
00:02:44,670 --> 00:02:45,910
Kind of defeats the purpose

81
00:02:45,910 --> 00:02:48,309
of partitioning this
in the first place.

82
00:02:48,309 --> 00:02:50,229
Some cases is okay,

83
00:02:50,229 --> 00:02:51,769
but many use cases, it's not.

84
00:02:51,769 --> 00:02:53,209
The other thing you could do is

85
00:02:53,209 --> 00:02:54,350
you could do range partitioning.

86
00:02:54,350 --> 00:02:57,749
Maybe we look at these
names alphabetically,

87
00:02:57,749 --> 00:03:00,170
and maybe there's 26
letters of the alphabet.

88
00:03:00,170 --> 00:03:04,410
So let's say A to grows on
the first machine and n to z,

89
00:03:04,410 --> 00:03:07,490
the last 13 letters grows
on the second machine.

90
00:03:07,490 --> 00:03:10,009
There's advantages and
disadvantages of that.

91
00:03:10,009 --> 00:03:11,249
The good thing about it is

92
00:03:11,249 --> 00:03:13,490
that if I have somebody's name,

93
00:03:13,490 --> 00:03:15,444
I could immediately figure out

94
00:03:15,444 --> 00:03:18,419
what machine there
has that range.

95
00:03:18,419 --> 00:03:20,620
I can figure out which one
machine I should talk to.

96
00:03:20,620 --> 00:03:21,860
You can see that sometimes

97
00:03:21,860 --> 00:03:23,280
it tends to lead to end ballots.

98
00:03:23,280 --> 00:03:25,359
In this case, just
maybe coincidentally,

99
00:03:25,359 --> 00:03:26,059
or I don't know if there's

100
00:03:26,059 --> 00:03:27,319
something more
interesting about it,

101
00:03:27,319 --> 00:03:29,479
but most of the names
ended up on that on

102
00:03:29,479 --> 00:03:32,720
that first cluster rather
than the second cluster.

103
00:03:32,840 --> 00:03:36,139
So that's not great. You can

104
00:03:36,139 --> 00:03:38,540
imagine trying to more
carefully find a split,

105
00:03:38,540 --> 00:03:40,919
maybe I look at a histogram
or something like that.

106
00:03:40,919 --> 00:03:42,460
That might work well initially.

107
00:03:42,460 --> 00:03:44,880
If there's totally new
students getting added,

108
00:03:44,880 --> 00:03:46,879
maybe the distribution
changes, right?

109
00:03:46,879 --> 00:03:49,080
So it's just kind of tricky
to keep that ballots.

110
00:03:49,080 --> 00:03:51,734
So there's good things about
it and bad things about it.

111
00:03:51,734 --> 00:03:54,869
A third thing that we could
do is hash partitioning.

112
00:03:54,869 --> 00:03:56,589
You're actually do
some hash partitioning

113
00:03:56,589 --> 00:03:59,509
on the project that's going
to be coming out shortly.

114
00:03:59,509 --> 00:04:03,129
And hash partitioning
depends on a hash function.

115
00:04:03,129 --> 00:04:04,009
Some of you might have seen

116
00:04:04,009 --> 00:04:05,269
hash flexions if
you're coming from

117
00:04:05,269 --> 00:04:07,750
the CS track, 200300400.

118
00:04:07,750 --> 00:04:09,870
For those of you from 22320,

119
00:04:09,870 --> 00:04:12,169
maybe you haven't seen
hash functions before.

120
00:04:12,169 --> 00:04:14,550
But the idea of a hash
function is pretty simple.

121
00:04:14,550 --> 00:04:17,130
It's a function that
can take any value,

122
00:04:17,130 --> 00:04:19,850
string dictionary,
whatever, doesn't matter.

123
00:04:19,850 --> 00:04:21,590
It can take anything, and

124
00:04:21,590 --> 00:04:23,970
it returns back a number to you.

125
00:04:23,970 --> 00:04:26,009
Okay? And then there's

126
00:04:26,009 --> 00:04:27,369
some other properties
that they usually

127
00:04:27,369 --> 00:04:29,449
have that are kind of nice.

128
00:04:29,449 --> 00:04:31,929
What, well, this
is a requirement.

129
00:04:31,929 --> 00:04:34,130
If I feed the same value
in more than one time,

130
00:04:34,130 --> 00:04:35,610
it has to be deterministic.

131
00:04:35,610 --> 00:04:38,270
The same value in gives
me the same number back.

132
00:04:38,270 --> 00:04:41,820
Okay? The other thing is that it

133
00:04:41,820 --> 00:04:42,880
should be kind of a

134
00:04:42,880 --> 00:04:45,399
seemingly almost like
arbitrary pattern.

135
00:04:45,399 --> 00:04:46,680
So if I put in A,

136
00:04:46,680 --> 00:04:47,999
I'm going to get some number.

137
00:04:47,999 --> 00:04:49,960
And then if I put in
B, it should just be

138
00:04:49,960 --> 00:04:52,039
a completely different number

139
00:04:52,039 --> 00:04:54,540
if they're doing a good job
with the hash function.

140
00:04:54,540 --> 00:04:55,839
Okay, so how are we going to use

141
00:04:55,839 --> 00:04:57,300
hash flexions for partitioning?

142
00:04:57,300 --> 00:05:00,099
Well, here I have my
name and my student ID,

143
00:05:00,099 --> 00:05:01,700
and I will choose
one of these to be

144
00:05:01,700 --> 00:05:03,699
what I call my partitioning key.

145
00:05:03,699 --> 00:05:05,739
And I may say the name
is the partitioning key,

146
00:05:05,739 --> 00:05:08,260
and I may compute
the hash over that.

147
00:05:08,260 --> 00:05:10,155
And I'm going basically get

148
00:05:10,155 --> 00:05:13,130
Numbers corresponding
to each person's name.

149
00:05:13,130 --> 00:05:16,930
And then what I could do is
I could put all the eV ones,

150
00:05:16,930 --> 00:05:18,630
let's say, computer one and

151
00:05:18,630 --> 00:05:20,390
all the odd ones
on Computer two.

152
00:05:20,390 --> 00:05:22,489
That's not perfectly balanced,

153
00:05:22,489 --> 00:05:24,469
but it'll tend to be a
little bit more balanced

154
00:05:24,469 --> 00:05:26,210
than the case I saw

155
00:05:26,210 --> 00:05:29,290
earlier where I was trying
to do the ranges, right?

156
00:05:29,290 --> 00:05:31,429
Because there's not like weird

157
00:05:31,429 --> 00:05:32,969
patterns in terms of, you know,

158
00:05:32,969 --> 00:05:34,429
a lot of people's names use

159
00:05:34,429 --> 00:05:36,510
letters from the first
half of the alphabet.

160
00:05:36,510 --> 00:05:38,510
Right? So that's the common
thing people will do.

161
00:05:38,510 --> 00:05:40,010
If I have somebody's name, then

162
00:05:40,010 --> 00:05:41,309
which machine do I talk to,

163
00:05:41,309 --> 00:05:42,870
well, I'll take the
hash of their name.

164
00:05:42,870 --> 00:05:45,254
And I'll see is that
number even or odd?

165
00:05:45,254 --> 00:05:48,299
And I'll talk to that
appro appropriate machine.

166
00:05:48,299 --> 00:05:50,079
If I wanted to get
everybody's name like

167
00:05:50,079 --> 00:05:52,020
at a given range of values,
so this wouldn't work.

168
00:05:52,020 --> 00:05:53,800
That I have to go back to
the range partitioning.

169
00:05:53,800 --> 00:05:55,360
But this works for you,

170
00:05:55,360 --> 00:05:56,639
a large variety of cases

171
00:05:56,639 --> 00:05:58,140
if what you're going
to do on the project.

172
00:05:58,140 --> 00:06:00,400
So the project we're going
to be releasing soon,

173
00:06:00,400 --> 00:06:01,900
what you'll do is
you'll actually have

174
00:06:01,900 --> 00:06:04,600
two datasets for the two
different partitions.

175
00:06:04,600 --> 00:06:06,260
And you're going to
start a simple doctor

176
00:06:06,260 --> 00:06:07,439
composed cluster where you have

177
00:06:07,439 --> 00:06:09,640
two containers and
each container

178
00:06:09,640 --> 00:06:11,885
is going to be responsible
for one of these datasets.

179
00:06:11,885 --> 00:06:13,410
And then inside of
the containers you

180
00:06:13,410 --> 00:06:15,070
have these two little
servers running, each,

181
00:06:15,070 --> 00:06:17,010
which is serving up
one of these datasets,

182
00:06:17,010 --> 00:06:19,050
and clients can ask
questions about it.

183
00:06:19,050 --> 00:06:21,610
And so some of the work will
just be kind of like getting

184
00:06:21,610 --> 00:06:24,130
these two GRP servers up and

185
00:06:24,130 --> 00:06:27,030
running and having the beat
responsible short some data.

186
00:06:27,030 --> 00:06:28,570
And then in your client,

187
00:06:28,570 --> 00:06:30,210
you have to say what I'm
calling a method and

188
00:06:30,210 --> 00:06:31,870
my colleague that server
water server too.

189
00:06:31,870 --> 00:06:33,150
The client will have
to do a little bit

190
00:06:33,150 --> 00:06:34,230
of work beforehand to figure

191
00:06:34,230 --> 00:06:37,309
out where we should w
looking for the data.

192
00:06:37,309 --> 00:06:39,509
Alright. So just a little
bit of vocabulary here.

193
00:06:39,509 --> 00:06:41,409
So partition is this
general concept

194
00:06:41,409 --> 00:06:42,830
that the T Bible use.

195
00:06:42,830 --> 00:06:44,370
There's a lot of
analogies for it,

196
00:06:44,370 --> 00:06:45,810
maybe used in different domains.

197
00:06:45,810 --> 00:06:48,909
So this data Itsive
applications book,

198
00:06:48,909 --> 00:06:50,590
which is excellent, by the way.

199
00:06:50,590 --> 00:06:51,950
They list a bunch
of them, right?

200
00:06:51,950 --> 00:06:53,650
Sometimes it's called a hard or

201
00:06:53,650 --> 00:06:56,749
a region or a tablet or vetoed.

202
00:06:56,749 --> 00:07:00,270
Whatever, you know, we
will learn the concept and

203
00:07:00,270 --> 00:07:03,690
adapt whatever vocabulary
different systems use.

204
00:07:03,690 --> 00:07:07,110
But I want you to see the
general concept up front.

205
00:07:07,630 --> 00:07:11,269
Have people have any
questions about partitioning.

206
00:07:15,710 --> 00:07:24,910
Right here. Yeah, Uh huh.

207
00:07:25,550 --> 00:07:28,709
Yeah. So if we wanted to subs
go from an ID to a name,

208
00:07:28,709 --> 00:07:30,509
sometimes from a name to an ID.

209
00:07:30,509 --> 00:07:33,190
Yeah, I think what we

210
00:07:33,190 --> 00:07:34,950
would often do is we might

211
00:07:34,950 --> 00:07:37,410
have like two copies of
the same data, right?

212
00:07:37,410 --> 00:07:39,270
Would be one way to do it.

213
00:07:39,270 --> 00:07:43,170
Or Another thing
you could do is you

214
00:07:43,170 --> 00:07:45,630
could have what we

215
00:07:45,630 --> 00:07:48,950
might call an index in this
case is just two columns,

216
00:07:48,950 --> 00:07:51,450
but me usually there
might be a long row.

217
00:07:51,450 --> 00:07:54,010
And so we could have the
rows started someway,

218
00:07:54,010 --> 00:07:57,090
and there could be
an ID for each row.

219
00:07:57,090 --> 00:07:58,329
And in different places,

220
00:07:58,329 --> 00:08:00,509
we could have different
lookup techniques,

221
00:08:00,509 --> 00:08:02,870
maybe I'll look up from
this column or that column.

222
00:08:02,870 --> 00:08:05,569
But anytime I want to support
more types of lookups,

223
00:08:05,569 --> 00:08:07,889
I have to use a little
bit extra information.

224
00:08:07,889 --> 00:08:09,809
That makes sense. Yeah,
it's an excellent question.

225
00:08:09,809 --> 00:08:11,090
It's the right way to
be thinking about this.

226
00:08:11,090 --> 00:08:12,870
We're going to see more
examples like that.

227
00:08:12,870 --> 00:08:18,339
Yeah, other questions
people have. All right.

228
00:08:18,339 --> 00:08:20,359
Let's talk about replication.

229
00:08:20,359 --> 00:08:21,960
This actually, I just pulled

230
00:08:21,960 --> 00:08:23,100
it off of a slide
that we're going

231
00:08:23,100 --> 00:08:24,380
to revisit later
this semester when

232
00:08:24,380 --> 00:08:26,119
we learned about the
udu file system.

233
00:08:26,119 --> 00:08:27,419
Don't worry about what the Hadu

234
00:08:27,419 --> 00:08:29,100
file system is for right now.

235
00:08:29,100 --> 00:08:30,560
What we're just going
to worry about is

236
00:08:30,560 --> 00:08:31,920
that it has files,

237
00:08:31,920 --> 00:08:34,820
and those files are both
partitioned like we saw,

238
00:08:34,820 --> 00:08:36,499
and they're also
replicated, right?

239
00:08:36,499 --> 00:08:38,839
There's going to be multiple
copies of the data.

240
00:08:38,839 --> 00:08:40,840
So here I have two files.

241
00:08:40,840 --> 00:08:43,544
File F one contains ABCD.

242
00:08:43,544 --> 00:08:45,510
And File two is a
little bit longer.

243
00:08:45,510 --> 00:08:47,890
It's EFGH IJ KL.

244
00:08:47,890 --> 00:08:49,709
And I may imagine that

245
00:08:49,709 --> 00:08:51,429
a partition is just
four characters.

246
00:08:51,429 --> 00:08:53,009
It's absurdly short, but just

247
00:08:53,009 --> 00:08:55,329
for the sake of the demo,
let's say that it is.

248
00:08:55,329 --> 00:08:58,329
And so the File one
has one partition.

249
00:08:58,329 --> 00:09:00,209
I may call that F 1.1,

250
00:09:00,209 --> 00:09:02,070
and File two has two partitions,

251
00:09:02,070 --> 00:09:04,474
F 1.1 and F 1.2.

252
00:09:04,474 --> 00:09:06,320
And for different files,

253
00:09:06,320 --> 00:09:07,920
I might have different
replication factors.

254
00:09:07,920 --> 00:09:09,480
If I'm more worried
about losing my data,

255
00:09:09,480 --> 00:09:10,919
I would have more replication,

256
00:09:10,919 --> 00:09:12,200
and I want to more machines.

257
00:09:12,200 --> 00:09:14,560
Let say this first file
has triple replication,

258
00:09:14,560 --> 00:09:16,899
and the second one has
two times replication.

259
00:09:16,899 --> 00:09:18,880
So the ABCD, I

260
00:09:18,880 --> 00:09:20,880
guess there's three machines
as a triple replication,

261
00:09:20,880 --> 00:09:22,579
kind of has to be
on all of them.

262
00:09:22,579 --> 00:09:25,559
And then what about F 2.1?

263
00:09:25,559 --> 00:09:27,419
Let's say that's on the
first two machines,

264
00:09:27,419 --> 00:09:31,300
F 2.2, t's say it's on the
the second two machines.

265
00:09:31,300 --> 00:09:33,659
Right? So AC systems
that do replication,

266
00:09:33,659 --> 00:09:35,640
Some AC systems that
do partitioning,

267
00:09:35,640 --> 00:09:37,859
often, you'll see the vies
in combination like this.

268
00:09:37,859 --> 00:09:45,639
Yeah, question right. Yeah,
that's an excellent question.

269
00:09:45,639 --> 00:09:47,239
How do I figure out
which machines get,

270
00:09:47,239 --> 00:09:48,200
which parts of the file?

271
00:09:48,200 --> 00:09:50,899
It's something we'll talk
about extensively, right?

272
00:09:50,899 --> 00:09:53,079
You can imagine lots of
different scenarios.

273
00:09:53,079 --> 00:09:55,159
I'll just quick throw out

274
00:09:55,159 --> 00:09:57,959
a few things you
might factor in.

275
00:09:57,959 --> 00:09:59,499
What I might factor in that?

276
00:09:59,499 --> 00:10:01,460
Some of these machines
might be in the same brac,

277
00:10:01,460 --> 00:10:02,720
and so I don't want to have

278
00:10:02,720 --> 00:10:05,005
all my replicas
of the same rack.

279
00:10:05,005 --> 00:10:07,210
I want the machines

280
00:10:07,210 --> 00:10:08,969
to kind of have even
amounts of data, right?

281
00:10:08,969 --> 00:10:12,189
So I don't run out of hard
drive space on one of them.

282
00:10:12,189 --> 00:10:14,350
Even if they all have
the same amount of data,

283
00:10:14,350 --> 00:10:16,350
some data might be more
popular than others.

284
00:10:16,350 --> 00:10:18,290
So I don't want some
specific machine

285
00:10:18,290 --> 00:10:19,729
to get overloaded with requests.

286
00:10:19,729 --> 00:10:20,769
So you can start thinking about

287
00:10:20,769 --> 00:10:22,009
all those things and
try to figure out

288
00:10:22,009 --> 00:10:24,689
how to lay it out, right?

289
00:10:24,689 --> 00:10:27,030
You know, you can You
know, it's a deep area.

290
00:10:27,030 --> 00:10:29,129
How do we figure out where
to put these replicas?

291
00:10:29,129 --> 00:10:32,190
Is a big problem, right?
What will revisit?

292
00:10:32,190 --> 00:10:34,429
Yeah, other questions
people have.

293
00:10:35,150 --> 00:10:40,110
Alright. Cool. Great. We're
done with networking.

294
00:10:40,110 --> 00:10:42,934
We're going to move into
our new topic, which is

295
00:10:42,934 --> 00:10:46,700
Memory resources, with
memory resources,

296
00:10:46,700 --> 00:10:48,700
you look at this
idea of caching.

297
00:10:48,700 --> 00:10:53,059
You know, this course is
specifically about big datasets,

298
00:10:53,059 --> 00:10:55,100
and memory tends to be kind

299
00:10:55,100 --> 00:10:57,340
of small compared to like
an SSD or hard drive.

300
00:10:57,340 --> 00:10:59,580
So often, for a lot of
these big data sets,

301
00:10:59,580 --> 00:11:01,479
it will not fit in Rab, right?

302
00:11:01,479 --> 00:11:03,460
Our dataset will
be disc somewhere.

303
00:11:03,460 --> 00:11:05,199
And so the question is,

304
00:11:05,199 --> 00:11:06,779
well, how do we use Rab?

305
00:11:06,779 --> 00:11:08,600
The answer is that
maybe certain subsets

306
00:11:08,600 --> 00:11:10,200
of our data is
access more often.

307
00:11:10,200 --> 00:11:11,560
We can't put everything in ab,

308
00:11:11,560 --> 00:11:13,700
but let's choose
something to put there,

309
00:11:13,700 --> 00:11:16,099
and let's make that
decision carefully, right?

310
00:11:16,099 --> 00:11:17,440
That's the question of caching.

311
00:11:17,440 --> 00:11:19,339
When can we put a
copy of our data?

312
00:11:19,339 --> 00:11:20,639
Is something that's faster and

313
00:11:20,639 --> 00:11:22,850
smaller because we
can't always do that,

314
00:11:22,850 --> 00:11:25,049
so we kind of have to be a
little bit smart about it.

315
00:11:25,049 --> 00:11:28,210
Alright. So there's a few things

316
00:11:28,210 --> 00:11:29,470
I want you to be
able to describe

317
00:11:29,470 --> 00:11:30,790
at the end of this lecture.

318
00:11:30,790 --> 00:11:32,049
The first is you
have to be able to

319
00:11:32,049 --> 00:11:33,450
describe about cash hierarchy.

320
00:11:33,450 --> 00:11:34,710
We try to talking
about it like, Oh,

321
00:11:34,710 --> 00:11:36,090
there's like Rab
and there's SST.

322
00:11:36,090 --> 00:11:38,010
There's actually many
different levels of cash

323
00:11:38,010 --> 00:11:40,930
growing from small and
fast, a big and slow.

324
00:11:40,930 --> 00:11:42,509
And we could have a kind of

325
00:11:42,509 --> 00:11:44,570
cash between any two
of these layers.

326
00:11:44,570 --> 00:11:45,789
And here you have to kind of

327
00:11:45,789 --> 00:11:47,249
talk about how that looks like

328
00:11:47,249 --> 00:11:50,734
in actual real hardware and
in a realistic scenario.

329
00:11:50,734 --> 00:11:52,820
Second, one of the
things I want you to be

330
00:11:52,820 --> 00:11:54,600
able to do is trace
through access pattern.

331
00:11:54,600 --> 00:11:56,720
So if I'm running a program

332
00:11:56,720 --> 00:11:59,520
and that program is like
reading different files,

333
00:11:59,520 --> 00:12:00,859
I can write down, like, Oh,

334
00:12:00,859 --> 00:12:02,479
read file one, then
read file two,

335
00:12:02,479 --> 00:12:03,680
then read file one again.

336
00:12:03,680 --> 00:12:05,120
That's an access pattern.

337
00:12:05,120 --> 00:12:07,499
And for an access pattern,

338
00:12:07,499 --> 00:12:09,299
there might be some
cashing going on.

339
00:12:09,299 --> 00:12:12,319
That caching might be driven
by a policy automatically.

340
00:12:12,319 --> 00:12:13,599
There's a couple of
policies that will

341
00:12:13,599 --> 00:12:15,320
led like LR U and FIFO.

342
00:12:15,320 --> 00:12:16,759
What I want you to
do is I want you to,

343
00:12:16,759 --> 00:12:17,920
like, look at an access pattern.

344
00:12:17,920 --> 00:12:19,039
Like this is what a program is

345
00:12:19,039 --> 00:12:21,519
doing and say, here's the cache,

346
00:12:21,519 --> 00:12:23,339
and kind of how we're
managing the cache,

347
00:12:23,339 --> 00:12:26,264
and then kind of trace
through step by step and say,

348
00:12:26,264 --> 00:12:28,269
We found this value
in the cache.

349
00:12:28,269 --> 00:12:30,130
We did it by this
value in the cache.

350
00:12:30,130 --> 00:12:31,930
Overall, this was the
total performance.

351
00:12:31,930 --> 00:12:33,109
Is this something
I would want to be

352
00:12:33,109 --> 00:12:34,630
able to do on pencil
and paper and actually,

353
00:12:34,630 --> 00:12:36,150
that's why I have
the worksheet today.

354
00:12:36,150 --> 00:12:38,470
And calculating the cash
performance metrics

355
00:12:38,470 --> 00:12:41,609
just naturally follows
that tracing aspect.

356
00:12:41,609 --> 00:12:44,929
Okay, so what is the problem
we're trying to solve here?

357
00:12:44,929 --> 00:12:47,489
The problem is at
at C. L at at C is

358
00:12:47,489 --> 00:12:50,190
any amount of time that
you wait for slipping.

359
00:12:50,190 --> 00:12:52,390
And so if we want to
understand ate at C and how

360
00:12:52,390 --> 00:12:54,730
it often shows up in
programs that are ready,

361
00:12:54,730 --> 00:12:56,930
we have to understand a
little bit about hardware.

362
00:12:56,930 --> 00:12:59,080
So I have a simple picture here.

363
00:12:59,080 --> 00:13:02,370
Over here, I have a CPU.

364
00:13:02,370 --> 00:13:05,369
I've been stowing match
like one core, one ship.

365
00:13:05,369 --> 00:13:06,790
So I have the CPU.

366
00:13:06,790 --> 00:13:09,449
And the CPU actually has lots
of different things in it,

367
00:13:09,449 --> 00:13:10,970
and I'm sowing, like, two things

368
00:13:10,970 --> 00:13:12,709
that are important
to us right now.

369
00:13:12,709 --> 00:13:15,349
O is that it has a clock. Right?

370
00:13:15,349 --> 00:13:17,329
And that clock is
ticking very fast.

371
00:13:17,329 --> 00:13:18,949
A lot of CPUs you buy.

372
00:13:18,949 --> 00:13:21,430
It will, like rate the
performance or the clock speed

373
00:13:21,430 --> 00:13:24,090
in terms of Gigahertz,
Giga billions.

374
00:13:24,090 --> 00:13:25,229
So that clock is actually

375
00:13:25,229 --> 00:13:27,330
ticking billions
of times a second.

376
00:13:27,330 --> 00:13:29,370
And as that clock is ticking,

377
00:13:29,370 --> 00:13:31,829
it's doing instructions, right?

378
00:13:31,829 --> 00:13:33,769
Maybe it's adding
numbers or kind

379
00:13:33,769 --> 00:13:35,010
of evaluating

380
00:13:35,010 --> 00:13:37,169
whether an expression is
true or things like that.

381
00:13:37,169 --> 00:13:39,429
It's definitely not
the case that we have

382
00:13:39,429 --> 00:13:41,950
one instruction for
one clock tick.

383
00:13:41,950 --> 00:13:43,329
I mean, there's some
instructions that

384
00:13:43,329 --> 00:13:45,130
might take a bunch
of clock techs.

385
00:13:45,130 --> 00:13:47,129
The flip side, sometimes
it's possible to get

386
00:13:47,129 --> 00:13:49,269
multiple instructions
through with

387
00:13:49,269 --> 00:13:50,890
a single top clock tick,

388
00:13:50,890 --> 00:13:52,910
but kind of a accrue
approximation would be

389
00:13:52,910 --> 00:13:55,529
fair to say this CPU can do,

390
00:13:55,529 --> 00:13:58,929
over 1 billion simple
things every second, right?

391
00:13:58,929 --> 00:14:00,995
CPU is running very fast.

392
00:14:00,995 --> 00:14:02,819
Now, as I say these
calculations,

393
00:14:02,819 --> 00:14:05,079
it does these
calculations on values.

394
00:14:05,079 --> 00:14:08,740
And you all are used to like
variables in your program.

395
00:14:08,740 --> 00:14:10,520
A CPU has something a lot like

396
00:14:10,520 --> 00:14:12,439
a variable called a register.

397
00:14:12,439 --> 00:14:15,320
Register is really like a
variable that's like built

398
00:14:15,320 --> 00:14:18,119
into hardware and is
super fast, right?

399
00:14:18,119 --> 00:14:21,139
And so you can't give
them banams or here

400
00:14:21,139 --> 00:14:24,779
I just them like register
12 and three, right?

401
00:14:24,779 --> 00:14:27,000
Call that R one or two or
three? They have other names.

402
00:14:27,000 --> 00:14:28,660
It really depends on the CPU.

403
00:14:28,660 --> 00:14:31,100
There won't be a lot of them,
maybe like half a dozen,

404
00:14:31,100 --> 00:14:32,479
maybe a dozen,
something like that,

405
00:14:32,479 --> 00:14:34,019
kind of a small order,

406
00:14:34,019 --> 00:14:35,800
but we can put values in there,

407
00:14:35,800 --> 00:14:37,680
and we can operate on very fast.

408
00:14:37,680 --> 00:14:39,730
So, for example, Maybe

409
00:14:39,730 --> 00:14:41,890
as this clock is ticking,
we could do a calculation.

410
00:14:41,890 --> 00:14:43,649
We could say the
R three register

411
00:14:43,649 --> 00:14:45,849
should equal R one plus R two.

412
00:14:45,849 --> 00:14:47,049
That would happen very quickly,

413
00:14:47,049 --> 00:14:49,369
maybe in one clock cycle.

414
00:14:49,369 --> 00:14:53,089
That's the happy
part of the story.

415
00:14:53,130 --> 00:14:56,210
Of course, even for
a small data set.

416
00:14:56,210 --> 00:14:57,590
We're looking at big data sets,

417
00:14:57,590 --> 00:14:59,230
but even for a small data set,

418
00:14:59,230 --> 00:15:01,590
it won't fit in this
handful of registers.

419
00:15:01,590 --> 00:15:05,310
I have a bunch of values
over there in RAB.

420
00:15:05,310 --> 00:15:07,890
And so Rab can have
lots of values,

421
00:15:07,890 --> 00:15:10,850
but there's no computation
built into RAB.

422
00:15:10,850 --> 00:15:13,209
There's not something
in RAM that can

423
00:15:13,209 --> 00:15:16,114
add to numbers or do any
other sort of calculation.

424
00:15:16,114 --> 00:15:17,940
And so what that
means is that if I

425
00:15:17,940 --> 00:15:19,460
want to add these
two numbers in Rab,

426
00:15:19,460 --> 00:15:22,220
I have to get them over
where the CPU can see them.

427
00:15:22,220 --> 00:15:24,320
And what that will involve
is a few instructure.

428
00:15:24,320 --> 00:15:25,659
I have to do a loaded
structure that will

429
00:15:25,659 --> 00:15:28,799
bring these values
into the registers,

430
00:15:28,799 --> 00:15:32,160
another calc another operation

431
00:15:32,160 --> 00:15:33,440
that will add them together.

432
00:15:33,440 --> 00:15:34,919
And then a third
one that's going to

433
00:15:34,919 --> 00:15:37,060
store them back up to Rab.

434
00:15:37,060 --> 00:15:39,020
And the way that all works,

435
00:15:39,020 --> 00:15:40,420
I kind of draw this
weird lie here.

436
00:15:40,420 --> 00:15:41,620
That's called a memory bus.

437
00:15:41,620 --> 00:15:46,780
The CPU and Rab are communicating
over this memory bus.

438
00:15:46,780 --> 00:15:49,780
And so what happens
when we do a load?

439
00:15:49,780 --> 00:15:52,020
Well? It has to

440
00:15:52,020 --> 00:15:54,200
bring that value from
rab into this register,

441
00:15:54,200 --> 00:15:55,779
and that might take
something like,

442
00:15:55,779 --> 00:15:57,760
let's say, 60 nato seconds.

443
00:15:57,760 --> 00:15:59,179
That seems kind of fast,

444
00:15:59,179 --> 00:16:00,699
but that might be say,

445
00:16:00,699 --> 00:16:03,959
like 200 cycles on
the CPU, right?

446
00:16:03,959 --> 00:16:05,060
So we were kind of
chugging along.

447
00:16:05,060 --> 00:16:06,660
We were maybe like
doing one thing every

448
00:16:06,660 --> 00:16:07,940
cycle more or less.

449
00:16:07,940 --> 00:16:11,160
And all of a sudden we have
to wait for 200 flock techs.

450
00:16:11,160 --> 00:16:13,000
So that's painfully slow,

451
00:16:13,000 --> 00:16:14,319
right? You will
feel that, right?

452
00:16:14,319 --> 00:16:16,020
I, you won't feel
if it happens once,

453
00:16:16,020 --> 00:16:17,400
but if your program
is doing this a

454
00:16:17,400 --> 00:16:19,399
lot versus doing this not a lot,

455
00:16:19,399 --> 00:16:21,260
Your program could be 100 times

456
00:16:21,260 --> 00:16:22,999
faster or slower than
it would be, right?

457
00:16:22,999 --> 00:16:25,399
This is something we very
much have to worry about.

458
00:16:25,399 --> 00:16:27,060
What can we do while
we're waiting?

459
00:16:27,060 --> 00:16:28,699
Well, there's kind of
limited options, right?

460
00:16:28,699 --> 00:16:31,720
It's kind of a lot longer
than a normal operation,

461
00:16:31,720 --> 00:16:33,680
but it's not long
enough to switch and

462
00:16:33,680 --> 00:16:35,799
run a different program, right?

463
00:16:35,799 --> 00:16:36,920
That would take even longer than

464
00:16:36,920 --> 00:16:40,220
the 200 nato seconds or
the 60 nato seconds.

465
00:16:40,220 --> 00:16:43,019
So it's a little
bit wasted, right?

466
00:16:43,310 --> 00:16:45,549
So the 60 data seconds,

467
00:16:45,549 --> 00:16:46,650
that's an example of lacy.

468
00:16:46,650 --> 00:16:49,049
Latency is measuring any
amount of time like that.

469
00:16:49,049 --> 00:16:52,230
Another measure of
performance is throughput.

470
00:16:52,230 --> 00:16:53,449
That's a rate, how many bytes

471
00:16:53,449 --> 00:16:54,869
can be transferred per second.

472
00:16:54,869 --> 00:16:56,529
And so I can also think about

473
00:16:56,529 --> 00:16:58,069
performance between these two,

474
00:16:58,069 --> 00:16:59,509
not just in terms of latency,

475
00:16:59,509 --> 00:17:01,029
but the throughput, right.

476
00:17:01,029 --> 00:17:03,610
Depending on how many
values I can load at

477
00:17:03,610 --> 00:17:06,649
the same time might affect
my performance too,

478
00:17:06,649 --> 00:17:07,990
not just how much time it takes

479
00:17:07,990 --> 00:17:10,389
to do an individual value.

480
00:17:11,350 --> 00:17:14,089
Alright, so how do we
solve this problem or

481
00:17:14,089 --> 00:17:16,610
at least, make it not as bad?

482
00:17:16,610 --> 00:17:19,329
We add, you can
almost think of it

483
00:17:19,329 --> 00:17:22,029
as a bit of memory
on the CPU itself,

484
00:17:22,029 --> 00:17:24,469
part of that chip, right?
That's called a cache.

485
00:17:24,469 --> 00:17:27,109
And obviously, the whole
ab will not fit there,

486
00:17:27,109 --> 00:17:28,909
otherwise we wouldn't
even need ab,

487
00:17:28,909 --> 00:17:30,450
but we can keep the hot data

488
00:17:30,450 --> 00:17:31,609
that we're accessing
often there.

489
00:17:31,609 --> 00:17:33,710
Maybe some small
subset of the data,

490
00:17:33,710 --> 00:17:35,149
we can put it there, then we can

491
00:17:35,149 --> 00:17:38,109
access it more quickly, right?

492
00:17:38,270 --> 00:17:40,509
Now, it turns out that,

493
00:17:40,509 --> 00:17:42,309
like, how big is this cache?

494
00:17:42,309 --> 00:17:45,249
Often, as we have to
make things bigger,

495
00:17:45,249 --> 00:17:47,249
they necessarily get slower.

496
00:17:47,249 --> 00:17:49,149
So you can imagine
that I don't know,

497
00:17:49,149 --> 00:17:50,509
I have a few papers here.

498
00:17:50,509 --> 00:17:53,249
Maybe I have like a bunch
of different books or

499
00:17:53,249 --> 00:17:55,109
things that I might
have different

500
00:17:55,109 --> 00:17:56,449
kinds of information, right?

501
00:17:56,449 --> 00:17:58,009
You know, I could
put these books

502
00:17:58,009 --> 00:17:59,430
and papers or whatever
on this desk,

503
00:17:59,430 --> 00:18:00,430
and I could switch between

504
00:18:00,430 --> 00:18:01,889
them quickly and read them all.

505
00:18:01,889 --> 00:18:03,710
You know, I I had
like 1 million books,

506
00:18:03,710 --> 00:18:06,130
it might fill the
stage or even more,

507
00:18:06,130 --> 00:18:07,930
maybe it might fill
the whole room,

508
00:18:07,930 --> 00:18:10,449
and to just buy the physical
necessity of it, right?

509
00:18:10,449 --> 00:18:12,789
If I want to have
some place to like,

510
00:18:12,789 --> 00:18:13,589
spread out, you know,

511
00:18:13,589 --> 00:18:15,184
1 million papers or books,

512
00:18:15,184 --> 00:18:17,039
I would take me longer to travel

513
00:18:17,039 --> 00:18:18,919
to each one that if I have
something small, right?

514
00:18:18,919 --> 00:18:19,879
So it's just like we

515
00:18:19,879 --> 00:18:21,299
see this fundamental
trade off, right?

516
00:18:21,299 --> 00:18:24,359
You could be small and
fast or big and slow,

517
00:18:24,359 --> 00:18:26,339
and we're look at more of that.

518
00:18:26,339 --> 00:18:27,580
There's a lot of
different places

519
00:18:27,580 --> 00:18:29,200
you could be on that spectrum.

520
00:18:29,200 --> 00:18:31,459
Okay, so if we have this cache,

521
00:18:31,459 --> 00:18:32,339
then we can think about

522
00:18:32,339 --> 00:18:33,580
performance in a
few different ways.

523
00:18:33,580 --> 00:18:34,999
We think about kind of

524
00:18:34,999 --> 00:18:37,219
total throughput of the
application. Right?

525
00:18:37,219 --> 00:18:40,280
There's throughput from
main memory to the CPU.

526
00:18:40,280 --> 00:18:42,360
But if a lot of the
data is in the cache,

527
00:18:42,360 --> 00:18:43,719
then if we look at

528
00:18:43,719 --> 00:18:45,800
how many bytes the
program is accessing,

529
00:18:45,800 --> 00:18:48,459
we might get better
throughput than that

530
00:18:48,459 --> 00:18:52,059
bandwidth between
CPU and memory.

531
00:18:52,059 --> 00:18:53,579
We could look at some kind of

532
00:18:53,579 --> 00:18:56,619
typical latency in terms of
maybe like average or median.

533
00:18:56,619 --> 00:18:58,679
And then sometimes people will

534
00:18:58,679 --> 00:19:00,759
measure what we call
tail latency, right?

535
00:19:00,759 --> 00:19:03,324
So there's like a
statistical distribution.

536
00:19:03,324 --> 00:19:06,509
Of the latencies.
And so tailed CVs

537
00:19:06,509 --> 00:19:08,029
were looking at kind of a
high percentile, right?

538
00:19:08,029 --> 00:19:09,350
If I took all the
different latencies

539
00:19:09,350 --> 00:19:10,510
of b different operations,

540
00:19:10,510 --> 00:19:12,550
maybe I look at the
99th percentile.

541
00:19:12,550 --> 00:19:15,150
So one of the slowest
ones or 99.9,

542
00:19:15,150 --> 00:19:16,789
and I can measure that.

543
00:19:16,789 --> 00:19:18,689
So when I add the cache,

544
00:19:18,689 --> 00:19:20,070
right, performance gets better,

545
00:19:20,070 --> 00:19:22,630
but there's one statistic

546
00:19:22,630 --> 00:19:25,469
out here that's going to be
hard to fix with a cache.

547
00:19:25,469 --> 00:19:28,489
Anybody have any thoughts on
which of these is going to

548
00:19:28,489 --> 00:19:31,869
be hardest to solve
using a cache?

549
00:19:39,760 --> 00:19:43,920
Yeah, right here.
Was the rough put

550
00:19:43,920 --> 00:19:45,220
be hard to solve with the cash?

551
00:19:45,220 --> 00:19:46,259
I think the cash will

552
00:19:46,259 --> 00:19:47,679
actually help with the
throughput, right?

553
00:19:47,679 --> 00:19:53,139
Because let's say that before,

554
00:19:53,139 --> 00:19:54,960
I had to access all
the values from rab.

555
00:19:54,960 --> 00:19:57,199
Let's say I can transfer
like a gigabyte per second.

556
00:19:57,199 --> 00:19:59,020
Right? Well, then my
applications performance

557
00:19:59,020 --> 00:20:00,959
was a gigabyte per second.

558
00:20:00,959 --> 00:20:04,659
If now I have a cache
and half of my values,

559
00:20:04,659 --> 00:20:05,740
I pull from the cache,

560
00:20:05,740 --> 00:20:08,699
and then half I can pull memory,

561
00:20:08,699 --> 00:20:10,120
then all of a sudden I can it 2

562
00:20:10,120 --> 00:20:12,219
gigabytes/second.
Yeah, I had I p here.

563
00:20:12,219 --> 00:20:15,620
The tail. Why is the
tail hard to fix?

564
00:20:15,620 --> 00:20:19,520
Faster. Mm hmm.

565
00:20:19,520 --> 00:20:20,939
Yeah, it makes some
things faster,

566
00:20:20,939 --> 00:20:22,400
but the slow saves
will still be slow

567
00:20:22,400 --> 00:20:24,639
because the only way to
make everything fast is

568
00:20:24,639 --> 00:20:26,579
that if all the
data fit in cash at

569
00:20:26,579 --> 00:20:28,680
that point is it
even really a cash?

570
00:20:28,680 --> 00:20:31,679
Right? If we have a cash,
you know, presumably,

571
00:20:31,679 --> 00:20:33,820
there's going to be some
data that's not in the cash,

572
00:20:33,820 --> 00:20:38,059
and that will show up as
the slowest accesses.

573
00:20:38,059 --> 00:20:40,019
So that's a hard
problem to deal with.

574
00:20:40,019 --> 00:20:43,510
And we'll talk more about
Hill to see other lectures.

575
00:20:43,510 --> 00:20:47,039
Alright, let's talk about
the cash hierarchy now.

576
00:20:47,039 --> 00:20:49,120
Here's a nice picture I
borrowed from that book,

577
00:20:49,120 --> 00:20:50,699
where we're comparing
that faster

578
00:20:50,699 --> 00:20:52,499
and smaller to
bigger and slower.

579
00:20:52,499 --> 00:20:54,140
So I mean, at the very
top of the hierarchy,

580
00:20:54,140 --> 00:20:55,380
we have CPU registers.

581
00:20:55,380 --> 00:20:59,844
That's super fast.
We might have a

582
00:20:59,844 --> 00:21:01,790
Kind of cash their
different size.

583
00:21:01,790 --> 00:21:02,469
L1l2.

584
00:21:02,469 --> 00:21:04,349
There's some other distinctions
between them I one and

585
00:21:04,349 --> 00:21:07,810
two that might be
per core on a CPU.

586
00:21:07,810 --> 00:21:10,429
Then I might have some like
at L three cash that might be

587
00:21:10,429 --> 00:21:13,710
shared across all the
cores on a processor.

588
00:21:13,710 --> 00:21:15,549
As we go down, you
can see some example

589
00:21:15,549 --> 00:21:17,490
sizes down here,
like at L one cash.

590
00:21:17,490 --> 00:21:19,370
Maybe that's like 64 kilobytes,

591
00:21:19,370 --> 00:21:22,290
l21 megabyte, 77 megabytes.

592
00:21:22,290 --> 00:21:23,569
This is just one particular CPU,

593
00:21:23,569 --> 00:21:25,330
but I want you get an idea
of the order of magnitude.

594
00:21:25,330 --> 00:21:27,809
It's like we have many gigabytes

595
00:21:27,809 --> 00:21:29,849
of data in a CPU cash, right?

596
00:21:29,849 --> 00:21:33,300
It's small. We have to use
that resource carefully.

597
00:21:33,300 --> 00:21:36,169
And then, of course, once
you get out of the CPU,

598
00:21:36,169 --> 00:21:37,469
out of the gray
area, then we have

599
00:21:37,469 --> 00:21:39,689
made memory, which was slower.

600
00:21:39,689 --> 00:21:42,389
Now, main memory
certainly is not

601
00:21:42,389 --> 00:21:45,329
the biggest slowest thing
you can imagine, right?

602
00:21:45,329 --> 00:21:46,270
There's other things that could

603
00:21:46,270 --> 00:21:47,869
store bytes, so for example,

604
00:21:47,869 --> 00:21:50,210
but SST or hard
drive would be even

605
00:21:50,210 --> 00:21:53,229
bigger than main memory,

606
00:21:53,229 --> 00:21:55,569
and quite a bit slower, right?

607
00:21:55,569 --> 00:21:57,390
So I could keep data there.

608
00:21:57,390 --> 00:21:59,009
And even beyond that,

609
00:21:59,009 --> 00:22:01,309
you could imagine like
in the cloud, right?

610
00:22:01,309 --> 00:22:03,449
There's these services I guess
it's technically finite,

611
00:22:03,449 --> 00:22:04,869
but for all practical purposes,

612
00:22:04,869 --> 00:22:07,949
there's like infinite
capacity in the cloud,

613
00:22:07,949 --> 00:22:09,369
and it's pretty slow to access,

614
00:22:09,369 --> 00:22:10,809
right? I have to kind
of go over the network.

615
00:22:10,809 --> 00:22:13,269
I fetch some data and
send it back to me.

616
00:22:13,269 --> 00:22:15,329
So maybe I put cloud
storage at the bottom of

617
00:22:15,329 --> 00:22:17,889
this hierarchy or maybe
a network in general.

618
00:22:17,889 --> 00:22:19,389
And so when we're
talking about thing,

619
00:22:19,389 --> 00:22:20,710
it could really be
happening between

620
00:22:20,710 --> 00:22:24,389
any two layers in
this picture, right?

621
00:22:24,389 --> 00:22:26,830
So it cuts up. That shows
up and get it again.

622
00:22:26,830 --> 00:22:28,870
And you should have kind of
imagined this like pyramid,

623
00:22:28,870 --> 00:22:30,310
tah hierarchy and kind

624
00:22:30,310 --> 00:22:32,809
of remember some of
the key layers here.

625
00:22:33,400 --> 00:22:35,999
So, those numbers I just showed

626
00:22:35,999 --> 00:22:38,119
were from reading a spec, right?

627
00:22:38,119 --> 00:22:40,599
For that hardware. But you

628
00:22:40,599 --> 00:22:42,180
can also run some experiments

629
00:22:42,180 --> 00:22:43,319
and figure it out empirically.

630
00:22:43,319 --> 00:22:46,140
So here's another nice
experiment they did in the book.

631
00:22:46,140 --> 00:22:48,775
And I apologize, the fat
is a little bit small.

632
00:22:48,775 --> 00:22:50,750
But what they did is they wrote

633
00:22:50,750 --> 00:22:52,170
this little benchmark program.

634
00:22:52,170 --> 00:22:54,069
And what the program
would do is it would

635
00:22:54,069 --> 00:22:56,769
generate datasets
of different sizes.

636
00:22:56,769 --> 00:22:59,949
And the size of the data set
is on the x axis, right?

637
00:22:59,949 --> 00:23:02,369
So I guess it goes it'll
be like 1 kilobyte up

638
00:23:02,369 --> 00:23:06,849
to 10,000 kilobytes like
10 megabytes, and beyond.

639
00:23:06,849 --> 00:23:08,630
And then when they
have that dataset,

640
00:23:08,630 --> 00:23:11,329
what they'll do is they'll
kind of loop over it, right?

641
00:23:11,329 --> 00:23:14,089
And they'll loop
over it many times.

642
00:23:14,089 --> 00:23:16,470
And if the dataset is small

643
00:23:16,470 --> 00:23:19,529
enough to fit at a particular
level of the cache,

644
00:23:19,529 --> 00:23:22,749
Well, then you'll get the
performance of that cash level?

645
00:23:22,749 --> 00:23:24,269
If it's a little bit
too big for that,

646
00:23:24,269 --> 00:23:25,610
then it'll be at a
different cash level

647
00:23:25,610 --> 00:23:26,910
and you'll get a
different performance.

648
00:23:26,910 --> 00:23:28,269
And so as they're
looping for it,

649
00:23:28,269 --> 00:23:31,389
they show how long it takes
to do a memory access, right?

650
00:23:31,389 --> 00:23:33,229
So in the good case, we're
talking about, you know,

651
00:23:33,229 --> 00:23:35,949
1-2 nato seconds to access,

652
00:23:35,949 --> 00:23:37,270
and then in the bad case,

653
00:23:37,270 --> 00:23:39,229
I guess what is that
100 nato seconds,

654
00:23:39,229 --> 00:23:40,929
so even worse to that,

655
00:23:40,929 --> 00:23:45,490
something like 100-200 nato
seconds in the worst case.

656
00:23:45,490 --> 00:23:47,009
So I'm just wondering if anybody

657
00:23:47,009 --> 00:23:49,610
could help me
interpret this strap.

658
00:23:49,610 --> 00:23:52,029
Does anybody want to venture

659
00:23:52,029 --> 00:23:54,429
a guess about how big
the L three cache is

660
00:23:54,429 --> 00:23:56,869
and what the latency is

661
00:23:56,869 --> 00:24:00,270
for accessing data,
L three cache?

662
00:24:10,150 --> 00:24:12,709
Yeah, right here.

663
00:24:18,950 --> 00:24:21,829
Yeah, I guess this
is the threshold,

664
00:24:21,829 --> 00:24:24,429
the 10,000 kill bytes
or 10 megabytes.

665
00:24:24,429 --> 00:24:27,150
So I guess what is
the last level?

666
00:24:27,150 --> 00:24:29,649
I guess what is the
last level that

667
00:24:29,649 --> 00:24:32,990
we might have here at
the picture up above.

668
00:24:37,040 --> 00:24:40,779
It is what? Under nanoseconds.

669
00:24:40,779 --> 00:24:42,519
So I think your logic is right.

670
00:24:42,519 --> 00:24:44,059
I think we have it off by one.

671
00:24:44,059 --> 00:24:45,819
Like this last level
is going to be

672
00:24:45,819 --> 00:24:47,539
some in made beary, right?

673
00:24:47,539 --> 00:24:49,199
So you described to be like

674
00:24:49,199 --> 00:24:50,859
the performance of
accessing bad beary,

675
00:24:50,859 --> 00:24:51,659
and that's up here.

676
00:24:51,659 --> 00:24:53,700
And then right before
the L three cache.

677
00:24:53,700 --> 00:24:55,519
I think this is I'd say that

678
00:24:55,519 --> 00:24:58,139
the size is about 10 megabytes,

679
00:24:58,139 --> 00:24:59,899
and the axis is,

680
00:24:59,899 --> 00:25:01,799
I guess a I don't know.

681
00:25:01,799 --> 00:25:03,719
It's hard to read out a log
scale, maybe let's say,

682
00:25:03,719 --> 00:25:05,479
18 nato seconds
or something like

683
00:25:05,479 --> 00:25:08,339
that for accessing the L three.

684
00:25:08,339 --> 00:25:10,459
So you distinctly
see that, right?

685
00:25:10,459 --> 00:25:11,759
If you're down here,
right, I mean,

686
00:25:11,759 --> 00:25:13,780
you're 100 times
faster than pier.

687
00:25:13,780 --> 00:25:15,640
So this makes a huge deal,

688
00:25:15,640 --> 00:25:19,399
like, what cash level
our dataset fits at.

689
00:25:19,399 --> 00:25:20,679
So, do people have
any question about

690
00:25:20,679 --> 00:25:23,799
the cash hierarchy or
that reason right here?

691
00:25:33,960 --> 00:25:36,599
Yeah, why is it smoother

692
00:25:36,599 --> 00:25:38,879
up here and kind of
more sharp down here?

693
00:25:38,879 --> 00:25:40,559
It's a little hard to see, but

694
00:25:40,559 --> 00:25:42,020
you can actually see they put

695
00:25:42,020 --> 00:25:43,519
little bubbles out here for

696
00:25:43,519 --> 00:25:46,319
the places where they
rat and experimented.

697
00:25:46,319 --> 00:25:47,499
The light is interpolated

698
00:25:47,499 --> 00:25:49,239
between different
data set sizes.

699
00:25:49,239 --> 00:25:50,519
And so the way it looks to be

700
00:25:50,519 --> 00:25:51,679
is where it's kind
of steep here.

701
00:25:51,679 --> 00:25:53,019
It looks like that
they didn't run

702
00:25:53,019 --> 00:25:55,439
anything in between, right?

703
00:25:55,439 --> 00:25:57,819
And here, we can see there's
a bunch of points at it.

704
00:25:57,819 --> 00:26:00,039
So maybe the other ones might
be a little curved, too.

705
00:26:00,039 --> 00:26:02,234
It's hard to tell.
I'm speculating.

706
00:26:02,234 --> 00:26:04,870
But especially when
you have a log scale,

707
00:26:04,870 --> 00:26:06,709
I don't know if I don't know if

708
00:26:06,709 --> 00:26:08,769
they chose their points on
a log scale as well, right?

709
00:26:08,769 --> 00:26:09,469
So if you do that,

710
00:26:09,469 --> 00:26:10,849
then maybe as you get
farther to the right,

711
00:26:10,849 --> 00:26:13,309
you might see more detail

712
00:26:13,309 --> 00:26:15,570
of the curve rather than
the interpolated light,

713
00:26:15,570 --> 00:26:17,809
speculating a little bit,
as I to do the experiment,

714
00:26:17,809 --> 00:26:19,609
but it's a good
thing to point out.

715
00:26:19,609 --> 00:26:21,109
Yeah, other questions or

716
00:26:21,109 --> 00:26:23,670
comments people have
about the experiment.

717
00:26:25,310 --> 00:26:27,699
All right. Yeah, right here.

718
00:26:27,699 --> 00:26:30,010
Why does it flat?

719
00:26:33,730 --> 00:26:37,489
Yeah. Yeah. Why does
it flat it out?

720
00:26:37,489 --> 00:26:42,030
So here my L three is
let's say 10 megabytes,

721
00:26:42,030 --> 00:26:43,689
what is this one over here?

722
00:26:43,689 --> 00:26:47,690
I guess in between there
would be like 1 megabyte.

723
00:26:47,690 --> 00:26:51,009
So somewhere I guess

724
00:26:51,009 --> 00:26:54,469
this drop off is less
than 1 megabyte.

725
00:26:54,469 --> 00:26:57,510
Let's say I have a five
megabyte data set.

726
00:26:57,510 --> 00:27:00,029
It fits entirely in my L three,

727
00:27:00,029 --> 00:27:02,704
but it definitely does
not fit at the L two ca.

728
00:27:02,704 --> 00:27:05,160
If I have an eight
baked by dataset,

729
00:27:05,160 --> 00:27:07,040
all fits of the L three cash,

730
00:27:07,040 --> 00:27:09,459
nothing fits in the
L two cash, right?

731
00:27:09,459 --> 00:27:11,140
That's why it's pretty flat.

732
00:27:11,140 --> 00:27:11,819
Now, I mean,

733
00:27:11,819 --> 00:27:13,719
maybe the question that
you're asking is, like,

734
00:27:13,719 --> 00:27:15,559
why don't we see that
at least some of

735
00:27:15,559 --> 00:27:18,860
the data is even though,

736
00:27:18,860 --> 00:27:20,319
like the Data set is
mostly in L three,

737
00:27:20,319 --> 00:27:22,199
why don't we see that some
of it is in L two, right?

738
00:27:22,199 --> 00:27:25,900
Li You might expect to be
maybe not perfectly flat.

739
00:27:25,900 --> 00:27:27,439
And it really depends, right?

740
00:27:27,439 --> 00:27:30,599
B I guess when we look
at the cash policies,

741
00:27:30,599 --> 00:27:31,699
we'll see there might
be cases where I

742
00:27:31,699 --> 00:27:33,239
keep scanning over
the whole data that

743
00:27:33,239 --> 00:27:34,819
never It doesn't know

744
00:27:34,819 --> 00:27:37,180
what data to keep in
the smaller cash,

745
00:27:37,180 --> 00:27:39,699
and it might not do a
good job of using it.

746
00:27:39,699 --> 00:27:41,439
You can totally imagine that if

747
00:27:41,439 --> 00:27:42,480
it doesn't fit L two Cash,

748
00:27:42,480 --> 00:27:43,720
it might still use
some L two cash

749
00:27:43,720 --> 00:27:44,879
and get some
performance out of it,

750
00:27:44,879 --> 00:27:47,179
but this CPU does not
seem to be doing that.

751
00:27:47,179 --> 00:27:49,980
It'll make more sense
when we do the worksheet.

752
00:27:49,980 --> 00:27:51,900
You're thinking about it
the right way, though.

753
00:27:51,900 --> 00:27:55,909
Yeah, other questions
people have. All right.

754
00:27:55,909 --> 00:27:59,369
W. The way to think

755
00:27:59,369 --> 00:28:00,909
about caching is that

756
00:28:00,909 --> 00:28:03,290
you're trading off two
different resources.

757
00:28:03,290 --> 00:28:04,529
Usually, the two
different types of

758
00:28:04,529 --> 00:28:06,030
resources or are different
ways of story pypes.

759
00:28:06,030 --> 00:28:07,329
So I would just look
at some examples

760
00:28:07,329 --> 00:28:09,289
of Caching shows up
everywhere, by the way.

761
00:28:09,289 --> 00:28:11,250
Let's just see a few examples.

762
00:28:11,250 --> 00:28:13,329
Normally, I have
a bunch of files

763
00:28:13,329 --> 00:28:16,010
on a hard drive or a SSD.

764
00:28:16,010 --> 00:28:17,949
And when I read those,

765
00:28:17,949 --> 00:28:20,569
my operating system
caches those in memory.

766
00:28:20,569 --> 00:28:22,350
So there's a res
source trade off here.

767
00:28:22,350 --> 00:28:24,389
The operating system
is using more memory.

768
00:28:24,389 --> 00:28:25,969
And there's a cost to
that. I could have used

769
00:28:25,969 --> 00:28:29,039
that memory for something
else. It's using more memory.

770
00:28:29,039 --> 00:28:32,369
But then it's avoiding having
to do storage reads, right?

771
00:28:32,369 --> 00:28:35,669
I can only read data so
fast from my device.

772
00:28:35,669 --> 00:28:39,449
So I'm trading off between
two scarce resources.

773
00:28:39,449 --> 00:28:41,170
And try to be good
at this space,

774
00:28:41,170 --> 00:28:43,089
you have to start to gain
some intuition about

775
00:28:43,089 --> 00:28:45,409
when you want to trade off one
resource for $1 resources,

776
00:28:45,409 --> 00:28:47,209
you have to think about
what resources are

777
00:28:47,209 --> 00:28:48,289
available to you and try to

778
00:28:48,289 --> 00:28:49,970
make a good decision
to that space.

779
00:28:49,970 --> 00:28:53,030
What about this? When my
browser visits a web page,

780
00:28:53,030 --> 00:28:54,289
it fetches it over the Internet,

781
00:28:54,289 --> 00:28:55,805
and that's inherently slow.

782
00:28:55,805 --> 00:28:57,900
It'll often store on
my local hard drive,

783
00:28:57,900 --> 00:28:59,600
and then I visit
the web page again,

784
00:28:59,600 --> 00:29:01,539
and it actually doesn't
do any network yo.

785
00:29:01,539 --> 00:29:05,759
Sees like, Oh, this web page
here is already stored.

786
00:29:05,759 --> 00:29:07,340
What am I avoiding?

787
00:29:07,340 --> 00:29:08,899
I'm avoiding network yo.

788
00:29:08,899 --> 00:29:10,499
And what am I spending?

789
00:29:10,499 --> 00:29:12,600
While I'm spending
some storage space,

790
00:29:12,600 --> 00:29:15,299
and then also some
reads to that storage.

791
00:29:15,299 --> 00:29:17,304
I'm trading off two resources.

792
00:29:17,304 --> 00:29:19,910
This third one is like a
good optimization trick

793
00:29:19,910 --> 00:29:21,910
that I bet you all will
use at some point,

794
00:29:21,910 --> 00:29:24,230
is a good one to remember.

795
00:29:24,270 --> 00:29:28,430
You often end up with
like your programming,

796
00:29:28,430 --> 00:29:30,649
you have a function that takes

797
00:29:30,649 --> 00:29:33,589
a long time to execute,
and your function,

798
00:29:33,589 --> 00:29:35,309
let's say, also happens to have

799
00:29:35,309 --> 00:29:37,649
the behavior that if you
give it the same input,

800
00:29:37,649 --> 00:29:39,589
it gives you the same output.

801
00:29:39,589 --> 00:29:40,989
Let's say you also have to call

802
00:29:40,989 --> 00:29:43,890
this function many times
for whatever reason.

803
00:29:43,890 --> 00:29:46,509
How can you deal with this?
You can solve it with cache.

804
00:29:46,509 --> 00:29:48,829
Your cash can remember
previous results.

805
00:29:48,829 --> 00:29:50,549
So I just have a little
code stip over here that

806
00:29:50,549 --> 00:29:53,140
Python I have by cash,

807
00:29:53,140 --> 00:29:54,760
which is a Python dictionary.

808
00:29:54,760 --> 00:29:57,959
Python dictionaries have
keys in values, right?

809
00:29:57,959 --> 00:30:01,299
So the values are going to
be the thing I'm caching.

810
00:30:01,299 --> 00:30:02,639
Like these cash entries will be

811
00:30:02,639 --> 00:30:05,939
the things that G of X
returned previously.

812
00:30:05,939 --> 00:30:08,380
And then the key
will be the x value.

813
00:30:08,380 --> 00:30:10,900
I'll use that key to
look up an entry.

814
00:30:10,900 --> 00:30:12,240
In general, when you're
building a cache,

815
00:30:12,240 --> 00:30:13,559
you have to have
some type of key on

816
00:30:13,559 --> 00:30:15,300
it to look up a specific value.

817
00:30:15,300 --> 00:30:17,160
So I have this
cash here, and I'm

818
00:30:17,160 --> 00:30:19,059
trying to make the G
of x flection faster.

819
00:30:19,059 --> 00:30:21,639
So what I'll do is I'll
write an F of x fleion,

820
00:30:21,639 --> 00:30:23,340
that's a wrapper
around of G of X.

821
00:30:23,340 --> 00:30:25,604
That F of x calls G of X.

822
00:30:25,604 --> 00:30:28,249
And what F of x will do is

823
00:30:28,249 --> 00:30:31,110
that it will check if we've
seen that x value before.

824
00:30:31,110 --> 00:30:32,789
Is that x value in the cache?

825
00:30:32,789 --> 00:30:35,289
If it's not, then we'll
have to call G of X,

826
00:30:35,289 --> 00:30:37,250
it'll be very slow,
but we'll save

827
00:30:37,250 --> 00:30:39,609
that in our Python
cache dictionary.

828
00:30:39,609 --> 00:30:40,909
And then when we
get down to here,

829
00:30:40,909 --> 00:30:42,789
we're going to return whatever
is in the cache, right?

830
00:30:42,789 --> 00:30:44,289
So at this point, it's
definitely there,

831
00:30:44,289 --> 00:30:46,469
if it wasn't, we put it there.

832
00:30:46,469 --> 00:30:48,049
So the first time I call f of x

833
00:30:48,049 --> 00:30:49,630
with a new X value,
it'll be slow.

834
00:30:49,630 --> 00:30:51,350
I call it again
it'll be very fast.

835
00:30:51,350 --> 00:30:53,389
And from the perspective of

836
00:30:53,389 --> 00:30:55,689
somebody like writing code
that uses this function,

837
00:30:55,689 --> 00:30:57,290
it doesn't feel any
different to them.

838
00:30:57,290 --> 00:31:00,530
So it's kind of a very
natural optimization to slip

839
00:31:00,530 --> 00:31:01,729
into a lot of programs if you

840
00:31:01,729 --> 00:31:04,969
identify a slow
flection somewhere.

841
00:31:05,430 --> 00:31:08,430
So what are we using? We're
using more memory space?

842
00:31:08,430 --> 00:31:11,909
What are we saving? We're
saving compute time.

843
00:31:12,150 --> 00:31:17,760
Alright. Most of the things

844
00:31:17,760 --> 00:31:18,999
I've been talking about might

845
00:31:18,999 --> 00:31:20,899
be thought of as
mechanisms, right?

846
00:31:20,899 --> 00:31:22,820
Like how do we
actually do something?

847
00:31:22,820 --> 00:31:25,760
But then there's a
question, like, well,

848
00:31:25,760 --> 00:31:27,799
what should we do or
what decisions can we

849
00:31:27,799 --> 00:31:30,040
make given these
general strategies.

850
00:31:30,040 --> 00:31:31,179
And that's a question of policy.

851
00:31:31,179 --> 00:31:33,320
So we're talking
about policy now.

852
00:31:33,320 --> 00:31:36,920
So we have a cache, but what
data should draw the cash?

853
00:31:36,920 --> 00:31:39,239
I clearly cannot put everything.

854
00:31:39,239 --> 00:31:41,139
There's a few different
ways. What is

855
00:31:41,139 --> 00:31:42,960
that we can decide manually?

856
00:31:42,960 --> 00:31:44,699
And you're going to
be doing this when we

857
00:31:44,699 --> 00:31:46,219
look at Spark later
this semester.

858
00:31:46,219 --> 00:31:49,229
So Spark is one of the most
important systems will learn.

859
00:31:49,229 --> 00:31:52,240
Spark is a little bit like Pads.

860
00:31:52,240 --> 00:31:54,019
Some of you might know pads from

861
00:31:54,019 --> 00:31:56,279
320 or elsewhere or not,
don't worry if not.

862
00:31:56,279 --> 00:31:58,300
But Pads gives you data frames.

863
00:31:58,300 --> 00:32:00,439
Data frames are basically
like tables of data.

864
00:32:00,439 --> 00:32:02,960
And data frames with
pads are usually,

865
00:32:02,960 --> 00:32:05,279
basically almost
always in memory.

866
00:32:05,279 --> 00:32:08,419
Spark also has data frames
when it's designed for

867
00:32:08,419 --> 00:32:09,879
large datasets
that do not fit in

868
00:32:09,879 --> 00:32:12,659
memory in general, right?

869
00:32:12,659 --> 00:32:15,099
Now, it might happen
that you have

870
00:32:15,099 --> 00:32:16,700
a small Spark data frame

871
00:32:16,700 --> 00:32:18,439
that you're accessing
a lot of times.

872
00:32:18,439 --> 00:32:20,219
And so you would like
it to be in memory,

873
00:32:20,219 --> 00:32:22,780
even though that's not
the usual behavior.

874
00:32:22,780 --> 00:32:24,839
In this case, you could say a

875
00:32:24,839 --> 00:32:26,300
smart data frame about cash.

876
00:32:26,300 --> 00:32:28,279
It'll be a memory
after you use it,

877
00:32:28,279 --> 00:32:29,860
and then you can
use it for a bunch

878
00:32:29,860 --> 00:32:30,940
of things, and when
you're all done,

879
00:32:30,940 --> 00:32:33,999
you can say persist, you're
done using it, right?

880
00:32:33,999 --> 00:32:36,920
And, is this squid or bad?

881
00:32:36,920 --> 00:32:39,179
You might wish that it
happens automatically,

882
00:32:39,179 --> 00:32:41,399
but there's some nice
things about Manuel, too.

883
00:32:41,399 --> 00:32:42,860
The nice thing about Manuel

884
00:32:42,860 --> 00:32:45,399
is only I know my
own mind, right?

885
00:32:45,399 --> 00:32:48,460
Only I know what plots in
the death somebody do next.

886
00:32:48,460 --> 00:32:50,559
And so you have that knowledge
of what I'm about to do,

887
00:32:50,559 --> 00:32:52,859
I can make a caching
decision, right?

888
00:32:52,859 --> 00:32:55,040
So if you get dredit cash,

889
00:32:55,040 --> 00:32:56,400
you kind of understand
how it works,

890
00:32:56,400 --> 00:32:59,294
and you get intuition about
what you should cache.

891
00:32:59,294 --> 00:33:01,149
Then analysis that might

892
00:33:01,149 --> 00:33:02,549
be very slow, you
could save some time.

893
00:33:02,549 --> 00:33:03,929
If you kind of selectively

894
00:33:03,929 --> 00:33:05,650
cah things that
you're using a lot

895
00:33:05,650 --> 00:33:09,349
of that fitted
memory. Excuse me.

896
00:33:09,349 --> 00:33:11,409
Alright, let's look
at another example.

897
00:33:11,409 --> 00:33:13,009
So a web browser.

898
00:33:13,009 --> 00:33:15,329
A web browser visits

899
00:33:15,329 --> 00:33:18,030
some server that has a
co that has a website.

900
00:33:18,030 --> 00:33:20,170
So let's say that's like
the course website.

901
00:33:20,170 --> 00:33:21,849
And it's a page back.

902
00:33:21,849 --> 00:33:24,549
Most browsers will
then write that page

903
00:33:24,549 --> 00:33:27,530
to a file somewhere on my SSD.

904
00:33:27,530 --> 00:33:30,469
And that's may be called
the browser cache.

905
00:33:30,469 --> 00:33:33,050
If I visit that same page again,

906
00:33:33,050 --> 00:33:35,489
there's a good chat
and we'll pull it from

907
00:33:35,489 --> 00:33:36,869
the browser cache instead of

908
00:33:36,869 --> 00:33:39,809
going back to the web server.

909
00:33:39,809 --> 00:33:42,189
I vocabulary here. The
first time I did it

910
00:33:42,189 --> 00:33:43,989
where I had to actually go
out and do the slow thing,

911
00:33:43,989 --> 00:33:45,170
that's called a cash mess.

912
00:33:45,170 --> 00:33:46,829
My data was out of the cache.

913
00:33:46,829 --> 00:33:49,589
The second time it was in the
cache, as we call it a hit.

914
00:33:49,589 --> 00:33:51,009
So I might often ask you,

915
00:33:51,009 --> 00:33:53,049
like for Devi scenario,
how many hits are there?

916
00:33:53,049 --> 00:33:54,469
How many messes are there,

917
00:33:54,469 --> 00:33:56,669
right? Alright, so I have that.

918
00:33:56,669 --> 00:33:59,569
Now, let's say a day
pass that I visit again,

919
00:33:59,569 --> 00:34:02,930
even though that data
might still be in my SSD,

920
00:34:02,930 --> 00:34:04,929
there's a good chance
that we'll go out to

921
00:34:04,929 --> 00:34:07,869
the course website server
again and fetch it.

922
00:34:07,869 --> 00:34:10,110
And that is because maybe

923
00:34:10,110 --> 00:34:13,119
the schedule change or
something like that.

924
00:34:13,119 --> 00:34:14,950
Maybe the data in the cache

925
00:34:14,950 --> 00:34:16,629
might be stale.
We have to check.

926
00:34:16,629 --> 00:34:18,269
So we have to send a
request over here.

927
00:34:18,269 --> 00:34:20,650
Maybe the request just
says, give me the website.

928
00:34:20,650 --> 00:34:22,109
There might be other
ways to be a little

929
00:34:22,109 --> 00:34:23,689
bit smarter about it
and kind of asked,

930
00:34:23,689 --> 00:34:25,430
when was the last time this page

931
00:34:25,430 --> 00:34:28,230
changed before we actually
asked for the whole page,

932
00:34:28,230 --> 00:34:30,970
but data can become sale,

933
00:34:30,970 --> 00:34:33,189
and so you know,

934
00:34:33,189 --> 00:34:36,289
SSD is so large that we don't
worry too much about space.

935
00:34:36,289 --> 00:34:37,329
We're really just worried about

936
00:34:37,329 --> 00:34:39,209
freshness in this type of case.

937
00:34:39,209 --> 00:34:41,069
So the policy could just be
that when we fetch something,

938
00:34:41,069 --> 00:34:42,649
we put some expiration
of data on it,

939
00:34:42,649 --> 00:34:44,969
and we stop using it after
that expiration date.

940
00:34:44,969 --> 00:34:46,749
We might do that if
we just have a lot of

941
00:34:46,749 --> 00:34:50,109
excess capacity to store stuff.

942
00:34:50,690 --> 00:34:52,829
The final one that
we're going to spend

943
00:34:52,829 --> 00:34:54,429
a bunch of time on are

944
00:34:54,429 --> 00:34:56,629
automatic policies where we have

945
00:34:56,629 --> 00:34:59,809
very limited cash space, right?

946
00:34:59,809 --> 00:35:02,590
And for these policies,

947
00:35:02,590 --> 00:35:04,409
there's two parts of them.
What do we have to figure out?

948
00:35:04,409 --> 00:35:06,509
When do we bring
something into the cash,

949
00:35:06,509 --> 00:35:09,709
and when do we remove
something from the cash?

950
00:35:09,709 --> 00:35:13,069
The bringing something into
the cache is the easier part,

951
00:35:13,069 --> 00:35:15,270
and I'm to talk about
it for like 1 minute,

952
00:35:15,270 --> 00:35:17,569
and then we'll talk
for quite a lot

953
00:35:17,569 --> 00:35:20,610
about how we evict or remove
things from the cache.

954
00:35:20,610 --> 00:35:22,690
The usual behavior
for most caches

955
00:35:22,690 --> 00:35:24,569
is that when you access
a piece of data,

956
00:35:24,569 --> 00:35:26,169
if you have a cache, it'll put

957
00:35:26,169 --> 00:35:27,769
into the cache after
you access it.

958
00:35:27,769 --> 00:35:29,410
That's what generally happens.

959
00:35:29,410 --> 00:35:32,830
Now, I mean, there's some
weird scenarios like maybe

960
00:35:32,830 --> 00:35:34,370
the person writing the program

961
00:35:34,370 --> 00:35:36,549
knows that after
I read this file,

962
00:35:36,549 --> 00:35:39,389
I will definitely never
read it again, right?

963
00:35:39,389 --> 00:35:41,880
Like maybe I'm trying
to think of an example.

964
00:35:41,880 --> 00:35:45,470
Maybe this program
is reading a file,

965
00:35:45,470 --> 00:35:47,030
encrypting it and writing

966
00:35:47,030 --> 00:35:48,489
the encrypted data
somewhere else,

967
00:35:48,489 --> 00:35:50,649
and then deleting the
add encrypted data.

968
00:35:50,649 --> 00:35:52,510
It would be weird to cache

969
00:35:52,510 --> 00:35:55,110
the original file because
it's about to be deleted.

970
00:35:55,110 --> 00:35:57,750
And only the program knows
that. So there's like flags.

971
00:35:57,750 --> 00:35:59,609
Like for example, Lyx, if
you're reading a file,

972
00:35:59,609 --> 00:36:01,770
you can say, operate system,

973
00:36:01,770 --> 00:36:04,349
please don't cache
this because I know,

974
00:36:04,349 --> 00:36:06,769
for a fact, I won't need
it in the future, right?

975
00:36:06,769 --> 00:36:07,909
So there's ways you can do that.

976
00:36:07,909 --> 00:36:09,649
But the general behavior
kind of except for

977
00:36:09,649 --> 00:36:11,009
these weird exceptions
that when you

978
00:36:11,009 --> 00:36:13,049
touch something, you
bring in the cache.

979
00:36:13,049 --> 00:36:15,429
Alright, I've done
talking about that half.

980
00:36:15,429 --> 00:36:17,469
Let's talk about
this other half.

981
00:36:17,469 --> 00:36:20,129
If I break something into the
cache and the cash is full,

982
00:36:20,129 --> 00:36:21,809
I have to bup
something else out.

983
00:36:21,809 --> 00:36:24,069
I have to choose an entry to be

984
00:36:24,069 --> 00:36:27,774
the evictim that
gets evicted, right?

985
00:36:27,774 --> 00:36:31,220
One way is I can randomly
choose a victim.

986
00:36:31,220 --> 00:36:33,359
And there's actually
some important scenarios

987
00:36:33,359 --> 00:36:35,819
where that's actually like
a good decision, right?

988
00:36:35,819 --> 00:36:38,939
It seems stupid, but it
can actually outperform

989
00:36:38,939 --> 00:36:42,619
the so called smarter
policies in some situations.

990
00:36:42,619 --> 00:36:44,839
Here are a couple of other
ones that are commonly used.

991
00:36:44,839 --> 00:36:46,539
One is first and first out,

992
00:36:46,539 --> 00:36:49,619
and the other one is
least recently used.

993
00:36:49,619 --> 00:36:52,739
The idea here is that
with first and first out

994
00:36:52,739 --> 00:36:55,499
is that I look at all the
entries in the cache,

995
00:36:55,499 --> 00:36:57,079
and I know when they
were added to the cash,

996
00:36:57,079 --> 00:36:58,680
and whoever has been
in the cash logs,

997
00:36:58,680 --> 00:37:03,204
well it's that entries
turned to be removed, right?

998
00:37:03,204 --> 00:37:05,469
LRU maybe is a little bit

999
00:37:05,469 --> 00:37:07,789
more clever because
LRU will say.

1000
00:37:07,789 --> 00:37:09,389
It doesn't really matter

1001
00:37:09,389 --> 00:37:10,629
how long you've
been in the cash.

1002
00:37:10,629 --> 00:37:12,369
What really matters is,
when was the last time

1003
00:37:12,369 --> 00:37:14,029
somebody used this piece

1004
00:37:14,029 --> 00:37:15,789
of data that case
that would draw.

1005
00:37:15,789 --> 00:37:17,349
So they both have
subsets of, like,

1006
00:37:17,349 --> 00:37:18,689
older and newer data,

1007
00:37:18,689 --> 00:37:21,430
but they defined it a
little bit bit differently.

1008
00:37:21,430 --> 00:37:25,150
All right. Let's head over
and we'll do the worksheet.

1009
00:37:25,150 --> 00:37:31,469
And let me grab this. All right.

1010
00:37:31,510 --> 00:37:33,649
And hopefully you
have this if you

1011
00:37:33,649 --> 00:37:34,889
have a tablet that's site.

1012
00:37:34,889 --> 00:37:36,069
Otherwise you could just try to

1013
00:37:36,069 --> 00:37:38,509
write it out on paper as well.

1014
00:37:38,870 --> 00:37:41,449
What I will do with these
is a couple of things.

1015
00:37:41,449 --> 00:37:44,070
Usually, I draw out a
big box for my cache.

1016
00:37:44,070 --> 00:37:45,829
I'll usually label
it, like, what is

1017
00:37:45,829 --> 00:37:48,229
the policy and how much
space does it have?

1018
00:37:48,229 --> 00:37:50,829
I usually try to keep
trees ordered here,

1019
00:37:50,829 --> 00:37:52,250
so the more important

1020
00:37:52,250 --> 00:37:54,189
fresher data is on
the right hand side.

1021
00:37:54,189 --> 00:37:55,889
I rese it up here?

1022
00:37:55,889 --> 00:37:57,489
And the older stuff I might want

1023
00:37:57,489 --> 00:37:59,029
to evict is on the
left hand side.

1024
00:37:59,029 --> 00:38:00,930
You can imagine drawing
it differently.

1025
00:38:00,930 --> 00:38:02,690
And then I have a workload.

1026
00:38:02,690 --> 00:38:04,310
Over here, a workload

1027
00:38:04,310 --> 00:38:07,469
describes the series of
accesses I did, right?

1028
00:38:07,469 --> 00:38:09,629
So if a program

1029
00:38:09,629 --> 00:38:12,009
reads file one, and
then it reads file two,

1030
00:38:12,009 --> 00:38:14,249
and then it reads file
one again, and so on,

1031
00:38:14,249 --> 00:38:18,009
what I'm describing is the
workload of that program.

1032
00:38:18,009 --> 00:38:19,969
So I have a workload,
I have a cash.

1033
00:38:19,969 --> 00:38:22,769
And a common problem I might
give you is I might say,

1034
00:38:22,769 --> 00:38:26,169
tell me which ones will be
cash hits and which one

1035
00:38:26,169 --> 00:38:29,869
will be cash misses.
So let's do it.

1036
00:38:29,869 --> 00:38:32,529
So I'll put an X if it's a mess,

1037
00:38:32,529 --> 00:38:34,149
check if it's a hit.

1038
00:38:34,149 --> 00:38:36,089
So the first one always is

1039
00:38:36,089 --> 00:38:38,809
a mess because while
there's nothing here.

1040
00:38:38,809 --> 00:38:40,630
Okay, so I miss.

1041
00:38:40,630 --> 00:38:45,910
And then I add one to the
cache. Alright, Good.

1042
00:38:45,910 --> 00:38:49,709
Now I do two. To
also is not here,

1043
00:38:49,709 --> 00:38:51,770
so that's another mess.

1044
00:38:51,770 --> 00:38:55,709
And I add two to
the cache up here.

1045
00:38:55,750 --> 00:38:59,469
Now I have one,
and one is there.

1046
00:38:59,469 --> 00:39:02,489
Fantastic. I have a cash hit.

1047
00:39:02,489 --> 00:39:03,609
And I don't have to bring

1048
00:39:03,609 --> 00:39:05,909
anything in because
it's already there.

1049
00:39:06,020 --> 00:39:10,240
Now I have three,
which is a cash mess.

1050
00:39:10,240 --> 00:39:12,319
And if I want to bring

1051
00:39:12,319 --> 00:39:13,799
three in here, I have
to make room, right?

1052
00:39:13,799 --> 00:39:15,520
Because the cash can
only have two values,

1053
00:39:15,520 --> 00:39:16,960
and I already have two values.

1054
00:39:16,960 --> 00:39:18,600
So I have to choose a victim,

1055
00:39:18,600 --> 00:39:21,259
and my victim is one.

1056
00:39:21,259 --> 00:39:24,959
One was the first
number in the cash,

1057
00:39:24,959 --> 00:39:26,279
so one will be the
first number out.

1058
00:39:26,279 --> 00:39:28,320
First in, first out, FIFO.

1059
00:39:28,320 --> 00:39:30,619
So I may say goodbye one.

1060
00:39:30,619 --> 00:39:35,380
Hello. Three. Alright.
And that was actually

1061
00:39:35,380 --> 00:39:37,499
very unfortunate because
my very next one

1062
00:39:37,499 --> 00:39:39,919
that I do is another one, right?

1063
00:39:39,919 --> 00:39:42,680
So I have a mess because the
one's not there anymore.

1064
00:39:42,680 --> 00:39:45,104
And I have to bring one back in.

1065
00:39:45,104 --> 00:39:47,989
Of these two, two was
the first one in.

1066
00:39:47,989 --> 00:39:51,629
So it'll be the first one
out. And then one is back.

1067
00:39:51,629 --> 00:39:55,309
And so I had one.

1068
00:39:55,309 --> 00:39:56,729
One out of five was a hit.

1069
00:39:56,729 --> 00:40:01,889
So my hit rate is 1/5
equals 0.2. Hit rate.

1070
00:40:01,889 --> 00:40:03,609
So you can imagine so many
things I could ask you.

1071
00:40:03,609 --> 00:40:05,549
I could ask you,
after this thing,

1072
00:40:05,549 --> 00:40:07,169
what is the contents
of the cash?

1073
00:40:07,169 --> 00:40:09,269
I could ask you how
many hits are there?

1074
00:40:09,269 --> 00:40:11,049
I could ask you what
is the hit rate.

1075
00:40:11,049 --> 00:40:12,969
So much fun we could
have with this kind

1076
00:40:12,969 --> 00:40:14,969
of problem, right? All right.

1077
00:40:14,969 --> 00:40:18,430
Any questions about how to
solve that kind of problem?

1078
00:40:21,630 --> 00:40:24,629
All right. Let's do another one.

1079
00:40:24,629 --> 00:40:26,710
This is a similar problem.

1080
00:40:26,710 --> 00:40:28,449
We have a cache of size two

1081
00:40:28,449 --> 00:40:30,689
again. Here's the big
difference, right?

1082
00:40:30,689 --> 00:40:33,250
Before we were doing FIFO,
and we're using LRU.

1083
00:40:33,250 --> 00:40:34,509
We can have like the same space,

1084
00:40:34,509 --> 00:40:36,630
but we're going to use it
a little bit differently.

1085
00:40:36,630 --> 00:40:39,029
And then what about this
workload over here?

1086
00:40:39,029 --> 00:40:41,830
This is actually the
same workload as above.

1087
00:40:41,830 --> 00:40:44,349
But it has different
names, right?

1088
00:40:44,349 --> 00:40:46,290
So instead of 121, it's ABA.

1089
00:40:46,290 --> 00:40:48,349
I'm just try to show
you that, you know,

1090
00:40:48,349 --> 00:40:49,789
the cash entries
could have any kind

1091
00:40:49,789 --> 00:40:51,249
of description or key on them.

1092
00:40:51,249 --> 00:40:54,510
Alright. So let's do the
same workload as before,

1093
00:40:54,510 --> 00:40:57,910
but with an LRU and a
slightly different labeling.

1094
00:40:57,910 --> 00:41:00,230
Okay, so the first
one is always ass,

1095
00:41:00,230 --> 00:41:02,289
of course. So I have A.

1096
00:41:02,289 --> 00:41:06,709
Then I have B, which
is also a mess.

1097
00:41:07,670 --> 00:41:11,469
And now I have A,
which is a hit.

1098
00:41:13,550 --> 00:41:15,769
And this is the point

1099
00:41:15,769 --> 00:41:18,150
where we do something
different than FIFO.

1100
00:41:18,150 --> 00:41:21,510
FFO and LRU are very similar.

1101
00:41:21,550 --> 00:41:26,949
When you have a mess,
these two are the same.

1102
00:41:26,949 --> 00:41:28,549
But when you have a hit,

1103
00:41:28,549 --> 00:41:30,670
they do something a
little bit different.

1104
00:41:30,670 --> 00:41:33,209
At this point, we

1105
00:41:33,209 --> 00:41:34,949
use something that was
already in the ca A,

1106
00:41:34,949 --> 00:41:37,509
and we're like, Oh, well,
I recently used that.

1107
00:41:37,509 --> 00:41:39,109
A is important to me now.

1108
00:41:39,109 --> 00:41:41,494
And so we'll actually move A.

1109
00:41:41,494 --> 00:41:46,200
Over here, right? So when
we have a hit on an LRU,

1110
00:41:46,200 --> 00:41:48,739
you will change the
order priority of

1111
00:41:48,739 --> 00:41:51,199
these things. FIFO
doesn't do that.

1112
00:41:51,199 --> 00:41:55,099
FIFO doesn't do anything
smart when there's a hit.

1113
00:41:55,099 --> 00:41:58,399
Only when there's a mess,
right? Alright, so we do that.

1114
00:41:58,399 --> 00:42:02,350
And now we have C C is a mess,

1115
00:42:02,350 --> 00:42:04,249
and so we're going
to bump out B.

1116
00:42:04,249 --> 00:42:05,689
You can see that
this is a case where

1117
00:42:05,689 --> 00:42:07,429
FIFO would have ended
up evicting something

1118
00:42:07,429 --> 00:42:09,489
differently because
previously they

1119
00:42:09,489 --> 00:42:11,209
put those letters a little
bit differently, right?

1120
00:42:11,209 --> 00:42:15,510
So I'm going to bring
in C. And then finally,

1121
00:42:15,510 --> 00:42:18,249
we have A again, and A is a hit.

1122
00:42:18,249 --> 00:42:21,549
And then I'll just move
A over to this side.

1123
00:42:21,549 --> 00:42:28,690
And so now I have
2/5 hits equals 0.4.

1124
00:42:28,690 --> 00:42:30,389
You can see for the
same cash size,

1125
00:42:30,389 --> 00:42:31,989
different policies might be

1126
00:42:31,989 --> 00:42:34,589
better or worse than other ones.

1127
00:42:34,589 --> 00:42:36,469
Do people have any
questions about

1128
00:42:36,469 --> 00:42:39,729
FIFO or LRU. You got a
question right here?

1129
00:42:45,220 --> 00:42:48,679
Yeah, I, I spent a lot of,

1130
00:42:48,679 --> 00:42:51,439
we can look at We will
look at code soon,

1131
00:42:51,439 --> 00:42:52,259
but I was just thinking,

1132
00:42:52,259 --> 00:42:53,819
how can I do it on
pencil and paper?

1133
00:42:53,819 --> 00:42:56,040
I write with pens, and I
don't like erasing stuff.

1134
00:42:56,040 --> 00:42:58,919
So that's just how I
reorder things, right?

1135
00:42:58,919 --> 00:43:00,499
But I mean, Yeah,

1136
00:43:00,499 --> 00:43:02,539
somehow restructure it said,

1137
00:43:02,539 --> 00:43:03,839
like, this is higher
priority. Now.

1138
00:43:03,839 --> 00:43:04,959
You can imagine it like a list,

1139
00:43:04,959 --> 00:43:07,139
and maybe I just swap some
values around in the list.

1140
00:43:07,139 --> 00:43:09,019
There's lots of different
ways you could represent it.

1141
00:43:09,019 --> 00:43:10,479
But we have to have
some sense of, like,

1142
00:43:10,479 --> 00:43:13,120
which entries are kind
of higher priority

1143
00:43:13,120 --> 00:43:15,020
and which ones are
lower priority.

1144
00:43:15,020 --> 00:43:17,099
That make sense? Yeah,
thank you for asking.

1145
00:43:17,099 --> 00:43:19,279
Yeah other questions
people have.

1146
00:43:19,279 --> 00:43:23,559
Okay, so we have, like 7
minutes left. 6 minutes left.

1147
00:43:23,559 --> 00:43:24,899
And so for this one,

1148
00:43:24,899 --> 00:43:26,479
we're actually I might
make it into a top

1149
00:43:26,479 --> 00:43:29,339
at question where I
spend 5 minutes on it.

1150
00:43:29,460 --> 00:43:32,319
The question is might be,
what is the hip rate?

1151
00:43:32,319 --> 00:43:34,599
And so you'll work
through this on your own.

1152
00:43:34,599 --> 00:43:36,660
And then upload it to Canvas.

1153
00:43:36,660 --> 00:43:38,699
I'm not to Canvas. You'll
upload the top pat.

1154
00:43:38,699 --> 00:43:40,159
I'll leave this on here in case

1155
00:43:40,159 --> 00:43:41,380
people don't have
their worksheet,

1156
00:43:41,380 --> 00:43:42,879
and then I'll just
open up the top hat

1157
00:43:42,879 --> 00:43:44,559
on my computer. So do it.

1158
00:43:44,559 --> 00:43:48,439
You have 5 minutes,
then put on top pad.

1159
00:43:48,439 --> 00:43:49,559
And you can actually
if you want, you can

1160
00:43:49,559 --> 00:43:50,899
leave after you do the
top hat because we

1161
00:43:50,899 --> 00:43:54,200
won't have time to do
something, something else.

1162
00:43:54,200 --> 00:43:57,559
Yeah, there's a
question here. No.

1163
00:43:57,559 --> 00:44:00,699
Okay. Alright. Yeah, go ahead
and get started on that.

1164
00:44:00,699 --> 00:44:01,959
And I'll kind of, like, since

1165
00:44:01,959 --> 00:44:03,279
I'm not showing top
pat on my streen,

1166
00:44:03,279 --> 00:44:05,439
I'll be kind of shout
out when you have, like,

1167
00:44:05,439 --> 00:44:07,119
2 minutes left or
something like that,

1168
00:44:07,119 --> 00:44:09,419
but you'll have 5
minutes to do it.

1169
00:44:20,700 --> 00:44:23,339
Alright. Well, the
top pat is open,

1170
00:44:23,339 --> 00:44:24,579
just do it on your
worksheet and then

1171
00:44:24,579 --> 00:44:26,699
put it there when you're done.

1172
00:44:40,320 --> 00:44:43,400
Yeah, so you do it like
the zero point something.

1173
00:44:43,400 --> 00:44:45,640
I would be my preference.

1174
00:47:25,710 --> 00:47:29,509
T 2 minutes left to
submit the topic.

1175
00:48:23,300 --> 00:48:26,500
1 minute left, everybody.

1176
00:49:11,440 --> 00:49:13,619
All right, 10 seconds left.

1177
00:49:13,619 --> 00:49:14,799
So if you haven't
put something in,

1178
00:49:14,799 --> 00:49:17,219
just throw something in on top.

1179
00:49:17,219 --> 00:49:19,719
And we're kind of out of time,

1180
00:49:19,719 --> 00:49:22,580
so I'll just like
do this on Monday.

1181
00:49:22,580 --> 00:49:24,840
We'll kind of work through it
and talk about the answer.

1182
00:49:24,840 --> 00:49:27,480
Have a great weekend, everybody.
