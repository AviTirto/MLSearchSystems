1
00:00:00,000 --> 00:00:03,480
Coming today. We've been
learning about Map reduce.

2
00:00:03,480 --> 00:00:04,780
And just at the very
end of last time,

3
00:00:04,780 --> 00:00:07,940
we started transitioning to
Spark Spark solve some of

4
00:00:07,940 --> 00:00:09,440
the issues that MapReduce

5
00:00:09,440 --> 00:00:11,659
has specifically around
intermediate data.

6
00:00:11,659 --> 00:00:13,699
I'm going to start today by
doing just a little bit of

7
00:00:13,699 --> 00:00:17,300
review with Map reduce by
doing a top hat question,

8
00:00:17,300 --> 00:00:19,839
so you can starting your
phone out if you like.

9
00:00:19,839 --> 00:00:21,779
But basically,

10
00:00:21,779 --> 00:00:23,459
you can see there's not
much out here today,

11
00:00:23,459 --> 00:00:24,699
and that's because there's

12
00:00:24,699 --> 00:00:27,359
just a lot that really kind
of spans two lectures, right?

13
00:00:27,359 --> 00:00:29,060
So Aki flash charts cover both.

14
00:00:29,060 --> 00:00:32,739
And I may spend some time on
the slides from last time.

15
00:00:32,739 --> 00:00:36,340
Alright, cool. So I may
bring up this top hat first.

16
00:00:36,340 --> 00:00:38,959
So a question about Map reduce.

17
00:00:38,959 --> 00:00:42,639
And then we'll talk about that,

18
00:00:42,639 --> 00:00:45,320
and we'll try to jump
back into the content.

19
00:01:23,770 --> 00:01:27,209
About 3 seconds left.

20
00:02:01,400 --> 00:02:04,919
Alright, so people have a
variety of different answers.

21
00:02:04,919 --> 00:02:07,580
The most popular answer is X,

22
00:02:07,580 --> 00:02:08,980
which is actually correct.

23
00:02:08,980 --> 00:02:09,999
So one of the important things

24
00:02:09,999 --> 00:02:10,999
to remember here is that you are

25
00:02:10,999 --> 00:02:13,540
providing a map function
and a reduced function,

26
00:02:13,540 --> 00:02:16,100
each of which might
be called many times.

27
00:02:16,100 --> 00:02:19,539
That's not necessarily related
to how many R tasks are.

28
00:02:19,539 --> 00:02:23,160
A Sigle MAP task could
have a lot of calls.

29
00:02:23,160 --> 00:02:26,239
A SL reduced task could have
a lot of reduced calls.

30
00:02:26,239 --> 00:02:28,219
And so I really
interested, well,

31
00:02:28,219 --> 00:02:30,700
how many times is
reduce actually called,

32
00:02:30,700 --> 00:02:34,559
And that makes us remember
that it's not just Map reduce,

33
00:02:34,559 --> 00:02:37,120
but in between the bap
and the reducing phase,

34
00:02:37,120 --> 00:02:38,799
there's a shuffle phase.

35
00:02:38,799 --> 00:02:40,559
And shuffle, what it's really

36
00:02:40,559 --> 00:02:43,359
similar to in SQL is a group by.

37
00:02:43,359 --> 00:02:44,740
When we shuffle the data,

38
00:02:44,740 --> 00:02:46,960
we're bringing a bunch of
related data together.

39
00:02:46,960 --> 00:02:49,500
And so what happens
is these bappers

40
00:02:49,500 --> 00:02:52,040
are emitting a bunch
of keys and values,

41
00:02:52,040 --> 00:02:54,319
and then the shuffle
phase will bring

42
00:02:54,319 --> 00:02:57,379
together all the related
keys in the same place.

43
00:02:57,379 --> 00:02:59,559
And then all the related keys or

44
00:02:59,559 --> 00:03:01,380
the identical keys
are going to be

45
00:03:01,380 --> 00:03:04,359
passed in to a
single reduced call.

46
00:03:04,359 --> 00:03:06,959
People have any
questions about that?

47
00:03:09,710 --> 00:03:14,550
All right. Cool. So
we're gonna do one more.

48
00:03:14,550 --> 00:03:16,529
So my head over here.

49
00:03:16,529 --> 00:03:18,969
Just a moment. I saw
a bunch of people

50
00:03:18,969 --> 00:03:20,010
like run out the door as soon

51
00:03:20,010 --> 00:03:21,189
as they were done
with the top hat,

52
00:03:21,189 --> 00:03:25,790
so um, that makes me feel
like doing one more today.

53
00:03:28,790 --> 00:03:33,470
Oh, right. So it's time
a similar question,

54
00:03:33,470 --> 00:03:35,430
but now I'm asking
how many output files

55
00:03:35,430 --> 00:03:38,109
are going to be written to HDFS.

56
00:04:11,890 --> 00:04:15,329
About 30 seconds left.

57
00:04:49,360 --> 00:04:51,979
Alright, so the
most common answer

58
00:04:51,979 --> 00:04:53,819
is R, which is correct.

59
00:04:53,819 --> 00:04:56,659
If the data coming out of
the Mappers is quite large,

60
00:04:56,659 --> 00:04:58,420
we might need to have
many different reducers

61
00:04:58,420 --> 00:05:00,440
involved in processing.
Right? That's fine.

62
00:05:00,440 --> 00:05:01,820
We can choose many
reducers we want.

63
00:05:01,820 --> 00:05:04,760
We can have a very
distributed lots of reducers.

64
00:05:04,760 --> 00:05:07,700
And ultimately, those reducers
have to produce output.

65
00:05:07,700 --> 00:05:09,000
And you can imagine that if

66
00:05:09,000 --> 00:05:10,699
they were all working
together on the same

67
00:05:10,699 --> 00:05:12,199
Output file, we
then they'd have to

68
00:05:12,199 --> 00:05:14,139
coordinate and that would
become a bottleeneck.

69
00:05:14,139 --> 00:05:15,519
So each reducer gets to write

70
00:05:15,519 --> 00:05:17,579
its own HDFS file as output.

71
00:05:17,579 --> 00:05:19,879
If you really wanted to have
just one file of output,

72
00:05:19,879 --> 00:05:21,080
you'd be forced to
have one reducer,

73
00:05:21,080 --> 00:05:22,240
it wouldn't be very scalable.

74
00:05:22,240 --> 00:05:24,900
This doesn't mean that for
kind of large map reduc jobs,

75
00:05:24,900 --> 00:05:25,939
you're going to have
a bunch of files,

76
00:05:25,939 --> 00:05:28,200
and anything that's using
those, we'll have to

77
00:05:28,200 --> 00:05:29,780
somehow consider all of

78
00:05:29,780 --> 00:05:33,040
those output files. Any
questions about that one?

79
00:05:33,220 --> 00:05:37,280
Oh, right. Cool. So
I'm to exit that out,

80
00:05:37,280 --> 00:05:39,560
and we're ahead over here.

81
00:05:39,560 --> 00:05:42,279
And so we've been learning
about map reduce.

82
00:05:42,279 --> 00:05:44,099
And oftentimes you're
not just running

83
00:05:44,099 --> 00:05:46,140
one map reduced job, you're
running a chain of them.

84
00:05:46,140 --> 00:05:47,659
You have some kind
of data pipeline,

85
00:05:47,659 --> 00:05:51,279
and the first one will
persist a data on HDFS files,

86
00:05:51,279 --> 00:05:53,419
and the output from
one Mp reduced job

87
00:05:53,419 --> 00:05:55,800
will then be the input
to the next one, right?

88
00:05:55,800 --> 00:05:57,479
That's actual bytes of data.

89
00:05:57,479 --> 00:05:58,699
We actually have actual bytes

90
00:05:58,699 --> 00:05:59,819
of data for intermediate data.

91
00:05:59,819 --> 00:06:03,359
What I'm saying is that I'm
materializing that data.

92
00:06:03,359 --> 00:06:05,020
And we talked last time

93
00:06:05,020 --> 00:06:06,700
about some of the reasons
that's not super efficient.

94
00:06:06,700 --> 00:06:08,934
HDFS is just trying
to slow in general.

95
00:06:08,934 --> 00:06:11,769
And so that leads us to a
different design with Spark,

96
00:06:11,769 --> 00:06:14,550
which is more clever
about intermediate data.

97
00:06:14,550 --> 00:06:17,289
Instead of actually materializing
those bytes somewhere,

98
00:06:17,289 --> 00:06:20,009
there's an RDD, a resilient
distributed data set,

99
00:06:20,009 --> 00:06:22,210
and that's really just
like a recipe for how we

100
00:06:22,210 --> 00:06:25,730
could compute that data
on demand, if need be.

101
00:06:25,730 --> 00:06:27,650
Right? The key observation here

102
00:06:27,650 --> 00:06:29,650
is that we don't care what
the intermediate data is.

103
00:06:29,650 --> 00:06:31,349
We care about some
other end result.

104
00:06:31,349 --> 00:06:32,889
And so we shouldn't be spending

105
00:06:32,889 --> 00:06:35,090
extra work generating
data that we might not

106
00:06:35,090 --> 00:06:37,649
end up using or that
maybe in the end,

107
00:06:37,649 --> 00:06:39,430
we might have some
optimization tool that finds

108
00:06:39,430 --> 00:06:41,829
a better way to get
to the end result.

109
00:06:41,829 --> 00:06:43,870
So that's what RDDs do.

110
00:06:43,870 --> 00:06:46,209
Let me give you a
very concrete example

111
00:06:46,209 --> 00:06:48,155
of some RDDs in action.

112
00:06:48,155 --> 00:06:50,199
And so I have a little snippet

113
00:06:50,199 --> 00:06:54,179
of python code here that's
really driving spark.

114
00:06:54,179 --> 00:06:55,940
And I'm operating on
this table of data.

115
00:06:55,940 --> 00:06:57,420
It's really kind of
just a simple table

116
00:06:57,420 --> 00:06:58,919
of data where I have
a list of tuples.

117
00:06:58,919 --> 00:07:01,080
I'm imagining each
tuple is a row.

118
00:07:01,080 --> 00:07:02,879
And to get some results,

119
00:07:02,879 --> 00:07:04,660
there's various transformations
I might want to

120
00:07:04,660 --> 00:07:06,899
do on that input data.

121
00:07:06,899 --> 00:07:09,540
And these transformations
can often be done by

122
00:07:09,540 --> 00:07:12,660
writing functions of some
sort that do something.

123
00:07:12,660 --> 00:07:16,099
And so up here, I have two
just regular Python functions

124
00:07:16,099 --> 00:07:17,840
that are operating on this data.

125
00:07:17,840 --> 00:07:20,650
My goal is to get

126
00:07:20,650 --> 00:07:24,950
two times the number for
all the A rows, right?

127
00:07:24,950 --> 00:07:26,250
And so I ended up writing

128
00:07:26,250 --> 00:07:27,929
two functions to get
these two parts.

129
00:07:27,929 --> 00:07:29,770
The first one is multiply two,

130
00:07:29,770 --> 00:07:31,330
and it's going to take in a row,

131
00:07:31,330 --> 00:07:33,089
the row is going to be
one of these tuples.

132
00:07:33,089 --> 00:07:34,569
And then it's going
to return a tuple,

133
00:07:34,569 --> 00:07:36,289
which is a different row, right?

134
00:07:36,289 --> 00:07:39,050
The first value
in the output row

135
00:07:39,050 --> 00:07:40,330
is going to be the same as

136
00:07:40,330 --> 00:07:41,890
the first value
in the input row.

137
00:07:41,890 --> 00:07:44,430
And then the second value
and output put row will be

138
00:07:44,430 --> 00:07:47,030
two times that second
value in input row.

139
00:07:47,030 --> 00:07:49,235
Okay. Great. So I have
some functions like that.

140
00:07:49,235 --> 00:07:50,919
Other function that
might be used to

141
00:07:50,919 --> 00:07:52,920
process the data
returns a Boolean.

142
00:07:52,920 --> 00:07:54,040
That's really
useful if I want to

143
00:07:54,040 --> 00:07:55,440
filter the data in some way.

144
00:07:55,440 --> 00:07:57,459
So this function
only A is returning

145
00:07:57,459 --> 00:08:00,979
true for A rows and
false for other rows.

146
00:08:00,979 --> 00:08:04,240
So one way I can accomplish

147
00:08:04,240 --> 00:08:06,600
my goal is with these
four steps down here.

148
00:08:06,600 --> 00:08:08,820
I have four different
spark operations.

149
00:08:08,820 --> 00:08:10,519
The first one is parallelized.

150
00:08:10,519 --> 00:08:11,900
I takes some Python data

151
00:08:11,900 --> 00:08:14,320
and basically turns
it into arrow data.

152
00:08:14,320 --> 00:08:16,999
The next one is Map.

153
00:08:16,999 --> 00:08:19,239
So Map will call the
multiply two function

154
00:08:19,239 --> 00:08:20,879
on each of my four rows.

155
00:08:20,879 --> 00:08:22,500
I'll get double back, which is

156
00:08:22,500 --> 00:08:26,119
a four row resilient
distributed data set.

157
00:08:26,119 --> 00:08:29,540
Double dot filter
means I'm going

158
00:08:29,540 --> 00:08:31,239
to reduce those rows

159
00:08:31,239 --> 00:08:33,119
so that I only have
the ones where it's A,

160
00:08:33,119 --> 00:08:34,379
that will give me double A,

161
00:08:34,379 --> 00:08:35,740
that will be a resilient

162
00:08:35,740 --> 00:08:37,520
distribute dataset
with two rows.

163
00:08:37,520 --> 00:08:39,380
And then finally, I say collect.

164
00:08:39,380 --> 00:08:40,820
And what collect
does is it takes

165
00:08:40,820 --> 00:08:44,959
that arrow result and it brings
it back to Python for me,

166
00:08:44,959 --> 00:08:46,280
which will look
like this list of

167
00:08:46,280 --> 00:08:48,560
tuples over on the
right hand side here.

168
00:08:48,560 --> 00:08:51,220
And so I have these
four operations,

169
00:08:51,220 --> 00:08:55,219
and operations and Spark are
broadly in two categories.

170
00:08:55,219 --> 00:08:56,419
And it's really
important to remember

171
00:08:56,419 --> 00:08:57,620
these two categories because it

172
00:08:57,620 --> 00:09:00,620
has huge implications
for performance.

173
00:09:00,620 --> 00:09:04,260
One kind of operation
is a transformation.

174
00:09:04,260 --> 00:09:08,260
A transformation takes an
RDD and returns an RDD.

175
00:09:08,260 --> 00:09:09,799
And remember that an RDD is

176
00:09:09,799 --> 00:09:12,360
just a recipe to produce
the data on demand.

177
00:09:12,360 --> 00:09:13,640
So if I write a little piece

178
00:09:13,640 --> 00:09:15,159
of code that does
a transformation,

179
00:09:15,159 --> 00:09:17,540
no work actually
happens immediately.

180
00:09:17,540 --> 00:09:21,379
And the first few of these
are transformations, right?

181
00:09:21,379 --> 00:09:23,759
They all are giving
me back RDDs.

182
00:09:23,759 --> 00:09:26,554
And so there's no real
work being done there.

183
00:09:26,554 --> 00:09:28,490
When I want the real
world to happen at

184
00:09:28,490 --> 00:09:30,269
the very end, I say, collect.

185
00:09:30,269 --> 00:09:32,589
Collect is not a
transformation. It's an action.

186
00:09:32,589 --> 00:09:34,850
Actions are when
I say, I actually

187
00:09:34,850 --> 00:09:37,110
care about my final result.

188
00:09:37,110 --> 00:09:38,410
So this distinction between

189
00:09:38,410 --> 00:09:40,310
transformation and action
is how we distinguish

190
00:09:40,310 --> 00:09:42,269
between intermediate data and

191
00:09:42,269 --> 00:09:44,389
final results that we

192
00:09:44,389 --> 00:09:46,389
actually actually
care about, right?

193
00:09:46,389 --> 00:09:47,730
And when I actually
do the collect,

194
00:09:47,730 --> 00:09:49,049
that's when all the
multiplication and

195
00:09:49,049 --> 00:09:50,609
the filtering all
that will happen.

196
00:09:50,609 --> 00:09:51,849
It won't happen
where the line of

197
00:09:51,849 --> 00:09:54,070
code happens. Yeah, right here.

198
00:10:01,090 --> 00:10:04,589
You're saying right here
when I do table that map.

199
00:10:04,589 --> 00:10:08,470
So what this is doing is
it's returning an RDD.

200
00:10:08,470 --> 00:10:11,490
And so double if I looked at
the type of would be an RDD.

201
00:10:11,490 --> 00:10:14,389
And internally, what
it will be saying is,

202
00:10:14,389 --> 00:10:16,049
these are the steps
that would be

203
00:10:16,049 --> 00:10:17,829
necessary to get this data,

204
00:10:17,829 --> 00:10:19,229
but it doesn't actually do any

205
00:10:19,229 --> 00:10:20,649
work at the moment I run this.

206
00:10:20,649 --> 00:10:22,729
It just says it just
remembers, Well,

207
00:10:22,729 --> 00:10:25,309
here's how we could get that
result if we wanted to.

208
00:10:25,309 --> 00:10:26,030
That makes sense?

209
00:10:26,030 --> 00:10:27,749
Yeah, there's another
question right here.

210
00:10:27,749 --> 00:10:30,770
How is this faster than actually

211
00:10:35,220 --> 00:10:37,279
Yeah, that's an
excellent question.

212
00:10:37,279 --> 00:10:38,440
Why is it fast why is it

213
00:10:38,440 --> 00:10:40,159
faster to do it
instead of eagerly?

214
00:10:40,159 --> 00:10:41,380
Yeah, I'll come back to that.

215
00:10:41,380 --> 00:10:42,939
There's a couple of ways
that's going to be faster.

216
00:10:42,939 --> 00:10:44,019
Yeah.

217
00:10:54,180 --> 00:10:55,599
Yeah, Yeah.

218
00:10:55,599 --> 00:10:58,219
You're asking I guess that
was be my very next question,

219
00:10:58,219 --> 00:10:59,579
which you kind of
just answered, right?

220
00:10:59,579 --> 00:11:02,059
So when we're looking
at this, right?

221
00:11:02,059 --> 00:11:03,360
Are there alternate
paths? And you said,

222
00:11:03,360 --> 00:11:05,579
what would be the
faster way to do it?

223
00:11:08,780 --> 00:11:18,139
Hm. Like, could it reorder them?

224
00:11:18,139 --> 00:11:20,359
Yeah. And so, first off,

225
00:11:20,359 --> 00:11:21,619
before I talk about
what it does,

226
00:11:21,619 --> 00:11:22,859
let's just talk about what it

227
00:11:22,859 --> 00:11:24,619
could do hypothetically, right?

228
00:11:24,619 --> 00:11:27,200
There's another way to
get the same end result.

229
00:11:27,200 --> 00:11:29,360
And presumably this
other way is faster.

230
00:11:29,360 --> 00:11:31,140
I mean, honestly, it
feels a little wasteful

231
00:11:31,140 --> 00:11:33,140
if I have a whole
bunch of numbers,

232
00:11:33,140 --> 00:11:34,659
and I multiply them all by two,

233
00:11:34,659 --> 00:11:36,820
and then I throw away
a lot of the roads.

234
00:11:36,820 --> 00:11:37,280
Why did I do

235
00:11:37,280 --> 00:11:39,019
all that multiplication when
I didn't care what it was?

236
00:11:39,019 --> 00:11:40,740
I should have filtered before

237
00:11:40,740 --> 00:11:42,429
I multiply We could
totally do that,

238
00:11:42,429 --> 00:11:44,150
we could do filter and then map,

239
00:11:44,150 --> 00:11:46,970
and we would have ended
up with the same result.

240
00:11:46,970 --> 00:11:49,109
And so by distinguishing
between these,

241
00:11:49,109 --> 00:11:51,109
these transformations
versus actions,

242
00:11:51,109 --> 00:11:52,649
it gives an opportunity for

243
00:11:52,649 --> 00:11:54,910
an optimizer to come
along and find,

244
00:11:54,910 --> 00:11:58,110
Okay, here's a faster way
to get the same result.

245
00:11:58,110 --> 00:11:59,750
Now, in this very
particular case

246
00:11:59,750 --> 00:12:01,289
is an optimizer
going to do that?

247
00:12:01,289 --> 00:12:02,909
And the answer is no.

248
00:12:02,909 --> 00:12:05,269
And the reason that the
optimizer does not do it is

249
00:12:05,269 --> 00:12:08,109
the optimizer would have
to understand Python code.

250
00:12:08,109 --> 00:12:11,050
And it's very hard to
write a tool that reads

251
00:12:11,050 --> 00:12:13,050
some Python code and understands

252
00:12:13,050 --> 00:12:15,289
when it's okay to
switch the order of it.

253
00:12:15,289 --> 00:12:17,320
So here, It wouldn't
be optimized.

254
00:12:17,320 --> 00:12:19,379
In other cases, it will be.
And the reason we'll be in

255
00:12:19,379 --> 00:12:20,879
other cases is that instead of

256
00:12:20,879 --> 00:12:22,699
writing all these lines
of codes ourselves,

257
00:12:22,699 --> 00:12:24,279
what we'll typically
be doing is we'll

258
00:12:24,279 --> 00:12:26,199
be writing something
in Spark equil and

259
00:12:26,199 --> 00:12:27,639
the Spark sequel is going to get

260
00:12:27,639 --> 00:12:30,120
translated to these
transformations and actions.

261
00:12:30,120 --> 00:12:31,540
And in those cases, each of

262
00:12:31,540 --> 00:12:33,720
these transformations
is very well defined.

263
00:12:33,720 --> 00:12:35,339
There's not an opportunity
for me to slip in

264
00:12:35,339 --> 00:12:36,259
some type of function that has

265
00:12:36,259 --> 00:12:37,519
something a little bit strange.

266
00:12:37,519 --> 00:12:38,980
And so in those cases,

267
00:12:38,980 --> 00:12:40,979
an optimizer tran trim
along and see, Okay,

268
00:12:40,979 --> 00:12:43,240
there's a different way to
get to the same result.

269
00:12:43,240 --> 00:12:43,999
So here it we'll not,

270
00:12:43,999 --> 00:12:45,479
even though there's
an opportunity to.

271
00:12:45,479 --> 00:12:47,939
In other cases, an
optimizer will absolutely

272
00:12:47,939 --> 00:12:49,580
maybe do something
in a different order

273
00:12:49,580 --> 00:12:51,105
or maybe skip some step.

274
00:12:51,105 --> 00:12:52,929
Maybe even add some steps that

275
00:12:52,929 --> 00:12:55,010
help us filter sooner
rather than later.

276
00:12:55,010 --> 00:12:57,449
Absolutely. So when we
distinguish between

277
00:12:57,449 --> 00:12:59,490
intermediate data and final data

278
00:12:59,490 --> 00:13:01,530
via transformations
versus actions,

279
00:13:01,530 --> 00:13:03,330
that absolutely
creates an opportunity

280
00:13:03,330 --> 00:13:04,809
for optimizers to step in.

281
00:13:04,809 --> 00:13:06,649
And hopefully that
answers the question.

282
00:13:06,649 --> 00:13:09,110
Yeah, Yeah, another
question right here.

283
00:13:13,060 --> 00:13:17,519
No. Yeah. So to clear that,

284
00:13:17,519 --> 00:13:18,840
it doesn't know that
it's not dependent.

285
00:13:18,840 --> 00:13:21,719
The way I would
say it is that if

286
00:13:21,719 --> 00:13:24,219
you have two steps and you
understand what the steps are,

287
00:13:24,219 --> 00:13:27,100
you as a human can see,
sometimes it's okay to switch,

288
00:13:27,100 --> 00:13:28,919
and sometimes it's not, right?

289
00:13:28,919 --> 00:13:31,719
And here, to actually
understand that,

290
00:13:31,719 --> 00:13:32,939
any kind of tool would have to

291
00:13:32,939 --> 00:13:35,019
understand the
Python rode, right?

292
00:13:35,019 --> 00:13:36,840
So when our transformations are

293
00:13:36,840 --> 00:13:38,779
based on kind of arbitrary
Python functions,

294
00:13:38,779 --> 00:13:40,779
an optimizer isn't going
to know to do with that.

295
00:13:40,779 --> 00:13:43,400
But a lot of the transformations
that Spark is doing,

296
00:13:43,400 --> 00:13:45,559
it's not just some
arbitrary Python function.

297
00:13:45,559 --> 00:13:48,560
It's like a very
well defined step,

298
00:13:48,560 --> 00:13:50,860
and then it can be smart
enough to see that k,

299
00:13:50,860 --> 00:13:52,299
it's safe to do
this, and so' get

300
00:13:52,299 --> 00:13:54,160
the same result.
That makes sense.

301
00:13:54,160 --> 00:13:55,719
Yeah. There are other
questions people have

302
00:13:55,719 --> 00:13:58,364
about these transformations
and actions.

303
00:13:58,364 --> 00:14:02,609
Oh, right. So that's

304
00:14:02,609 --> 00:14:03,949
one opportunity where we have

305
00:14:03,949 --> 00:14:06,390
an opportunity to be
faster by being lazy.

306
00:14:06,390 --> 00:14:08,429
And Ao has to do
with the granularity

307
00:14:08,429 --> 00:14:10,089
at which we do this, right?

308
00:14:10,089 --> 00:14:12,830
So I have all these
stages in the pipeline,

309
00:14:12,830 --> 00:14:14,630
and I have a bunch of
rows at the beginning.

310
00:14:14,630 --> 00:14:16,769
And you can imagine different
ways I could do it.

311
00:14:16,769 --> 00:14:19,669
I could take one row
of data and sve it

312
00:14:19,669 --> 00:14:21,050
in the pipeline and then

313
00:14:21,050 --> 00:14:22,570
see what pops out
the other side.

314
00:14:22,570 --> 00:14:24,250
Maybe a row pops
out, maybe nothing

315
00:14:24,250 --> 00:14:26,050
pops out because
maybe I got filtered,

316
00:14:26,050 --> 00:14:26,929
but I could just start

317
00:14:26,929 --> 00:14:28,349
sending rows through
one at a time.

318
00:14:28,349 --> 00:14:29,610
I could also take

319
00:14:29,610 --> 00:14:32,070
my whole dataset if I wanted
and try to chunk it along,

320
00:14:32,070 --> 00:14:33,450
like, you know, the whole data

321
00:14:33,450 --> 00:14:34,895
set could drow step by step.

322
00:14:34,895 --> 00:14:38,019
Um, both of those have
some disadvantages, right?

323
00:14:38,019 --> 00:14:39,859
I think that the
disadvantage of having

324
00:14:39,859 --> 00:14:42,039
the whole data set is that
maybe it's quite large.

325
00:14:42,039 --> 00:14:43,680
I don't want to have
the whole dataset

326
00:14:43,680 --> 00:14:45,639
in memory at the same time.

327
00:14:45,639 --> 00:14:47,979
On the flip of it, if I
send one brow at a time,

328
00:14:47,979 --> 00:14:50,380
then there's this overhead
of kind of like spending

329
00:14:50,380 --> 00:14:52,960
up a task to process it for
a stage in the pipeline,

330
00:14:52,960 --> 00:14:54,180
so that won't be very efficient.

331
00:14:54,180 --> 00:14:56,739
And so what Spark actually
does is something in between,

332
00:14:56,739 --> 00:14:58,180
one brow and the whole dataset.

333
00:14:58,180 --> 00:15:00,299
And what it does in
between is a partition.

334
00:15:00,299 --> 00:15:04,229
And we have some control
over the partition size.

335
00:15:04,229 --> 00:15:07,249
So you can see down here when
I did SC dot parallelize,

336
00:15:07,249 --> 00:15:09,910
I pass in my list of
tuples, which is data,

337
00:15:09,910 --> 00:15:11,370
and I could say I
want one partition,

338
00:15:11,370 --> 00:15:12,790
or maybe I want two partitions.

339
00:15:12,790 --> 00:15:14,790
By the way, SC stands
for Spark context.

340
00:15:14,790 --> 00:15:16,649
I'm may be showing
that again later to

341
00:15:16,649 --> 00:15:19,149
the common name for a
Spark context variable.

342
00:15:19,149 --> 00:15:22,050
And so I could do that. I
could choose what granularity

343
00:15:22,050 --> 00:15:25,269
I want to pass pass
my data through.

344
00:15:25,269 --> 00:15:27,250
Okay. Why does that matter?

345
00:15:27,250 --> 00:15:29,510
These partitions?
So A RDD I look at,

346
00:15:29,510 --> 00:15:32,274
I can see how many partitions
are there for this RDD,

347
00:15:32,274 --> 00:15:34,600
Work gets done and spark at

348
00:15:34,600 --> 00:15:36,740
the granularity of
something called a task.

349
00:15:36,740 --> 00:15:39,060
And a task brings
two things together.

350
00:15:39,060 --> 00:15:41,780
A task runs on
exactly one CPU core

351
00:15:41,780 --> 00:15:44,620
and operates on
exactly one partition.

352
00:15:44,620 --> 00:15:48,199
And so if I have twice
as many partitions,

353
00:15:48,199 --> 00:15:51,299
I'm going to have twice
as many tasks, right?

354
00:15:51,299 --> 00:15:54,300
And so when you're choosing
the partition count,

355
00:15:54,300 --> 00:15:55,980
you're going to be
directly choosing

356
00:15:55,980 --> 00:15:57,620
the task count as a result,

357
00:15:57,620 --> 00:16:01,039
and that has some big
performance implications.

358
00:16:01,039 --> 00:16:04,780
So if I have larger
partitions, well,

359
00:16:04,780 --> 00:16:07,180
that means I have fewer tasks

360
00:16:07,180 --> 00:16:09,720
and less overhead for
starting those tasks.

361
00:16:09,720 --> 00:16:12,280
It's kind of slow, it's like
starting up a java process.

362
00:16:12,280 --> 00:16:15,679
What are some disadvantages
of having larger partitions?

363
00:16:15,679 --> 00:16:19,769
Um Maybe maybe I
have ten machines,

364
00:16:19,769 --> 00:16:21,310
and they each have 20 cores.

365
00:16:21,310 --> 00:16:23,970
That means I have 20
cores in my cluster.

366
00:16:23,970 --> 00:16:26,909
I could be running 200
tasks at the same time.

367
00:16:26,909 --> 00:16:28,950
If I don't have at
least 200 partitions,

368
00:16:28,950 --> 00:16:31,109
I can't use my whole
cluster, right?

369
00:16:31,109 --> 00:16:32,369
So I might need to have

370
00:16:32,369 --> 00:16:35,569
smaller partitions so that I
could use the whole cluster.

371
00:16:35,569 --> 00:16:38,249
It's a little harder to
balance work evenly, right?

372
00:16:38,249 --> 00:16:40,490
If I have lots of partitions,

373
00:16:40,490 --> 00:16:41,890
maybe some of them
are heavier than

374
00:16:41,890 --> 00:16:43,309
others. I can kind
of balance them.

375
00:16:43,309 --> 00:16:45,430
If I have big chunks of work,
it's hard to make sure that

376
00:16:45,430 --> 00:16:47,629
all the workers are getting
the same amount of work.

377
00:16:47,629 --> 00:16:48,709
And then finally, this is

378
00:16:48,709 --> 00:16:50,029
probably the most important one.

379
00:16:50,029 --> 00:16:52,769
How much memory am I using
at any given point in time?

380
00:16:52,769 --> 00:16:54,790
Whenever we're operating
on a partition,

381
00:16:54,790 --> 00:16:57,390
that entire partition is memory.

382
00:16:57,390 --> 00:16:58,849
Some people say that Spark is

383
00:16:58,849 --> 00:17:01,090
an in memory analytics platform,

384
00:17:01,090 --> 00:17:02,930
and that's true,
but that doesn't

385
00:17:02,930 --> 00:17:05,289
mean that all data is in
memory at the same time.

386
00:17:05,289 --> 00:17:06,710
What it means is that when we're

387
00:17:06,710 --> 00:17:08,390
operating on these
partitions of data,

388
00:17:08,390 --> 00:17:10,449
all partition of data will

389
00:17:10,449 --> 00:17:12,989
be in memory while
we're operating on it.

390
00:17:12,989 --> 00:17:14,449
Alright, so you're
going to have to

391
00:17:14,449 --> 00:17:16,529
figure out how to tune
this a little bit.

392
00:17:16,529 --> 00:17:20,079
And and By default, right?

393
00:17:20,079 --> 00:17:21,840
If I don't say, Spark
will try to choose.

394
00:17:21,840 --> 00:17:24,219
It might look at how many
CPs I have in my cluster,

395
00:17:24,219 --> 00:17:25,339
how much memory, how

396
00:17:25,339 --> 00:17:26,800
big the data is,
it'll try to choose.

397
00:17:26,800 --> 00:17:27,999
It doesn't always choose right.

398
00:17:27,999 --> 00:17:29,139
And so that's why you might have

399
00:17:29,139 --> 00:17:30,499
to come in and set it, right?

400
00:17:30,499 --> 00:17:32,880
It would be kind of a finicky
thing to choose correctly.

401
00:17:32,880 --> 00:17:34,499
So I want you to
be able to observe

402
00:17:34,499 --> 00:17:36,699
different problems and
then correct it, right?

403
00:17:36,699 --> 00:17:39,119
If if you're doing
some spark job and

404
00:17:39,119 --> 00:17:41,860
you're running out of memory,
try smaller partitions.

405
00:17:41,860 --> 00:17:44,619
Smaller partitions means
more partitions, right?

406
00:17:44,619 --> 00:17:47,460
If you have a large cluster
and you're not really

407
00:17:47,460 --> 00:17:50,139
utilizing all the
cores in your cluster,

408
00:17:50,139 --> 00:17:53,079
I'll maybe try more
partitions, right?

409
00:17:53,079 --> 00:17:55,719
It's kind of a piniky thing
that you have to get right.

410
00:17:55,719 --> 00:17:59,969
Alright. Any questions about

411
00:17:59,969 --> 00:18:04,049
tasks or this idea of partition
size? Yeah, right here.

412
00:18:04,049 --> 00:18:09,609
Get to Yeah.

413
00:18:09,609 --> 00:18:11,770
So if you choose way
too many partitions,

414
00:18:11,770 --> 00:18:14,070
then each partition is going
to correspond to a task,

415
00:18:14,070 --> 00:18:16,269
which is starting like
some kind of Java process.

416
00:18:16,269 --> 00:18:19,169
And so, like if I
had one partition

417
00:18:19,169 --> 00:18:21,009
for every row would
be kind of extreme,

418
00:18:21,009 --> 00:18:23,009
then I would have to start up

419
00:18:23,009 --> 00:18:25,949
a whole Java process
to analyze one row,

420
00:18:25,949 --> 00:18:28,609
which is the start up cost is

421
00:18:28,609 --> 00:18:31,250
going to be much greater than
the actual analysis cost.

422
00:18:31,250 --> 00:18:32,429
So that's why we
don't want to go too

423
00:18:32,429 --> 00:18:34,210
extreme in that
direction. Makes sense?

424
00:18:34,210 --> 00:18:36,029
Yeah, a great question.
Other questions

425
00:18:36,029 --> 00:18:38,979
people have. All right.

426
00:18:38,979 --> 00:18:41,159
So sometimes, as
we're doing this,

427
00:18:41,159 --> 00:18:42,820
we might have to be intentional

428
00:18:42,820 --> 00:18:45,140
about changing the
partition count.

429
00:18:45,140 --> 00:18:47,940
I think a very common scenario
is that we might start

430
00:18:47,940 --> 00:18:51,000
with a very large
dataset, four rows.

431
00:18:51,000 --> 00:18:53,059
A, that's not that large,
but let's pretend it is.

432
00:18:53,059 --> 00:18:54,739
And we might filter it down.

433
00:18:54,739 --> 00:18:56,579
Maybe the filter,
if it's restrictive

434
00:18:56,579 --> 00:19:00,300
might output 10% of
the original rows.

435
00:19:00,300 --> 00:19:02,419
And so the number of partitions

436
00:19:02,419 --> 00:19:04,780
that's good for
the original data

437
00:19:04,780 --> 00:19:06,739
or the original RDD might not

438
00:19:06,739 --> 00:19:09,700
be good for something
downstream.

439
00:19:09,700 --> 00:19:11,899
Okay. By default, what Spark is

440
00:19:11,899 --> 00:19:14,620
going to do is at each step,

441
00:19:14,620 --> 00:19:16,339
it's trying to keep
the same number

442
00:19:16,339 --> 00:19:19,079
of partitions. Why is that?

443
00:19:19,079 --> 00:19:20,939
Well, Spark is trying to

444
00:19:20,939 --> 00:19:23,319
avoid sending data over
the network, right?

445
00:19:23,319 --> 00:19:25,500
And if I have kind of
like a long chain,

446
00:19:25,500 --> 00:19:28,799
long, simple chain of
partitions, right?

447
00:19:28,799 --> 00:19:30,319
We just like one flows to one,

448
00:19:30,319 --> 00:19:32,319
then I can put all of
those on the same machine.

449
00:19:32,319 --> 00:19:35,500
I can schedule all the tasks
for that chain in one place,

450
00:19:35,500 --> 00:19:36,480
and I don't have to be sending

451
00:19:36,480 --> 00:19:39,149
data over the network, right?

452
00:19:39,149 --> 00:19:42,299
If I'm somehow changing the
partition count, right?

453
00:19:42,299 --> 00:19:43,500
Maybe I have my data spread

454
00:19:43,500 --> 00:19:45,279
across partitions that are
on many different machines,

455
00:19:45,279 --> 00:19:46,699
maybe it's like 100
different machines,

456
00:19:46,699 --> 00:19:47,699
each with one partition.

457
00:19:47,699 --> 00:19:48,900
If I want to shrink that down

458
00:19:48,900 --> 00:19:50,059
into ten big partitions, well,

459
00:19:50,059 --> 00:19:52,639
I'm going to have to set a
lot of data over the network.

460
00:19:52,639 --> 00:19:54,039
Maybe it's worth
and maybe it's not.

461
00:19:54,039 --> 00:19:55,959
So if you have a resilient
distributed data set,

462
00:19:55,959 --> 00:19:58,019
you can just say, get some
partitions to see what it is.

463
00:19:58,019 --> 00:19:58,899
And then you could do

464
00:19:58,899 --> 00:20:00,780
a different resilient
distributed data

465
00:20:00,780 --> 00:20:02,959
set by saying RDD
dot repartition,

466
00:20:02,959 --> 00:20:04,280
and you say some count.

467
00:20:04,280 --> 00:20:05,040
This is a transformation.

468
00:20:05,040 --> 00:20:06,340
Sometime I do
anything right away.

469
00:20:06,340 --> 00:20:08,619
But then if I do some
calculations on RDD,

470
00:20:08,619 --> 00:20:10,759
it's going to involve
that coalescing data from

471
00:20:10,759 --> 00:20:14,239
all these places into
relatively fewer places, right?

472
00:20:14,239 --> 00:20:15,079
In this case here when I'm

473
00:20:15,079 --> 00:20:16,500
filtering down might
be a classic case.

474
00:20:16,500 --> 00:20:17,699
There's a couple of
ways I could do it.

475
00:20:17,699 --> 00:20:19,719
I could let it alone, right?

476
00:20:19,719 --> 00:20:20,960
And after the filter, I could

477
00:20:20,960 --> 00:20:22,300
cheat the same number
of partitions.

478
00:20:22,300 --> 00:20:24,379
Or in this case, I could
observe, hey, after the filter,

479
00:20:24,379 --> 00:20:26,199
I don't have so
many, maybe I want

480
00:20:26,199 --> 00:20:28,699
to repartition it. That's
an investment, right?

481
00:20:28,699 --> 00:20:29,539
Because there's a cost of

482
00:20:29,539 --> 00:20:30,940
shuffle of the data
into one place.

483
00:20:30,940 --> 00:20:32,399
But then after that,
everything will be

484
00:20:32,399 --> 00:20:34,559
faster because I won't have
to start as many tasks,

485
00:20:34,559 --> 00:20:36,780
and starting tasks as slow.

486
00:20:36,780 --> 00:20:39,979
Do we have any questions
about repartitioning?

487
00:20:41,540 --> 00:20:47,199
Oh, right. There are
other scenarios.

488
00:20:47,199 --> 00:20:48,340
So repartition is one case

489
00:20:48,340 --> 00:20:49,839
where I send data
over the network.

490
00:20:49,839 --> 00:20:51,299
Another case might be

491
00:20:51,299 --> 00:20:53,039
for certain kinds
of transformation.

492
00:20:53,039 --> 00:20:56,100
So we already said, Okay,
everything is an operation.

493
00:20:56,100 --> 00:20:59,459
Operations are either
actions that give us data

494
00:20:59,459 --> 00:21:01,639
or transformations
that just define

495
00:21:01,639 --> 00:21:04,159
a new RDD in terms of other RDs.

496
00:21:04,159 --> 00:21:06,760
Transformations have
two sub categories.

497
00:21:06,760 --> 00:21:09,100
They can either be
narrow or wide.

498
00:21:09,100 --> 00:21:11,339
And basically, I've been
showing you a bunch of

499
00:21:11,339 --> 00:21:14,539
narrow transformations so far.

500
00:21:14,539 --> 00:21:15,780
A narrow transformation means

501
00:21:15,780 --> 00:21:17,119
that I have one
partition coming in,

502
00:21:17,119 --> 00:21:19,719
and then one corresponding
partition coming out.

503
00:21:19,719 --> 00:21:22,619
There's a question right
here? Nope. All right.

504
00:21:22,619 --> 00:21:23,960
And so I can see on the left

505
00:21:23,960 --> 00:21:25,160
hand side when I'm filtering,

506
00:21:25,160 --> 00:21:27,199
one N one out, that's
a narrow partition.

507
00:21:27,199 --> 00:21:28,879
Some things just I can do that.

508
00:21:28,879 --> 00:21:30,619
So, for example, if I wanted

509
00:21:30,619 --> 00:21:33,140
to take some input
rows and then order,

510
00:21:33,140 --> 00:21:34,839
like, I want to sort
by some column,

511
00:21:34,839 --> 00:21:37,000
that's going to be
a wide partition.

512
00:21:37,000 --> 00:21:39,420
Why? Well, my original
data was ABAB.

513
00:21:39,420 --> 00:21:41,480
I wanted to sort
it, so it's A ABB.

514
00:21:41,480 --> 00:21:43,539
And so the first two
are going to go to

515
00:21:43,539 --> 00:21:45,740
one partition and the BB,
are going to go to another.

516
00:21:45,740 --> 00:21:49,309
Each of these is pulling
from two different sources.

517
00:21:49,309 --> 00:21:51,339
Um, if you're lucky,

518
00:21:51,339 --> 00:21:54,139
right, this might not
involve network io.

519
00:21:54,139 --> 00:21:56,039
I mean, it's possible,
right that both of

520
00:21:56,039 --> 00:22:00,500
the input partitions happen
to be on the same computer,

521
00:22:00,500 --> 00:22:02,600
in which case, I can
do the two output ones

522
00:22:02,600 --> 00:22:03,979
without doing network iO.

523
00:22:03,979 --> 00:22:05,419
But in general, right,

524
00:22:05,419 --> 00:22:07,519
partitions are going to
be on different machines,

525
00:22:07,519 --> 00:22:10,479
and this will involve sending
some data over the network.

526
00:22:10,479 --> 00:22:12,359
Right? I want you
to start to look at

527
00:22:12,359 --> 00:22:13,560
these different
things and see things

528
00:22:13,560 --> 00:22:15,219
that might be slow, right?

529
00:22:15,219 --> 00:22:16,819
If you have a large
number of partitions.

530
00:22:16,819 --> 00:22:19,109
Maybe you have to worry
about how many tasks are

531
00:22:19,109 --> 00:22:23,170
starting if you're having
wide transformations?

532
00:22:23,170 --> 00:22:24,289
Maybe you have to
worry about there

533
00:22:24,289 --> 00:22:26,849
being some network IO, right?

534
00:22:26,849 --> 00:22:28,629
These are different
things that might

535
00:22:28,629 --> 00:22:30,630
arise as you're
working in this space.

536
00:22:30,630 --> 00:22:33,309
If I have an action that
collects all my data together,

537
00:22:33,309 --> 00:22:35,349
maybe everything was fine
before the action right,

538
00:22:35,349 --> 00:22:36,470
maybe I might have a lot of data

539
00:22:36,470 --> 00:22:37,729
spread across
different machines.

540
00:22:37,729 --> 00:22:39,150
Once I do that action,
maybe it brings

541
00:22:39,150 --> 00:22:41,610
all the data together
in one place.

542
00:22:41,610 --> 00:22:43,610
Any questions about
these different kinds

543
00:22:43,610 --> 00:22:46,049
of transformations?

544
00:22:54,630 --> 00:22:57,709
All right. Let's talk about
another thing that's going to

545
00:22:57,709 --> 00:23:00,229
be critical to performance,
which is caching.

546
00:23:00,229 --> 00:23:03,170
And so I'm going to imagine
a concrete example here.

547
00:23:03,170 --> 00:23:04,989
Let's say I have weather data

548
00:23:04,989 --> 00:23:07,030
from weather stations
all across the world,

549
00:23:07,030 --> 00:23:08,749
but I specifically want to do

550
00:23:08,749 --> 00:23:10,749
a study of weather in Wisconsin.

551
00:23:10,749 --> 00:23:12,849
And so there's different
things I might do.

552
00:23:12,849 --> 00:23:15,470
I think that maybe
in my first test,

553
00:23:15,470 --> 00:23:17,330
I might filter down
to Wisconsin data,

554
00:23:17,330 --> 00:23:18,690
I might do some other
transformations,

555
00:23:18,690 --> 00:23:19,809
and then in the end,

556
00:23:19,809 --> 00:23:23,044
I might pull out an average
temperature for Wisconsin.

557
00:23:23,044 --> 00:23:25,920
Maybe I want to get the
rainfall in Madison.

558
00:23:25,920 --> 00:23:28,260
Maybe that involves
filtering down to Wisconsin,

559
00:23:28,260 --> 00:23:29,580
maybe filtering down to Madison

560
00:23:29,580 --> 00:23:31,580
further and then
getting rainfall.

561
00:23:31,580 --> 00:23:33,160
Each of these RDZDs,

562
00:23:33,160 --> 00:23:34,859
you can see it's
just a chain, right?

563
00:23:34,859 --> 00:23:36,420
But these different
chains I have might

564
00:23:36,420 --> 00:23:38,080
have a common source of data,

565
00:23:38,080 --> 00:23:39,579
which is maybe some
file somewhere with

566
00:23:39,579 --> 00:23:41,500
weather data from all
across the world.

567
00:23:41,500 --> 00:23:43,679
And so if I just do
this naively and I

568
00:23:43,679 --> 00:23:45,990
run each of these
three jobs, Well,

569
00:23:45,990 --> 00:23:47,569
what's unfortunate is that

570
00:23:47,569 --> 00:23:49,310
each time I do a
new computation,

571
00:23:49,310 --> 00:23:52,250
it's try to refilter all
of the data in the world.

572
00:23:52,250 --> 00:23:54,209
And, of course, that's
slow to loop over

573
00:23:54,209 --> 00:23:55,469
all the data in the world just

574
00:23:55,469 --> 00:23:56,970
to extract the Wisconsin data.

575
00:23:56,970 --> 00:23:58,549
I wouldn't necessarily
want to do that

576
00:23:58,549 --> 00:24:00,889
more often than necessary.

577
00:24:00,889 --> 00:24:02,269
So there are certain cases,

578
00:24:02,269 --> 00:24:04,260
even though even though

579
00:24:04,260 --> 00:24:07,239
an RDD is kind of a recipe
for how to get some data,

580
00:24:07,239 --> 00:24:09,879
sometimes I actually
want to save the result

581
00:24:09,879 --> 00:24:12,800
of what I achieved by
following that recipe.

582
00:24:12,800 --> 00:24:14,959
And so that's
caching. And before

583
00:24:14,959 --> 00:24:17,759
with all these caching
policies we were on like LRU,

584
00:24:17,759 --> 00:24:19,840
for example, what those things

585
00:24:19,840 --> 00:24:21,559
were trying to do is they
were trying to predict,

586
00:24:21,559 --> 00:24:22,699
what data you're going to need

587
00:24:22,699 --> 00:24:24,119
soon and keep it in the cache.

588
00:24:24,119 --> 00:24:26,764
And they were really,
like least recently used,

589
00:24:26,764 --> 00:24:28,649
Recent is talking
about the past, right?

590
00:24:28,649 --> 00:24:30,609
So in LRU cash is like trying to

591
00:24:30,609 --> 00:24:31,409
predict where you're going to do

592
00:24:31,409 --> 00:24:32,630
the future by
looking at the past.

593
00:24:32,630 --> 00:24:34,529
Sometimes that works.
Sometimes it doesn't.

594
00:24:34,529 --> 00:24:37,510
What Sparka is doing is
not anything so clever.

595
00:24:37,510 --> 00:24:39,389
They're asking you as
a programmer to say,

596
00:24:39,389 --> 00:24:40,769
like, Oh, well, you're
computing this thing,

597
00:24:40,769 --> 00:24:42,749
and you have to
explicitly identify,

598
00:24:42,749 --> 00:24:44,749
I might need it
again soon, right?

599
00:24:44,749 --> 00:24:46,649
So, how might we
do this up here?

600
00:24:46,649 --> 00:24:49,150
Maybe this all weather thing
is reading from some file.

601
00:24:49,150 --> 00:24:50,850
I filter down to Wisconsin.

602
00:24:50,850 --> 00:24:53,490
And then I can say
Wisconsin weather.

603
00:24:53,490 --> 00:24:55,760
Then At that point,

604
00:24:55,760 --> 00:24:57,339
no work has actually
happened yet, because,

605
00:24:57,339 --> 00:24:59,320
again, these are all
lazy transformations.

606
00:24:59,320 --> 00:25:01,379
When I compute the
average temperature,

607
00:25:01,379 --> 00:25:05,099
then in addition to processing
all this computing, like,

608
00:25:05,099 --> 00:25:06,600
filtering down to
the Wisconsin data,

609
00:25:06,600 --> 00:25:09,179
it will also save that
Wisconsin data in memory.

610
00:25:09,179 --> 00:25:10,440
It'll save it for me later.

611
00:25:10,440 --> 00:25:12,960
Then when I come along and I
do Madison rainfall later,

612
00:25:12,960 --> 00:25:14,399
it doesn't have to go
back to the beginning

613
00:25:14,399 --> 00:25:15,660
where we have the
whole world of data.

614
00:25:15,660 --> 00:25:18,199
It can look at the Wisconsin
data that's in memory.

615
00:25:18,199 --> 00:25:19,780
Same thing when I'm
looking at the correlation

616
00:25:19,780 --> 00:25:21,700
between different weather
stations and Madison.

617
00:25:21,700 --> 00:25:22,959
When I'm all done, I can say,

618
00:25:22,959 --> 00:25:24,840
Wisconsin weather
or not persist,

619
00:25:24,840 --> 00:25:27,880
and then it can free up that
memory for other things.

620
00:25:27,880 --> 00:25:29,999
Alright. That's another thing
you have to get rid of.

621
00:25:29,999 --> 00:25:31,080
You have to figure
out, we, you're

622
00:25:31,080 --> 00:25:32,380
working with all of these RDDs,

623
00:25:32,380 --> 00:25:34,459
which ones do you want
to cache and which not,

624
00:25:34,459 --> 00:25:37,059
and when are you actually
done with it, right?

625
00:25:37,059 --> 00:25:38,880
So, you know, I think a lot

626
00:25:38,880 --> 00:25:40,019
of people could
draw and be like,

627
00:25:40,019 --> 00:25:41,440
a naive spark user.

628
00:25:41,440 --> 00:25:42,699
What I'm hoping you will all do

629
00:25:42,699 --> 00:25:44,679
is understand a little
bit about how things work

630
00:25:44,679 --> 00:25:47,000
internally and then be a
more sophisticated user

631
00:25:47,000 --> 00:25:49,299
that can get the best
performance out of this system.

632
00:25:49,299 --> 00:25:50,699
That's what my goal is for you.

633
00:25:50,699 --> 00:25:53,239
So Any question about caching?

634
00:25:55,530 --> 00:26:01,369
All right. Cool. So we
talked about Map reduce.

635
00:26:01,369 --> 00:26:03,810
Spark came along with
this idea of RDDs,

636
00:26:03,810 --> 00:26:05,650
which is in just a
lot of ways better,

637
00:26:05,650 --> 00:26:08,129
right than Map reduce, so they

638
00:26:08,129 --> 00:26:10,969
started kind of replacing
it with based on that idea.

639
00:26:10,969 --> 00:26:13,049
And so that's like the core
thing they're doing it.

640
00:26:13,049 --> 00:26:15,949
But they built all this stuff
on top of it and around it.

641
00:26:15,949 --> 00:26:17,849
So I want to talk a
little bit about that.

642
00:26:17,849 --> 00:26:20,290
One is that not everybody

643
00:26:20,290 --> 00:26:22,789
is going to want to be
programming RDDs, right?

644
00:26:22,789 --> 00:26:24,169
Maybe not everybody
has that background.

645
00:26:24,169 --> 00:26:25,849
There's plenty of
people who know SQL,

646
00:26:25,849 --> 00:26:28,470
but they could not,
write a Python program.

647
00:26:28,470 --> 00:26:30,530
That's fine. And so what
they did is they built

648
00:26:30,530 --> 00:26:32,930
something called Spark
Sequel on top of RDDs.

649
00:26:32,930 --> 00:26:35,229
A lot of these things like
group by or filtering, right?

650
00:26:35,229 --> 00:26:37,349
There's corresponds something
you could do in RDD,

651
00:26:37,349 --> 00:26:38,810
but it also corresponds
to something

652
00:26:38,810 --> 00:26:40,449
you might see in SQL, right?

653
00:26:40,449 --> 00:26:41,809
So that builds on top of that.

654
00:26:41,809 --> 00:26:44,790
And SQL actually has
various formal standards,

655
00:26:44,790 --> 00:26:46,969
and so they aren't just
building some SQL language.

656
00:26:46,969 --> 00:26:49,210
They built like a
legit formal version.

657
00:26:49,210 --> 00:26:52,109
They supported a legit formal
version of SQL, right?

658
00:26:52,109 --> 00:26:55,960
They have a standard And for
Spark SQL, in particular,

659
00:26:55,960 --> 00:26:57,359
a lot of these optimizations are

660
00:26:57,359 --> 00:26:59,079
possible because you look at

661
00:26:59,079 --> 00:27:02,859
things that are
happening in SQL, right?

662
00:27:02,859 --> 00:27:04,919
Like you're doing group
buys or joins a lot of

663
00:27:04,919 --> 00:27:07,380
standard things that happen
in a variety of situations.

664
00:27:07,380 --> 00:27:08,859
And so it's possible
for an optimizer

665
00:27:08,859 --> 00:27:10,499
to understand this handful

666
00:27:10,499 --> 00:27:11,999
of things that people
do all the time

667
00:27:11,999 --> 00:27:13,879
and understand when it's
possible to reorder,

668
00:27:13,879 --> 00:27:16,219
or find different ways
to get the same result.

669
00:27:16,219 --> 00:27:17,920
So Spark SQL can optimize

670
00:27:17,920 --> 00:27:22,169
that Some people like
doing analysis with SQL.

671
00:27:22,169 --> 00:27:23,949
Other people like data frames.

672
00:27:23,949 --> 00:27:25,850
Is there anybody
here who, really

673
00:27:25,850 --> 00:27:28,549
likes programming with
Pandas, for example?

674
00:27:28,549 --> 00:27:30,869
Like, I guess, like five of you.

675
00:27:30,869 --> 00:27:32,569
I thought it was more
popular, but anyway,

676
00:27:32,569 --> 00:27:34,210
I think Pandas is a
nice way to program.

677
00:27:34,210 --> 00:27:36,529
I like Pandas, right? And
so people like data frames,

678
00:27:36,529 --> 00:27:38,250
and so they wanted to
support that as well.

679
00:27:38,250 --> 00:27:41,149
And rather than build that
directly on top of RDDs,

680
00:27:41,149 --> 00:27:43,369
they built that on
top of Spark SQL.

681
00:27:43,369 --> 00:27:44,909
All these things that you
might be interacting with

682
00:27:44,909 --> 00:27:46,350
the data frame ultimately gets

683
00:27:46,350 --> 00:27:47,910
translated to some
kind of SQL query,

684
00:27:47,910 --> 00:27:49,129
ultimately gets translated to

685
00:27:49,129 --> 00:27:51,069
something that's
happening with RDDs,

686
00:27:51,069 --> 00:27:52,809
and, of course, optimized.

687
00:27:52,809 --> 00:27:55,570
Now, If I'm doing a
data frame in Pandas,

688
00:27:55,570 --> 00:27:57,489
it's really easy to change
data frames in Pandas.

689
00:27:57,489 --> 00:27:59,889
I can add columns, change
values, whatever I want.

690
00:27:59,889 --> 00:28:02,949
And that's because Pandas
data frames are mutable.

691
00:28:02,949 --> 00:28:04,909
Data frames in Spark

692
00:28:04,909 --> 00:28:06,809
are based on RDDs,
which are immutable.

693
00:28:06,809 --> 00:28:09,129
Once I have an RDD,
I can't change it.

694
00:28:09,129 --> 00:28:11,129
And so one of the
implications is that

695
00:28:11,129 --> 00:28:13,429
a Spark data frame
is going to be

696
00:28:13,429 --> 00:28:16,050
basically kreate it
and it's read only.

697
00:28:16,050 --> 00:28:17,590
I can't change it any further.

698
00:28:17,590 --> 00:28:21,319
It's immutable, right?
Alright. The powerful thing

699
00:28:21,319 --> 00:28:22,720
though is that if I
have a spark data

700
00:28:22,720 --> 00:28:24,559
frame and I'm using it,

701
00:28:24,559 --> 00:28:26,739
it's not in memory on the
computer I'm using it.

702
00:28:26,739 --> 00:28:28,399
I just I'm doing operations on

703
00:28:28,399 --> 00:28:30,319
it to leverage the resources
of my whole cluster,

704
00:28:30,319 --> 00:28:31,859
maybe thousands of machines.

705
00:28:31,859 --> 00:28:34,280
And even if those
machines cumulative,

706
00:28:34,280 --> 00:28:36,879
don't have enough memory for
it, that can be okay, right?

707
00:28:36,879 --> 00:28:38,579
I can have a data
frame that there's not

708
00:28:38,579 --> 00:28:39,919
even entirely in memory

709
00:28:39,919 --> 00:28:41,280
across all these
different machines.

710
00:28:41,280 --> 00:28:43,019
And so I can do a
lot of things for

711
00:28:43,019 --> 00:28:44,439
bigger data sets that Pandas

712
00:28:44,439 --> 00:28:46,384
would just fall over
for very quickly.

713
00:28:46,384 --> 00:28:49,289
Let me just show you some ting
examples to compare them.

714
00:28:49,289 --> 00:28:51,530
I think Pandas is easier
to use because, well,

715
00:28:51,530 --> 00:28:54,050
it's also not trying to
help us with big data.

716
00:28:54,050 --> 00:28:55,830
So here I'm creating
a pandasata frame

717
00:28:55,830 --> 00:28:57,429
up here and I have a picture
of what it looks like.

718
00:28:57,429 --> 00:28:59,209
If I want to add a
column to it, right?

719
00:28:59,209 --> 00:29:00,469
It originally has x column,

720
00:29:00,469 --> 00:29:02,010
I can just say pandas Sta frame

721
00:29:02,010 --> 00:29:04,969
y equals the x column
squared, right?

722
00:29:04,969 --> 00:29:06,670
So I have 123, 149.

723
00:29:06,670 --> 00:29:08,809
Very easy to mutate
it and add stuff.

724
00:29:08,809 --> 00:29:10,329
If I want to go from a Pandadta

725
00:29:10,329 --> 00:29:11,569
frame to a spark
data frame, I can,

726
00:29:11,569 --> 00:29:13,570
I can just say spart
dot create data frame,

727
00:29:13,570 --> 00:29:16,290
passing a pandasta
frame Spark DF.

728
00:29:16,290 --> 00:29:17,629
If I want to convert
it back later,

729
00:29:17,629 --> 00:29:20,879
I could say Spark
DF two, to Pandas?

730
00:29:20,879 --> 00:29:22,260
You have to be a little
bit careful there,

731
00:29:22,260 --> 00:29:23,559
right because it
might be huge, right?

732
00:29:23,559 --> 00:29:25,680
That's a commonplace where
you'll run out of memory,

733
00:29:25,680 --> 00:29:26,159
and then, you know,

734
00:29:26,159 --> 00:29:27,839
things will crash on
your machine, right?

735
00:29:27,839 --> 00:29:29,840
But if somehow you did a
bunch of stuff on big data,

736
00:29:29,840 --> 00:29:32,160
and then you got some
smaller aggregate,

737
00:29:32,160 --> 00:29:33,299
you could bring it back if you

738
00:29:33,299 --> 00:29:35,279
wanted to. Right,
so I can do that.

739
00:29:35,279 --> 00:29:36,780
How would I do
something like above

740
00:29:36,780 --> 00:29:38,464
where I wanted to
add a y column?

741
00:29:38,464 --> 00:29:41,170
So I cannot change Spark DF,

742
00:29:41,170 --> 00:29:43,370
but I can make a new data frame

743
00:29:43,370 --> 00:29:44,909
that looks like it
with some changes.

744
00:29:44,909 --> 00:29:47,829
So I could say something like
Spark df dot with column.

745
00:29:47,829 --> 00:29:49,310
I'm adding a new column y,

746
00:29:49,310 --> 00:29:51,129
and I can say that y
should be computed

747
00:29:51,129 --> 00:29:52,969
as column x squared,

748
00:29:52,969 --> 00:29:55,409
and that will return
Spark DF two, right?

749
00:29:55,409 --> 00:29:58,330
I'll have one data
frame with just x,

750
00:29:58,330 --> 00:30:01,910
and I'll have another
data frame with x and y.

751
00:30:01,990 --> 00:30:05,549
Any questions or
concerns about that?

752
00:30:10,200 --> 00:30:17,559
Here. Why is what?

753
00:30:17,559 --> 00:30:25,759
Five. Why can Spark
not append it?

754
00:30:26,080 --> 00:30:29,960
Yeah, Spark, it's immutable,

755
00:30:29,960 --> 00:30:31,739
right Because the Spark
data frame is on top of

756
00:30:31,739 --> 00:30:34,119
Spark SQL which is on
top of Spark RDDs,

757
00:30:34,119 --> 00:30:36,040
and RDDs are immutable.

758
00:30:36,040 --> 00:30:38,579
I can create a new
RDD from an old RDD,

759
00:30:38,579 --> 00:30:41,399
but I cannot change
an RDD, right?

760
00:30:41,399 --> 00:30:44,819
If I wanted to, I mean, I
could use the Python variable.

761
00:30:44,819 --> 00:30:47,679
I could say Spark
DF equals Spark DF,

762
00:30:47,679 --> 00:30:50,934
but I cannot change
that data frame object.

763
00:30:50,934 --> 00:30:56,149
Sons? It's very similar
to strings, right?

764
00:30:56,149 --> 00:30:59,309
In the language in some
languages strings are mutable,

765
00:30:59,309 --> 00:31:01,309
but in Python, strings
are immutable.

766
00:31:01,309 --> 00:31:04,230
So if I wanted to a pend
something to a string, well,

767
00:31:04,230 --> 00:31:05,429
I don't change that
string, I just

768
00:31:05,429 --> 00:31:06,550
make like a new string object,

769
00:31:06,550 --> 00:31:08,729
which is the old
one plus a new one.

770
00:31:08,729 --> 00:31:11,049
Python, right if I'm kind of

771
00:31:11,049 --> 00:31:12,150
concatining one large string

772
00:31:12,150 --> 00:31:13,430
with another one is
a little bit waste.

773
00:31:13,430 --> 00:31:15,110
There's multiple
copies of the data.

774
00:31:15,110 --> 00:31:16,390
But this would actually, even

775
00:31:16,390 --> 00:31:17,730
though it feels like
a string to be waste,

776
00:31:17,730 --> 00:31:19,090
well it's actually
very efficient,

777
00:31:19,090 --> 00:31:21,789
because what is Spark
DF and Spark DF two?

778
00:31:21,789 --> 00:31:24,249
They're both recipes for

779
00:31:24,249 --> 00:31:26,509
computing the data
and all the cells,

780
00:31:26,509 --> 00:31:29,189
if I ever need to
look at them, right?

781
00:31:29,189 --> 00:31:30,769
So Unless I ever look at them,

782
00:31:30,769 --> 00:31:32,510
there's actually
no work even being

783
00:31:32,510 --> 00:31:34,569
Done here, right? You know,

784
00:31:34,569 --> 00:31:37,209
maybe Spark DF is a
recipe that has, like,

785
00:31:37,209 --> 00:31:39,310
steps 123, and Spark DF

786
00:31:39,310 --> 00:31:41,169
two is a recipe
that has steps one,

787
00:31:41,169 --> 00:31:42,629
two, three and four, right?

788
00:31:42,629 --> 00:31:44,710
It's not expensive to
create new data frame.

789
00:31:44,710 --> 00:31:46,650
So it kind of feels
weird that I'm creating

790
00:31:46,650 --> 00:31:47,589
new data frames that are like

791
00:31:47,589 --> 00:31:48,929
old ones with a little bit more.

792
00:31:48,929 --> 00:31:50,630
But internally, it's fine,

793
00:31:50,630 --> 00:31:52,444
and it's fast. Yeah, right here.

794
00:31:52,444 --> 00:31:57,780
A small size.

795
00:31:58,740 --> 00:32:01,979
Yeah, the RDD is small, right?

796
00:32:01,979 --> 00:32:03,239
It's just a list of directions.

797
00:32:03,239 --> 00:32:05,419
There's no data associated
with it, right?

798
00:32:05,419 --> 00:32:07,660
The only time there's
ever a lot of data

799
00:32:07,660 --> 00:32:09,699
or a lot of costs is when
I have an action, right?

800
00:32:09,699 --> 00:32:11,760
And then all of a sudden,
there's data that's

801
00:32:11,760 --> 00:32:14,319
going to flow through the
RDD until it hits my action.

802
00:32:14,319 --> 00:32:15,659
And at that point,
there might be

803
00:32:15,659 --> 00:32:17,200
a lot of data and
memory temporarily.

804
00:32:17,200 --> 00:32:19,159
But until I actually
materialize it somewhere,

805
00:32:19,159 --> 00:32:22,459
then there's no
significant cost.

806
00:32:22,740 --> 00:32:26,380
Lists of instructions
at point to a data set?

807
00:32:26,380 --> 00:32:28,860
Are they a list of instructions
at point to a data set?

808
00:32:28,860 --> 00:32:30,119
Yeah, yeah, they usually are.

809
00:32:30,119 --> 00:32:31,700
So usually it's like maybe

810
00:32:31,700 --> 00:32:33,579
PK files and HFS or
something like that.

811
00:32:33,579 --> 00:32:35,319
So that might be my
first RDD, right?

812
00:32:35,319 --> 00:32:38,380
We would be referring to
that data in that file,

813
00:32:38,380 --> 00:32:39,899
and I could have other
ones that transform

814
00:32:39,899 --> 00:32:41,160
the data in that
file in some way.

815
00:32:41,160 --> 00:32:42,319
Absolutely. Yeah. Thank you

816
00:32:42,319 --> 00:32:43,779
for asking and clarifying that.

817
00:32:43,779 --> 00:32:44,799
Yeah, both great questions.

818
00:32:44,799 --> 00:32:46,659
Yeah other questions
people have.

819
00:32:46,659 --> 00:32:49,299
Yeah, question right here.

820
00:32:55,180 --> 00:32:57,859
Exactly. So that's a
great point, right?

821
00:32:57,859 --> 00:32:59,379
So this Spark DF two,

822
00:32:59,379 --> 00:33:01,120
when I say with column, that's

823
00:33:01,120 --> 00:33:02,739
not calculated
until later, right?

824
00:33:02,739 --> 00:33:06,599
If I said spark df
two dot collect,

825
00:33:06,599 --> 00:33:08,099
that would try to bring
it into memory on

826
00:33:08,099 --> 00:33:09,759
my node, that would trigger it.

827
00:33:09,759 --> 00:33:11,039
Or if I said two Pandas,

828
00:33:11,039 --> 00:33:12,680
that would trigger
it or if I said,

829
00:33:12,680 --> 00:33:15,179
give me the average
value in a column.

830
00:33:15,179 --> 00:33:15,839
That would trigger it.

831
00:33:15,839 --> 00:33:17,359
At this point, nothing
has been triggered.

832
00:33:17,359 --> 00:33:19,919
No meaningful amount of work
has been done anywhere.

833
00:33:19,919 --> 00:33:21,659
Yeah, thank you for
clarifying that.

834
00:33:21,659 --> 00:33:24,699
Yeah, other questions or
clarifications people have.

835
00:33:24,770 --> 00:33:29,010
Right. Cool. Let's talk

836
00:33:29,010 --> 00:33:31,089
a little bit about how
we're going to deploy it.

837
00:33:31,089 --> 00:33:33,569
And so they have lots of
different deployment modes

838
00:33:33,569 --> 00:33:35,289
that interact with
different systems

839
00:33:35,289 --> 00:33:36,770
like Yarn or C Kubernetes.

840
00:33:36,770 --> 00:33:39,290
We're just going to look
at two this semester,

841
00:33:39,290 --> 00:33:41,510
and the first is called
a standalone mode.

842
00:33:41,510 --> 00:33:44,050
Is not any other
kind of framework.

843
00:33:44,050 --> 00:33:46,050
In this case, we have
to take different parts

844
00:33:46,050 --> 00:33:48,570
of the Spark cluster and
just run them ourselves.

845
00:33:48,570 --> 00:33:50,269
The most interesting thing,

846
00:33:50,269 --> 00:33:51,870
I think is a Spark executor.

847
00:33:51,870 --> 00:33:53,569
A Spark executor is a process

848
00:33:53,569 --> 00:33:56,209
that runs Spark tasks for us.

849
00:33:56,209 --> 00:33:58,250
Here I might have a few of them.

850
00:33:58,250 --> 00:34:00,550
If I have some Spark
job that's running,

851
00:34:00,550 --> 00:34:01,969
a decision has to be made about

852
00:34:01,969 --> 00:34:04,069
which tasks run on
which executors,

853
00:34:04,069 --> 00:34:06,069
and so I may have some
kind of cluster manager,

854
00:34:06,069 --> 00:34:08,689
maybe a separate process
that's in charge of that.

855
00:34:08,689 --> 00:34:10,990
Now, I as a programmer
I'm probably writing

856
00:34:10,990 --> 00:34:12,109
some code like in

857
00:34:12,109 --> 00:34:13,689
a Jupiter notebook or
something like that,

858
00:34:13,689 --> 00:34:15,069
and I'm interacting with it via

859
00:34:15,069 --> 00:34:16,570
something called
the PySpark module,

860
00:34:16,570 --> 00:34:17,960
which is also in Python.

861
00:34:17,960 --> 00:34:19,389
But it turns out that

862
00:34:19,389 --> 00:34:21,590
all the spark stuff is
running on the JVM.

863
00:34:21,590 --> 00:34:22,949
Spark was not written in

864
00:34:22,949 --> 00:34:24,730
Java actually, it was
written in Scala,

865
00:34:24,730 --> 00:34:26,650
but Scala can compile

866
00:34:26,650 --> 00:34:29,269
to JVM Bite Trode that's
what they do, right?

867
00:34:29,269 --> 00:34:30,629
So they've built this as

868
00:34:30,629 --> 00:34:32,909
JVM Bite Trode they have a
couple of components here,

869
00:34:32,909 --> 00:34:34,710
a Spark driver and
a spark session.

870
00:34:34,710 --> 00:34:36,409
And those are the things
that are going to be

871
00:34:36,409 --> 00:34:37,830
communicating with
these other nodes

872
00:34:37,830 --> 00:34:38,789
in the cluster, right?

873
00:34:38,789 --> 00:34:40,890
So I may be writing Python
rode, but internally,

874
00:34:40,890 --> 00:34:43,870
there's going to be this scala
running on top of the JVM.

875
00:34:43,870 --> 00:34:45,850
That doesn't mean that a
lot of the air messages

876
00:34:45,850 --> 00:34:47,849
we see are going to be
pretty awful, right?

877
00:34:47,849 --> 00:34:49,749
Because there might be an
exception, and I'll see, like,

878
00:34:49,749 --> 00:34:51,009
well, you know, I had

879
00:34:51,009 --> 00:34:52,769
this Python line of
code that was running,

880
00:34:52,769 --> 00:34:55,529
and then there's
some scala lines of

881
00:34:55,529 --> 00:34:56,769
code and some java lines of

882
00:34:56,769 --> 00:34:58,449
code that might be a little
bit overwhelming, right?

883
00:34:58,449 --> 00:35:00,029
It will have quite long errors.

884
00:35:00,029 --> 00:35:03,230
And I don't expect anybody
to know Scala or Java.

885
00:35:03,230 --> 00:35:04,590
I don't know Scala myself.

886
00:35:04,590 --> 00:35:06,409
But we'll so have
to kind of dig into

887
00:35:06,409 --> 00:35:08,689
these nasty error messages
and try to pull out

888
00:35:08,689 --> 00:35:10,850
pieces of information to
troubleshoot what actually

889
00:35:10,850 --> 00:35:13,159
went wrong. All right.

890
00:35:13,159 --> 00:35:14,719
So that's one thing
that you could do.

891
00:35:14,719 --> 00:35:17,340
Another thing you could
do is called local mode.

892
00:35:17,340 --> 00:35:19,459
And in that case,
we basically just

893
00:35:19,459 --> 00:35:21,919
have a Spark executor built in

894
00:35:21,919 --> 00:35:24,499
to the same JVM that's
running this process over

895
00:35:24,499 --> 00:35:27,319
here inside of Python, right?

896
00:35:27,319 --> 00:35:29,120
In that case, everything's
just running locally.

897
00:35:29,120 --> 00:35:30,979
So I couldn't take advantage
of a large cluster or

898
00:35:30,979 --> 00:35:32,060
anything like that
because everything's

899
00:35:32,060 --> 00:35:33,460
running one on one machine,

900
00:35:33,460 --> 00:35:35,800
which is fine, I guess.

901
00:35:35,800 --> 00:35:37,719
It's often used for testing or

902
00:35:37,719 --> 00:35:40,580
development because
yeah, it's not scalable.

903
00:35:40,580 --> 00:35:42,219
There are cases
where I think it is

904
00:35:42,219 --> 00:35:44,479
useful for real things as well.

905
00:35:44,479 --> 00:35:47,380
If I want to do all my
computation on a single machine,

906
00:35:47,380 --> 00:35:48,959
but I don't have
enough memory to

907
00:35:48,959 --> 00:35:51,084
keep all my data and
memory at the same time.

908
00:35:51,084 --> 00:35:52,669
This would be a nice
way to do it because

909
00:35:52,669 --> 00:35:54,929
the computation will happen
on one partition at a time.

910
00:35:54,929 --> 00:35:56,949
And so I could still doing this.

911
00:35:56,949 --> 00:35:59,050
I could work on some
datasets that are bigger

912
00:35:59,050 --> 00:36:02,149
than what say like
Pandas could deal with.

913
00:36:02,149 --> 00:36:05,609
Alright, Cel. So
I'm head over here.

914
00:36:06,170 --> 00:36:11,589
And if you go to my lecture
snippets for today,

915
00:36:11,589 --> 00:36:13,630
I have a link here to
some starter stuff.

916
00:36:13,630 --> 00:36:16,370
I have a docker file there
and also a Docker compose.

917
00:36:16,370 --> 00:36:19,150
And let's just take a
look at that briefly.

918
00:36:19,150 --> 00:36:22,890
So let me make this
a little bit larger.

919
00:36:24,670 --> 00:36:27,449
Great. And so I have

920
00:36:27,449 --> 00:36:30,409
a Docker file first. I'll
take a look at that.

921
00:36:30,409 --> 00:36:32,409
Kind of pretty typical, right.

922
00:36:32,409 --> 00:36:35,710
We've already seen how
we install HDFS before.

923
00:36:35,710 --> 00:36:38,129
And installing Spark
is actually very

924
00:36:38,129 --> 00:36:41,029
similar. What are we doing?

925
00:36:41,029 --> 00:36:44,489
We're downloading a
G zipped tar file.

926
00:36:44,489 --> 00:36:47,389
We're decompressing it, and
then it's installed, right?

927
00:36:47,389 --> 00:36:50,149
That's installed just a
lot like it does for HDFS.

928
00:36:50,149 --> 00:36:53,269
You know, We have that Pi
spark wrapper around it.

929
00:36:53,269 --> 00:36:55,770
Uh, we have the JVM as before.

930
00:36:55,770 --> 00:36:57,409
There's some kind of

931
00:36:57,409 --> 00:36:59,949
Java environment variable
stuff we have to do.

932
00:36:59,949 --> 00:37:02,009
Anyway, nothing too crazy here.

933
00:37:02,009 --> 00:37:03,949
And so you could build this.

934
00:37:03,949 --> 00:37:06,210
And if I look at
my Docker Compose,

935
00:37:06,210 --> 00:37:07,669
that image that I built from the

936
00:37:07,669 --> 00:37:09,430
Docker file is
called Spark Demo.

937
00:37:09,430 --> 00:37:11,049
And even though I have lots of

938
00:37:11,049 --> 00:37:12,669
different services in here,

939
00:37:12,669 --> 00:37:14,689
what I thought might be
convenient would just be to have

940
00:37:14,689 --> 00:37:17,210
the same image for all the
different types of service.

941
00:37:17,210 --> 00:37:18,829
I just have to build one thing.

942
00:37:18,829 --> 00:37:21,149
Do a Doctor compose
up and I'm good.

943
00:37:21,149 --> 00:37:21,549
Now,

944
00:37:21,549 --> 00:37:23,490
they have different purposes,
these different containers,

945
00:37:23,490 --> 00:37:25,029
and so the way I deal
with that is I would put

946
00:37:25,029 --> 00:37:27,469
in different commands
for each of them.

947
00:37:27,469 --> 00:37:29,329
Like, for example, this one

948
00:37:29,329 --> 00:37:31,549
is starting Jupiter
inside of it,

949
00:37:31,549 --> 00:37:33,390
and I'm may have the
notebook directory

950
00:37:33,390 --> 00:37:35,109
shared so I can
save my files out,

951
00:37:35,109 --> 00:37:37,069
and I'm may have some
port mapping so that I

952
00:37:37,069 --> 00:37:40,135
can access Jupiter
on port 5,000.

953
00:37:40,135 --> 00:37:42,079
Here I'm starting a name node.

954
00:37:42,079 --> 00:37:43,459
This might actually
help you with the

955
00:37:43,459 --> 00:37:44,919
current project, by the way.

956
00:37:44,919 --> 00:37:47,800
It's often natural that when
you're starting a container,

957
00:37:47,800 --> 00:37:49,440
you want to do multiple steps.

958
00:37:49,440 --> 00:37:53,459
For example, maybe you want
to format a name node, right?

959
00:37:53,459 --> 00:37:55,719
And then actually
start a name node.

960
00:37:55,719 --> 00:37:58,599
You can only put one docker
command in for start up.

961
00:37:58,599 --> 00:38:00,319
And so the trick
here is I say, H a,

962
00:38:00,319 --> 00:38:03,099
my one docker command
is to run a shell,

963
00:38:03,099 --> 00:38:04,699
and I'm just trying to
pass at this sting.

964
00:38:04,699 --> 00:38:06,599
Well, guess what this string
has two commands in it.

965
00:38:06,599 --> 00:38:07,919
Kind of just a dirty trick.

966
00:38:07,919 --> 00:38:09,079
I mean, the other
thing you could do,

967
00:38:09,079 --> 00:38:10,179
which might be a
little bit cleaner,

968
00:38:10,179 --> 00:38:11,759
and you actually did
on Project one is

969
00:38:11,759 --> 00:38:13,519
that your one start
up command could

970
00:38:13,519 --> 00:38:15,419
be a shell strap
like a dot SH file

971
00:38:15,419 --> 00:38:17,119
and you can put whatever
you want in there.

972
00:38:17,119 --> 00:38:18,479
So, you know, figure
out what you want to do

973
00:38:18,479 --> 00:38:20,359
with P four. I either
would be fine.

974
00:38:20,359 --> 00:38:23,779
Either the old way or
this kind of dirty hack.

975
00:38:23,779 --> 00:38:27,179
I may have one data node
talking to the name node.

976
00:38:27,179 --> 00:38:28,999
And then down here, I have

977
00:38:28,999 --> 00:38:31,260
my executors and these workers,

978
00:38:31,260 --> 00:38:33,459
and I may have two of them.

979
00:38:33,459 --> 00:38:35,119
I'm going to tell
them that they each

980
00:38:35,119 --> 00:38:36,939
have one CPU, right?

981
00:38:36,939 --> 00:38:38,180
That means in this cluster,

982
00:38:38,180 --> 00:38:40,239
I can run two tasks
at a time at most.

983
00:38:40,239 --> 00:38:42,259
And then up here, I
have a boss, right?

984
00:38:42,259 --> 00:38:45,040
So a lot of systems have
this architectural.

985
00:38:45,040 --> 00:38:47,220
You have one centralized
boss and a lot of workers.

986
00:38:47,220 --> 00:38:48,959
Sometimes different
vocabulary is used for that.

987
00:38:48,959 --> 00:38:50,459
So for example, in HTFS,

988
00:38:50,459 --> 00:38:52,039
the boss is called a name node.

989
00:38:52,039 --> 00:38:53,560
The workers are
called data nodes.

990
00:38:53,560 --> 00:38:54,920
Another name that
you might sometimes

991
00:38:54,920 --> 00:38:56,660
see is they might call
it like a master.

992
00:38:56,660 --> 00:38:58,080
I think the systems community

993
00:38:58,080 --> 00:38:59,219
is getting away from
that because it has

994
00:38:59,219 --> 00:39:01,999
this kind of nasty association
with slavery, right?

995
00:39:01,999 --> 00:39:03,160
But anyway, if you see strips

996
00:39:03,160 --> 00:39:04,299
like that you should
know what it is, right?

997
00:39:04,299 --> 00:39:05,899
That's starting the boss node

998
00:39:05,899 --> 00:39:07,689
in my cluster, and that's
what this is doing here.

999
00:39:07,689 --> 00:39:10,499
So I can do a Docker compose
up, which I've already done,

1000
00:39:10,499 --> 00:39:12,059
and that will bring up all of

1001
00:39:12,059 --> 00:39:13,499
these many containers
that are part of

1002
00:39:13,499 --> 00:39:16,659
this little project that
I'm doing right now.

1003
00:39:16,659 --> 00:39:19,200
And if I head over
here to Jupiter,

1004
00:39:19,200 --> 00:39:20,599
then I should be able to start

1005
00:39:20,599 --> 00:39:23,140
interacting with
this Spark cluster.

1006
00:39:23,140 --> 00:39:24,559
So may come to the snippets,

1007
00:39:24,559 --> 00:39:26,119
and there's a bit of code

1008
00:39:26,119 --> 00:39:28,549
here I can use to connect to it.

1009
00:39:28,549 --> 00:39:30,820
I think it warrants a
little bit of explanation.

1010
00:39:30,820 --> 00:39:33,999
I'm just going to pause
here for a moment.

1011
00:39:33,999 --> 00:39:36,059
First, I'm going to import
from Pi Spark I'm to

1012
00:39:36,059 --> 00:39:38,359
import this Spark session thing.

1013
00:39:38,359 --> 00:39:40,380
And inside of Spark session,

1014
00:39:40,380 --> 00:39:42,500
they have this thing
called a builder.

1015
00:39:42,500 --> 00:39:44,479
And a builder is a
special kind of class

1016
00:39:44,479 --> 00:39:47,480
that has a very
particular purpose.

1017
00:39:47,480 --> 00:39:50,460
Job is to create new objects.

1018
00:39:50,460 --> 00:39:51,619
And I think the way most of

1019
00:39:51,619 --> 00:39:53,139
you have probably
seen many times

1020
00:39:53,139 --> 00:39:54,859
actually is that you create

1021
00:39:54,859 --> 00:39:57,259
new objects by invoking
a constructor.

1022
00:39:57,259 --> 00:40:00,000
And maybe the instructor has
lots and lots of arguments.

1023
00:40:00,000 --> 00:40:01,620
And then based on
those arguments,

1024
00:40:01,620 --> 00:40:02,879
it will actually initialize it.

1025
00:40:02,879 --> 00:40:05,105
That's one style for
creating objects.

1026
00:40:05,105 --> 00:40:07,009
Not everybody likes that style,

1027
00:40:07,009 --> 00:40:09,690
because if the language does
not have default arguments,

1028
00:40:09,690 --> 00:40:10,789
then it's kind of

1029
00:40:10,789 --> 00:40:12,669
annoying having this long
list of arguments, right?

1030
00:40:12,669 --> 00:40:14,270
So that has led to
this other style

1031
00:40:14,270 --> 00:40:16,570
of builders for
creating objects.

1032
00:40:16,570 --> 00:40:17,729
And so the way it works is

1033
00:40:17,729 --> 00:40:20,229
that I have this
builder object here,

1034
00:40:20,229 --> 00:40:22,390
and I can say something
like app name,

1035
00:40:22,390 --> 00:40:25,749
CS 544, and that's going to
return a builder object.

1036
00:40:25,749 --> 00:40:27,670
Again, it's actually
returning itself.

1037
00:40:27,670 --> 00:40:29,649
And I can have
other things here,

1038
00:40:29,649 --> 00:40:33,229
like I could specify the
boss node like that.

1039
00:40:33,229 --> 00:40:35,230
And that will again
just return itself.

1040
00:40:35,230 --> 00:40:36,809
And the idea is that I can call

1041
00:40:36,809 --> 00:40:38,829
any combination of
functions like this,

1042
00:40:38,829 --> 00:40:40,689
and each function configures

1043
00:40:40,689 --> 00:40:42,849
something that's going to
used for creation later,

1044
00:40:42,849 --> 00:40:44,150
and it also returns itself.

1045
00:40:44,150 --> 00:40:47,089
I have a long chain of
configuration is a little bit

1046
00:40:47,089 --> 00:40:48,449
more readable than
having just like one

1047
00:40:48,449 --> 00:40:50,090
constructor with
lots of arguments.

1048
00:40:50,090 --> 00:40:51,909
So anyway, that's what's
happening up here.

1049
00:40:51,909 --> 00:40:54,089
It's creating all this
stuff, it's configuring it.

1050
00:40:54,089 --> 00:40:56,790
And at the very end,
I say G or create.

1051
00:40:56,790 --> 00:40:58,749
And so when I run
that, that's going to

1052
00:40:58,749 --> 00:41:00,909
spin up some JVM stuff.

1053
00:41:00,909 --> 00:41:03,170
I I start running
my spark driver.

1054
00:41:03,170 --> 00:41:04,590
It's kind of slow honestly,

1055
00:41:04,590 --> 00:41:07,030
but once it's up and running,
at least it's scalable.

1056
00:41:07,030 --> 00:41:10,230
So I'm going to do that.
And this G or create,

1057
00:41:10,230 --> 00:41:12,329
I should be a little
bit careful about that.

1058
00:41:12,329 --> 00:41:13,809
If I were to run this line

1059
00:41:13,809 --> 00:41:15,209
of code again, it
will say, Oh, great,

1060
00:41:15,209 --> 00:41:16,409
you already have an app named

1061
00:41:16,409 --> 00:41:18,749
CS 544. It won't re run that.

1062
00:41:18,749 --> 00:41:20,429
So it's faster the second time.

1063
00:41:20,429 --> 00:41:23,570
It's also annoying because
if I change these settings,

1064
00:41:23,570 --> 00:41:24,689
and it's already there, it won't

1065
00:41:24,689 --> 00:41:25,869
pick up my new settings, right?

1066
00:41:25,869 --> 00:41:27,239
So When I'm doing

1067
00:41:27,239 --> 00:41:28,839
a Git or create, if I
want to change that,

1068
00:41:28,839 --> 00:41:30,659
then I'm going to have to make
sure I actually shut down

1069
00:41:30,659 --> 00:41:32,739
my notebook and restart,
so I pick up the new one.

1070
00:41:32,739 --> 00:41:35,679
All right, fantastic. So I
have the Spark session now.

1071
00:41:35,679 --> 00:41:38,339
And with the Spark session
is usually how we're

1072
00:41:38,339 --> 00:41:40,880
going to interact with it
via SQL or data frames.

1073
00:41:40,880 --> 00:41:43,440
But internally, they
have a Spark context,

1074
00:41:43,440 --> 00:41:46,499
which is getting back to the
roots of when Spark started.

1075
00:41:46,499 --> 00:41:51,285
The Spark context
is how we interact.

1076
00:41:51,285 --> 00:41:54,449
Directly with RDDs, right?

1077
00:41:54,449 --> 00:41:56,129
And normally, people are

1078
00:41:56,129 --> 00:41:57,910
not interacting
with RDDs directly.

1079
00:41:57,910 --> 00:42:00,509
They're either using data
frames or SQL, right?

1080
00:42:00,509 --> 00:42:02,169
Because that's easier, and it

1081
00:42:02,169 --> 00:42:04,830
makes more sense in
like 95% of the cases.

1082
00:42:04,830 --> 00:42:05,669
I like to start here

1083
00:42:05,669 --> 00:42:06,970
though because I think
it's really important

1084
00:42:06,970 --> 00:42:08,249
pedagogically to
understand what's

1085
00:42:08,249 --> 00:42:10,209
happening internally so
we can optimize later.

1086
00:42:10,209 --> 00:42:11,849
We're going to do some
stuff with RDDs and

1087
00:42:11,849 --> 00:42:14,859
the spart context is
how we would do that.

1088
00:42:14,859 --> 00:42:17,290
Alright, so I have
the Spark context,

1089
00:42:17,290 --> 00:42:19,349
and I can give it
some data, right?

1090
00:42:19,349 --> 00:42:20,970
So maybe I have a
range of numbers

1091
00:42:20,970 --> 00:42:24,789
0-1000000. I could have that.

1092
00:42:24,789 --> 00:42:26,409
Maybe I get a list
of those, right?

1093
00:42:26,409 --> 00:42:27,969
So I could have some numbs here.

1094
00:42:27,969 --> 00:42:30,269
Let me just take a peek at
like the first ten of them,

1095
00:42:30,269 --> 00:42:31,849
so I start counting
up from zero.

1096
00:42:31,849 --> 00:42:33,189
That's all fine and well.

1097
00:42:33,189 --> 00:42:34,869
And so then if I wanted to,

1098
00:42:34,869 --> 00:42:36,750
I could turn these into an RDD.

1099
00:42:36,750 --> 00:42:40,570
I could say a spark
context that parallels,

1100
00:42:40,570 --> 00:42:43,529
and I could pass in
however many numbs I want,

1101
00:42:43,529 --> 00:42:46,520
and that would give
me on RDD. Great.

1102
00:42:46,520 --> 00:42:48,539
So I'm going to have that
RDD and I can look at it

1103
00:42:48,539 --> 00:42:51,120
and it's type suggests
that it's an RDD.

1104
00:42:51,120 --> 00:42:53,019
Things are going well so far.

1105
00:42:53,019 --> 00:42:55,299
And then I can do different
operations on it.

1106
00:42:55,299 --> 00:42:57,319
I could define some
kind of function here,

1107
00:42:57,319 --> 00:42:58,819
and then based on that,

1108
00:42:58,819 --> 00:43:00,359
I could say RDD dot map,

1109
00:43:00,359 --> 00:43:02,220
and I could put that function.

1110
00:43:02,220 --> 00:43:03,479
In a lot of cases where I have

1111
00:43:03,479 --> 00:43:05,279
functions that really have
a single purpose like this.

1112
00:43:05,279 --> 00:43:08,380
And so there's a shortcut
in Python call the Lambda.

1113
00:43:08,380 --> 00:43:11,380
Lambda is just kind of an
anonymous, simple function.

1114
00:43:11,380 --> 00:43:13,280
And instead of doing
that, I can say Lambda,

1115
00:43:13,280 --> 00:43:15,739
and I have to say
arguments here and then I

1116
00:43:15,739 --> 00:43:18,569
say a return value down here.

1117
00:43:18,569 --> 00:43:20,279
And that's what
I'll do right here.

1118
00:43:20,279 --> 00:43:23,400
So what I may say is I
want to get n verses.

1119
00:43:23,400 --> 00:43:26,399
And for every X in nums,

1120
00:43:26,399 --> 00:43:28,219
I want to get the n verse of it,

1121
00:43:28,219 --> 00:43:30,359
and that would just
be one over x.

1122
00:43:30,359 --> 00:43:31,720
And I'm just wondering,

1123
00:43:31,720 --> 00:43:33,079
does anybody have
any thoughts like,

1124
00:43:33,079 --> 00:43:35,079
what will probably happen
when I run this line of code?

1125
00:43:35,079 --> 00:43:37,740
Yeah, go ahead. Zero vision.

1126
00:43:37,740 --> 00:43:39,059
Okay, I always catch
somebody. Yeah, I

1127
00:43:39,059 --> 00:43:40,219
was hoping that
somebody will say that.

1128
00:43:40,219 --> 00:43:41,739
And surprisingly,

1129
00:43:41,739 --> 00:43:44,299
I should have a zero vision
arr, but I don't, right?

1130
00:43:44,299 --> 00:43:46,499
And now, this is a good
point to stop and think,

1131
00:43:46,499 --> 00:43:47,959
Okay, Spark is doing
some things that

1132
00:43:47,959 --> 00:43:49,659
are a little bit different
what we're used to.

1133
00:43:49,659 --> 00:43:53,259
Why did I not get an
error? Yeah, right here.

1134
00:43:53,650 --> 00:43:55,989
It's not actually running it.

1135
00:43:55,989 --> 00:43:57,629
All it did is that it

1136
00:43:57,629 --> 00:43:59,590
created a recipe for
how to get the verses,

1137
00:43:59,590 --> 00:44:01,789
and it doesn't realize
that the recipe is bad

1138
00:44:01,789 --> 00:44:05,029
until I would actually go
along and try to do it, right?

1139
00:44:05,029 --> 00:44:07,209
So I could even have other
transformations on here.

1140
00:44:07,209 --> 00:44:08,950
Nothing bad will happen
until I actually

1141
00:44:08,950 --> 00:44:10,789
try to look at the data, right?

1142
00:44:10,789 --> 00:44:12,350
So let's try to try

1143
00:44:12,350 --> 00:44:13,669
a pause to make sure
people understand it.

1144
00:44:13,669 --> 00:44:16,029
People understand why there's
no error. Yeah, right here.

1145
00:44:16,029 --> 00:44:18,030
I'm curious what the
previous lights.

1146
00:44:18,030 --> 00:44:21,549
What does. Yeah, so this
returns on RDD for me.

1147
00:44:21,549 --> 00:44:24,509
It's basically trying to
take this python data

1148
00:44:24,509 --> 00:44:26,069
and make it available as

1149
00:44:26,069 --> 00:44:27,989
spark data that I
could operate on.

1150
00:44:27,989 --> 00:44:30,129
That makes sense? Yeah. Mm hmm.

1151
00:44:30,129 --> 00:44:32,609
Yeah, other questions
people have?

1152
00:44:32,660 --> 00:44:35,119
All right. So, right?

1153
00:44:35,119 --> 00:44:37,219
This was just a
transformation, right?

1154
00:44:37,219 --> 00:44:39,659
So just a transformation

1155
00:44:39,659 --> 00:44:43,479
doesn't do anything
yet. It's lazy, right?

1156
00:44:43,479 --> 00:44:45,359
And so if I try to do an action,

1157
00:44:45,359 --> 00:44:47,339
right, let me think about
some actions I could do.

1158
00:44:47,339 --> 00:44:48,740
I could try to
collect everything.

1159
00:44:48,740 --> 00:44:50,380
I would try to bring
back 1 million numbers

1160
00:44:50,380 --> 00:44:52,140
that would try to
bring everything.

1161
00:44:52,140 --> 00:44:53,639
Often, to just make it faster,

1162
00:44:53,639 --> 00:44:55,779
I might try to take
the first ten, right?

1163
00:44:55,779 --> 00:44:57,200
So this would be an action.

1164
00:44:57,200 --> 00:44:58,759
And because it's an action,

1165
00:44:58,759 --> 00:45:00,339
I'm going to get an
error down here, right?

1166
00:45:00,339 --> 00:45:04,995
So this is an action,
and it triggers.

1167
00:45:04,995 --> 00:45:08,250
The prior transformations,

1168
00:45:08,250 --> 00:45:12,229
including the divide
by zero, right?

1169
00:45:12,229 --> 00:45:15,309
I'm going to do that. And
this will run for a while.

1170
00:45:15,309 --> 00:45:16,710
And it's probably failing

1171
00:45:16,710 --> 00:45:18,490
and retrying some
stuff honestly,

1172
00:45:18,490 --> 00:45:21,249
right now, often it'll retry
automatically for you.

1173
00:45:21,249 --> 00:45:25,349
So initial job has not
accepted any resources.

1174
00:45:25,349 --> 00:45:33,930
That's not Dred. So I
wonder if I Somehow,

1175
00:45:33,930 --> 00:45:35,349
I'm wondering if the other one

1176
00:45:35,349 --> 00:45:37,829
needs to be shut down first.

1177
00:45:37,829 --> 00:45:39,509
I shut down the other one?

1178
00:45:39,509 --> 00:45:42,749
Would that help me? Let me

1179
00:45:42,749 --> 00:45:46,129
just shut down all and see
if I can get a clean start.

1180
00:45:47,860 --> 00:45:50,220
Sometime do you see that forever

1181
00:45:50,220 --> 00:45:52,199
reason if there's no workers
or something like that,

1182
00:45:52,199 --> 00:45:53,759
then it might say, Hey,

1183
00:45:53,759 --> 00:45:55,099
this job hasn't
even started yet.

1184
00:45:55,099 --> 00:45:57,859
So not what I was
wanting to show,

1185
00:45:57,859 --> 00:46:00,459
but also something
interesting to see.

1186
00:46:00,459 --> 00:46:03,979
Let's see if we have any
more luck this time.

1187
00:46:15,740 --> 00:46:18,959
And that's not good.
So what this means is

1188
00:46:18,959 --> 00:46:21,559
that the Oh, I think
that might be better.

1189
00:46:21,559 --> 00:46:23,279
Okay, great. I think it's
actually running now.

1190
00:46:23,279 --> 00:46:24,639
Maybe from the morning lecture,

1191
00:46:24,639 --> 00:46:25,900
still using some resources

1192
00:46:25,900 --> 00:46:27,319
and I couldn't get
resources now.

1193
00:46:27,319 --> 00:46:28,959
Okay. And it crashed, right?

1194
00:46:28,959 --> 00:46:31,439
And you can see that
for division by zero,

1195
00:46:31,439 --> 00:46:32,759
this is probably the
worst division by

1196
00:46:32,759 --> 00:46:35,579
zero message that anybody's
ever seen, right?

1197
00:46:35,579 --> 00:46:39,619
Way down at the bottom, I
can see my code, right?

1198
00:46:39,619 --> 00:46:41,299
Here's the division by zero.

1199
00:46:41,299 --> 00:46:43,839
And you know, this is a
notebook, so it's even worse,

1200
00:46:43,839 --> 00:46:46,179
right like it's doesn't
tell me what cell it is,

1201
00:46:46,179 --> 00:46:47,859
but I guess when it
was running that cell,

1202
00:46:47,859 --> 00:46:49,639
they put it in some
file like this.

1203
00:46:49,639 --> 00:46:51,759
It was like line
one of some cell.

1204
00:46:51,759 --> 00:46:53,699
If I draw up further,

1205
00:46:53,699 --> 00:46:55,839
I can see, there's some
java stuff going on, right?

1206
00:46:55,839 --> 00:46:57,060
Because we're in the JVM.

1207
00:46:57,060 --> 00:46:59,300
I go up further, there's
some scala stuff.

1208
00:46:59,300 --> 00:47:01,019
And so the takeaway is that

1209
00:47:01,019 --> 00:47:03,220
some very simple benign errors

1210
00:47:03,220 --> 00:47:06,119
give you these very nasty
output messages, right?

1211
00:47:06,119 --> 00:47:07,859
So don't get
intimidated. Slow down,

1212
00:47:07,859 --> 00:47:09,899
dig through, find out what
you need to know from it.

1213
00:47:09,899 --> 00:47:11,139
I don't know Scala either,

1214
00:47:11,139 --> 00:47:12,959
but I can still dig through
and try to figure out

1215
00:47:12,959 --> 00:47:15,349
what happened, right? Cool.

1216
00:47:15,349 --> 00:47:17,149
That's an action. Can't do that.

1217
00:47:17,149 --> 00:47:22,689
Another action that I could
have is like inverses mean.

1218
00:47:22,689 --> 00:47:25,029
It actually has to do the
inverses before it can

1219
00:47:25,029 --> 00:47:27,789
try to the means,

1220
00:47:27,789 --> 00:47:30,059
so that's going to fail
as well. Same thing.

1221
00:47:30,059 --> 00:47:32,369
And so I think one of the
things that everybody should be

1222
00:47:32,369 --> 00:47:33,329
familiar with is that there's

1223
00:47:33,329 --> 00:47:34,829
different operations
I should do,

1224
00:47:34,829 --> 00:47:35,970
and you should
start making notes,

1225
00:47:35,970 --> 00:47:37,369
which ones are which ones are

1226
00:47:37,369 --> 00:47:39,810
actions and which ones
are transformations.

1227
00:47:39,810 --> 00:47:42,530
So how could I actually
do this correctly?

1228
00:47:42,530 --> 00:47:45,109
Well, I think that I
have the inverses.

1229
00:47:45,109 --> 00:47:47,210
Well, actually, let me
go back to the RDD.

1230
00:47:47,210 --> 00:47:50,089
What I could do is I could
actually filter it first,

1231
00:47:50,089 --> 00:47:51,990
and I could have another
Lambda function,

1232
00:47:51,990 --> 00:47:55,509
and for each number, I could
return a Boolean, right?

1233
00:47:55,509 --> 00:47:57,029
And so maybe I
could do is I could

1234
00:47:57,029 --> 00:47:59,109
say if X is greater than zero,

1235
00:47:59,109 --> 00:48:00,929
so that would help me out.

1236
00:48:00,929 --> 00:48:03,469
And then after that, I
could say, do this map,

1237
00:48:03,469 --> 00:48:07,879
where I say, Land
of X is one over x.

1238
00:48:07,879 --> 00:48:10,779
That would give me some
inverses over here.

1239
00:48:10,779 --> 00:48:12,319
And then if I wanted to, I

1240
00:48:12,319 --> 00:48:13,839
could actually have
real actions, right?

1241
00:48:13,839 --> 00:48:16,499
I say verse dot mean.

1242
00:48:16,499 --> 00:48:17,859
Mostly the number will be pretty

1243
00:48:17,859 --> 00:48:19,139
small. I mean, I
have like 1 million.

1244
00:48:19,139 --> 00:48:21,059
As X gets pretty big.
These numbers will be

1245
00:48:21,059 --> 00:48:23,879
small. And then there we go.

1246
00:48:23,879 --> 00:48:25,740
I can see that I got this number

1247
00:48:25,740 --> 00:48:28,100
back here, which
seems plausible.

1248
00:48:28,100 --> 00:48:31,859
All right. What else might I do?

1249
00:48:31,859 --> 00:48:33,579
I might do things like,

1250
00:48:33,579 --> 00:48:36,699
say verse dot, take ten.

1251
00:48:36,699 --> 00:48:38,299
That would be another
action, and then

1252
00:48:38,299 --> 00:48:40,939
I could get like the first
ten numbers out of it.

1253
00:48:40,939 --> 00:48:47,879
Yeah, question
right. What's that?

1254
00:48:51,640 --> 00:48:53,839
Oh, yeah, that's
a good question.

1255
00:48:53,839 --> 00:48:55,739
So if we do the flip of it,

1256
00:48:55,739 --> 00:48:57,279
my expectation is that

1257
00:48:57,279 --> 00:49:00,499
it should do the
vide by zero, right?

1258
00:49:00,499 --> 00:49:01,939
But let's find out.

1259
00:49:01,939 --> 00:49:03,479
Oh, but then I actually
have to do an action.

1260
00:49:03,479 --> 00:49:13,609
Right? Oh, do the inverse
twice or Oh, I see.

1261
00:49:13,609 --> 00:49:14,529
You're wondering if it's like

1262
00:49:14,529 --> 00:49:15,709
going to somehow optimize it.

1263
00:49:15,709 --> 00:49:19,889
So you're saying, So
you're saying like,

1264
00:49:19,889 --> 00:49:22,909
RDD and then I inverse
it and inverse it twice,

1265
00:49:22,909 --> 00:49:25,509
and then I guess take the
mean or something like that.

1266
00:49:25,509 --> 00:49:27,629
I think it will do it
because I think it

1267
00:49:27,629 --> 00:49:32,269
will still divides by zero
before it grows back, right?

1268
00:49:32,269 --> 00:49:35,069
So it looks like it does fail.

1269
00:49:35,069 --> 00:49:36,569
It does it say divided by

1270
00:49:36,569 --> 00:49:42,219
zero. You saw it
somewhere? Okay.

1271
00:49:42,219 --> 00:49:43,920
I'll trust that it
said it somewhere.

1272
00:49:43,920 --> 00:49:45,259
Thank you for saving me.

1273
00:49:45,259 --> 00:49:47,599
Okay, yeah, it's still
doing that in order.

1274
00:49:47,599 --> 00:49:49,219
It's the same as if
I actually ran it.

1275
00:49:49,219 --> 00:49:50,959
It's just that the thing
that's different from

1276
00:49:50,959 --> 00:49:52,820
what we're used to is
when it actually happens.

1277
00:49:52,820 --> 00:49:55,759
And when it actually happens
is when the action is there.

1278
00:49:55,759 --> 00:49:57,480
Alright, Col. Thanks, everybody.

1279
00:49:57,480 --> 00:49:58,819
I'll be around to
people want a chat.

1280
00:49:58,819 --> 00:50:00,039
Otherwise, you know, there's

1281
00:50:00,039 --> 00:50:02,479
lots more examples I go
to dig into next week.

1282
00:50:02,479 --> 00:50:04,780
So I have a fantastic weekend.
