1
00:00:00,000 --> 00:00:04,875
Kind of loud. How is
the volume in the back?

2
00:00:04,875 --> 00:00:06,870
Alright, great. So today

3
00:00:06,870 --> 00:00:08,390
is just a student
driven review session.

4
00:00:08,390 --> 00:00:09,410
So you can ask questions

5
00:00:09,410 --> 00:00:10,529
about anything that
you want to that

6
00:00:10,529 --> 00:00:13,269
will help you prepare
for the final exam.

7
00:00:13,269 --> 00:00:15,230
You know, I print
off some old exams.

8
00:00:15,230 --> 00:00:17,089
Like you could ask questions
off of there, right?

9
00:00:17,089 --> 00:00:18,849
If you've looked at it,
and there's a question you

10
00:00:18,849 --> 00:00:20,769
don't really understand
the answer to.

11
00:00:20,769 --> 00:00:23,309
Of course, all the answers
for that are posted, right?

12
00:00:23,309 --> 00:00:25,009
Or you could just
be asking things

13
00:00:25,009 --> 00:00:26,769
more generally about
different topics.

14
00:00:26,769 --> 00:00:28,349
One message I just said,

15
00:00:28,349 --> 00:00:29,869
I finished drafting the exam,

16
00:00:29,869 --> 00:00:31,309
and so I want to
give you an idea of

17
00:00:31,309 --> 00:00:33,089
the breakdown of
different topics.

18
00:00:33,089 --> 00:00:35,450
Like I said, there's more
weight on the new stuff,

19
00:00:35,450 --> 00:00:37,070
and it's kind of what that looks

20
00:00:37,070 --> 00:00:39,129
like is that about
six questions on

21
00:00:39,129 --> 00:00:42,609
Ta Sparks Strea about
seven questions

22
00:00:42,609 --> 00:00:44,650
on Big y and the Cloud.

23
00:00:44,650 --> 00:00:46,770
And that's the new stuff.

24
00:00:46,770 --> 00:00:49,469
You know, we covered five
major systems this semester?

25
00:00:49,469 --> 00:00:52,209
So I want to have at least
sub coverage. Excuse me.

26
00:00:52,209 --> 00:00:53,689
Kind of echo for me.

27
00:00:53,689 --> 00:00:54,169
I want to have

28
00:00:54,169 --> 00:00:55,769
at least sub coverage of
each of these, right?

29
00:00:55,769 --> 00:00:58,850
So we have three questions,
HDFS, Park, and Cassandra.

30
00:00:58,850 --> 00:01:00,710
You know, there's a bunch
of miscellaneous things

31
00:01:00,710 --> 00:01:02,429
we've learned throughout
the semester.

32
00:01:02,429 --> 00:01:04,290
You should still
be, for example,

33
00:01:04,290 --> 00:01:05,989
traced through for like a cash,

34
00:01:05,989 --> 00:01:08,950
like how many hits or misses
there are, stuff like that.

35
00:01:08,950 --> 00:01:11,350
This is approximate
because I'm still adding

36
00:01:11,350 --> 00:01:13,110
and be moving questions
accounts might change.

37
00:01:13,110 --> 00:01:14,269
There's some questions
that don't really

38
00:01:14,269 --> 00:01:15,770
fit neatly into one category,

39
00:01:15,770 --> 00:01:17,809
but just to give
you a general idea.

40
00:01:17,809 --> 00:01:19,769
Do people have any questions?

41
00:01:19,769 --> 00:01:21,990
Yeah, right here.

42
00:01:22,450 --> 00:01:27,250
Yeah, 29 on the fall 2023.

43
00:01:28,330 --> 00:01:30,850
All right.

44
00:01:32,250 --> 00:01:34,890
Which big query model uses

45
00:01:34,890 --> 00:01:38,130
leftover CPU and
memory resources.

46
00:01:38,130 --> 00:01:42,870
And the answer is
on demand, right?

47
00:01:42,870 --> 00:01:45,450
And so really what we're
working with here is that

48
00:01:45,450 --> 00:01:46,589
we pay for a few

49
00:01:46,589 --> 00:01:48,050
different things,
different cases, right?

50
00:01:48,050 --> 00:01:52,169
There's CPUs. There's RAM.

51
00:01:52,730 --> 00:01:58,989
There's a colossus IO.

52
00:01:58,989 --> 00:02:03,130
And then there's
Closus storage, right?

53
00:02:05,850 --> 00:02:08,949
And so the first
model that they do

54
00:02:08,949 --> 00:02:11,509
is they will just let you
reserve these, right?

55
00:02:11,509 --> 00:02:14,329
And that reservation is called
capacity building, right?

56
00:02:14,329 --> 00:02:16,690
So we have capacity.

57
00:02:16,690 --> 00:02:19,510
You reserve some CPU and RAM,

58
00:02:19,510 --> 00:02:21,130
kind of at a more
expensive rate than

59
00:02:21,130 --> 00:02:23,269
a VM because they have a
platform on top of it.

60
00:02:23,269 --> 00:02:24,989
And when they do
that, of course,

61
00:02:24,989 --> 00:02:26,889
there's some leftover
capacity, right?

62
00:02:26,889 --> 00:02:28,129
Maybe they don't sell all of it,

63
00:02:28,129 --> 00:02:30,350
or maybe people aren't
using it continuously.

64
00:02:30,350 --> 00:02:32,050
And I'm sorry, I should

65
00:02:32,050 --> 00:02:34,130
also indicate that this
is up here as well.

66
00:02:34,130 --> 00:02:35,389
And so what they do is they have

67
00:02:35,389 --> 00:02:38,749
a second billing model that
you just have here, right?

68
00:02:38,749 --> 00:02:40,449
And on demand, I mean, the name

69
00:02:40,449 --> 00:02:42,229
is almost a little bit
misleading, right?

70
00:02:42,229 --> 00:02:44,070
If you demand it, it kind
of implies you get it,

71
00:02:44,070 --> 00:02:45,670
it's really kind of a
best effort, right?

72
00:02:45,670 --> 00:02:47,309
Whatever is left over, you get

73
00:02:47,309 --> 00:02:49,369
the CPU and memory for free.

74
00:02:49,369 --> 00:02:52,259
And then you'll be paid
be paying for Closs IO.

75
00:02:52,259 --> 00:02:53,899
And so we did on
demand billing for

76
00:02:53,899 --> 00:02:56,519
PA and all the
examples of semester.

77
00:02:56,519 --> 00:02:57,999
And because of that,

78
00:02:57,999 --> 00:02:59,879
the Closs SIO can be
measured in bytes,

79
00:02:59,879 --> 00:03:01,539
and that's why each query
we could look at and say,

80
00:03:01,539 --> 00:03:03,059
well, this is how many
bytes are processed.

81
00:03:03,059 --> 00:03:04,719
This is how much it will cost.

82
00:03:04,719 --> 00:03:07,960
So they can have two
complimentary billing models.

83
00:03:07,960 --> 00:03:09,199
Yeah, does that make sense?

84
00:03:09,199 --> 00:03:11,579
Yeah, there are
questions people have.

85
00:03:11,780 --> 00:03:14,339
There right here.

86
00:03:14,940 --> 00:03:17,859
Question 27? Absolutely, right?

87
00:03:17,859 --> 00:03:21,559
Let's take a look at
question 27. All right.

88
00:03:21,559 --> 00:03:24,040
So you want to do a streaming
group by with Spark,

89
00:03:24,040 --> 00:03:25,859
using a Kafka topic as a source.

90
00:03:25,859 --> 00:03:27,579
Great. Okay, the
column you want to

91
00:03:27,579 --> 00:03:29,340
group by in Spark
is different than

92
00:03:29,340 --> 00:03:31,399
the column used to

93
00:03:31,399 --> 00:03:34,220
set the key for the messages
and the Kata topic.

94
00:03:34,220 --> 00:03:36,860
Does Spark support such a query?

95
00:03:36,860 --> 00:03:39,079
The answer is, yes.

96
00:03:39,079 --> 00:03:41,040
It does support such a query.

97
00:03:41,040 --> 00:03:43,419
Anybody kind of walk me
through the details of

98
00:03:43,419 --> 00:03:46,620
how Spark would
execute such a query?

99
00:03:46,780 --> 00:03:56,789
There, right here. Basically
try to look at the keys.

100
00:03:56,789 --> 00:04:06,629
Mm Yeah, I guess,
like the first one.

101
00:04:06,629 --> 00:04:08,729
So there is kind of
some topic there,

102
00:04:08,729 --> 00:04:10,749
that has presumably some key

103
00:04:10,749 --> 00:04:11,890
and that means that
there's already

104
00:04:11,890 --> 00:04:15,230
a natural grouping to the
messages and the topics.

105
00:04:15,230 --> 00:04:17,990
However, that grouping is
not the one we want, right?

106
00:04:17,990 --> 00:04:19,670
I guess we did these
examples, for example,

107
00:04:19,670 --> 00:04:21,430
where we had animal
sightings and I was like,

108
00:04:21,430 --> 00:04:22,729
Well, animal sited on a beach,

109
00:04:22,729 --> 00:04:24,429
and it's a particular animal,

110
00:04:24,429 --> 00:04:26,809
you might want to do a group
by and count per beach

111
00:04:26,809 --> 00:04:29,370
or you might want to do
it by animal, right?

112
00:04:29,370 --> 00:04:31,190
If you're kind of doing
a group by query,

113
00:04:31,190 --> 00:04:32,589
which is like the same key

114
00:04:32,589 --> 00:04:34,670
that TOFCA has
already grouped on,

115
00:04:34,670 --> 00:04:36,810
that's a very easy
thing computationally

116
00:04:36,810 --> 00:04:39,109
to do because you don't have
to move any data around.

117
00:04:39,109 --> 00:04:40,909
So does anybody
want to elaborate?

118
00:04:40,909 --> 00:04:43,610
If we're trying to group
on a different key, right?

119
00:04:43,610 --> 00:04:45,070
Any thoughts on how

120
00:04:45,070 --> 00:04:47,990
Spark is going to be
execute that query?

121
00:04:47,990 --> 00:04:52,350
There are here. You just
shove the data around.

122
00:04:54,320 --> 00:04:58,739
S. Excellent.

123
00:04:58,739 --> 00:05:00,439
Yeah, we're going to have
to shuffle the data around

124
00:05:00,439 --> 00:05:02,440
to bring together
related data, right?

125
00:05:02,440 --> 00:05:03,800
So the data was already

126
00:05:03,800 --> 00:05:05,600
not shuffled into
the groups we want.

127
00:05:05,600 --> 00:05:08,859
So we'll have to shuffle
it into different groups.

128
00:05:08,859 --> 00:05:10,160
And the technique we
would use for that would

129
00:05:10,160 --> 00:05:11,720
be the hash partitioning, right?

130
00:05:11,720 --> 00:05:13,480
So, of course, like

131
00:05:13,480 --> 00:05:15,819
Spark has hash
partitioning baked into it

132
00:05:15,819 --> 00:05:17,580
because it's supposed to be

133
00:05:17,580 --> 00:05:20,040
any kind of SQL stuff
in general, right?

134
00:05:20,040 --> 00:05:23,080
And even if you just
have regular data,

135
00:05:23,080 --> 00:05:24,240
it's not streaming
or anything, you

136
00:05:24,240 --> 00:05:25,340
have to shuffle things around.

137
00:05:25,340 --> 00:05:27,120
And so it's very natural
that here we would just

138
00:05:27,120 --> 00:05:28,780
shuffle using a hash partition

139
00:05:28,780 --> 00:05:30,200
again, and then it can do that.

140
00:05:30,200 --> 00:05:32,959
It would be an advantage of
having Spark streaming be

141
00:05:32,959 --> 00:05:35,839
your consumer instead of
building a consumer yourself.

142
00:05:35,839 --> 00:05:37,340
If you were writing your
own, just kind of, like,

143
00:05:37,340 --> 00:05:39,500
raw python road to
consume these streams,

144
00:05:39,500 --> 00:05:41,939
it would be difficult
to do this operation.

145
00:05:41,939 --> 00:05:43,599
You have to implement
your own shuffle,

146
00:05:43,599 --> 00:05:45,419
which would be challenging?

147
00:05:45,419 --> 00:05:46,580
Yeah, great question.

148
00:05:46,580 --> 00:05:48,160
Yeah, all the
questions people have.

149
00:05:48,160 --> 00:05:50,160
Yeah, right here.

150
00:05:58,560 --> 00:06:00,920
So the first part
you said is correct.

151
00:06:00,920 --> 00:06:03,160
So Spark requires a shuffle.

152
00:06:03,160 --> 00:06:04,700
It does, in this case,
because the data is not

153
00:06:04,700 --> 00:06:06,400
already grouped the
way we want it,

154
00:06:06,400 --> 00:06:07,979
so I can shuffle to group
and how we want it.

155
00:06:07,979 --> 00:06:10,199
What was the second
piece you asked?

156
00:06:13,480 --> 00:06:17,860
Well, I guess you said is
Kafka more consistent?

157
00:06:17,860 --> 00:06:21,420
Maybe, like when I'm thinking
about consistent, I mean,

158
00:06:21,420 --> 00:06:23,119
there's like all these
different technical meanings,

159
00:06:23,119 --> 00:06:24,840
and you can define
it in terms of,

160
00:06:24,840 --> 00:06:26,440
like, you know,

161
00:06:26,440 --> 00:06:27,879
what does it mean for
somebody to be in sync?

162
00:06:27,879 --> 00:06:29,240
And I'm just like
a little bit, when

163
00:06:29,240 --> 00:06:30,459
you're using the
word consistent,

164
00:06:30,459 --> 00:06:32,379
I'm like maybe going
off the rails.

165
00:06:32,379 --> 00:06:33,600
I guess, do you mean,

166
00:06:33,600 --> 00:06:35,379
like consistent in
a technical sense,

167
00:06:35,379 --> 00:06:36,880
or do you mean something else?

168
00:06:36,880 --> 00:06:40,920
In a technical is
Kafka consistent?

169
00:06:40,920 --> 00:06:43,379
I don't know if I would
say it's more consistent.

170
00:06:43,379 --> 00:06:49,070
I mean, I guess,

171
00:06:49,070 --> 00:06:50,069
what we're ultimately trying

172
00:06:50,069 --> 00:06:51,169
to do is we're trying to produce

173
00:06:51,169 --> 00:06:53,810
correct results from the
Spark stream, right?

174
00:06:53,810 --> 00:06:55,009
Like, we want to do a query,

175
00:06:55,009 --> 00:06:56,389
and produce correct results.

176
00:06:56,389 --> 00:06:57,790
And the ways we might get

177
00:06:57,790 --> 00:06:59,969
correct results would be if
there are some messages that

178
00:06:59,969 --> 00:07:01,850
are like double counted or

179
00:07:01,850 --> 00:07:03,190
missed and it needs
to be correct

180
00:07:03,190 --> 00:07:04,349
even if some machines die.

181
00:07:04,349 --> 00:07:06,149
So, you know, in this case,

182
00:07:06,149 --> 00:07:07,789
Spark can take
advantage of KAFKA,

183
00:07:07,789 --> 00:07:09,010
right if somebody
dies, it can go

184
00:07:09,010 --> 00:07:10,750
back and replay it, right?

185
00:07:10,750 --> 00:07:12,470
So, so I don't want to say

186
00:07:12,470 --> 00:07:15,000
KAFKA is like more
consistent because well,

187
00:07:15,000 --> 00:07:17,369
Spark is taking advantage
of its features.

188
00:07:17,369 --> 00:07:19,029
And then Spark has
additional features

189
00:07:19,029 --> 00:07:20,490
that even if it goes back and

190
00:07:20,490 --> 00:07:22,350
replays it to
produce some output

191
00:07:22,350 --> 00:07:24,070
for some kinds of output,

192
00:07:24,070 --> 00:07:26,190
I can recognize, Oh, I have
these duplicate outputs,

193
00:07:26,190 --> 00:07:27,669
and I can suppress it, right?

194
00:07:27,669 --> 00:07:29,369
So we can produce

195
00:07:29,369 --> 00:07:32,569
correct output with
Spark on top of ACA,

196
00:07:32,569 --> 00:07:34,409
if we're writing to say Park.

197
00:07:34,409 --> 00:07:35,990
So I don't know if that quite

198
00:07:35,990 --> 00:07:37,630
answers the question, but Yeah.

199
00:07:37,630 --> 00:07:39,730
Yeah, they're working together,
so I don't want to say,

200
00:07:39,730 --> 00:07:41,910
one is more consistent,
right? Alright, C.

201
00:07:41,910 --> 00:07:43,830
Yeah are questions people have.

202
00:07:43,830 --> 00:07:46,050
Yeah, here.

203
00:07:54,210 --> 00:07:58,170
C two.

204
00:07:58,170 --> 00:08:02,370
There's currently three in one.

205
00:08:02,970 --> 00:08:10,000
Is it like a message two
res one liter Mm hm.

206
00:08:15,320 --> 00:08:18,960
Yeah. Okay. Excellent. Yeah, so

207
00:08:18,960 --> 00:08:20,800
the question that was
being raised was from

208
00:08:20,800 --> 00:08:23,159
Top Pad and maybe I'll just
write something similar

209
00:08:23,159 --> 00:08:26,340
since I don't have that
handy at the moment.

210
00:08:26,340 --> 00:08:29,380
But what we are
imagining, right,

211
00:08:29,380 --> 00:08:34,520
is that we have
different brokers,

212
00:08:34,520 --> 00:08:36,759
right that have different copies

213
00:08:36,759 --> 00:08:38,439
of the same partition, right?

214
00:08:38,439 --> 00:08:42,359
So maybe up here, I
have the leader, right?

215
00:08:43,320 --> 00:08:48,599
And then down here,
I have the follower.

216
00:08:48,680 --> 00:08:51,819
And then I have another
follower down here.

217
00:08:51,819 --> 00:08:55,139
Right. Now, we want the system
to keep working even if

218
00:08:55,139 --> 00:08:59,040
some followers are maybe

219
00:08:59,040 --> 00:09:01,219
either dead or they're
going to to solar.

220
00:09:01,219 --> 00:09:02,799
So we want to have some
tolerance for that.

221
00:09:02,799 --> 00:09:05,160
And but we want to

222
00:09:05,160 --> 00:09:08,119
identify which ones are in a
mostly healthy state, right?

223
00:09:08,119 --> 00:09:12,700
And so the leader will decide
which ones are n sync.

224
00:09:12,700 --> 00:09:14,500
And it can define
that different way.

225
00:09:14,500 --> 00:09:16,099
The more important
thing is that, it's

226
00:09:16,099 --> 00:09:17,480
very clear who is in sync,

227
00:09:17,480 --> 00:09:18,519
and then we're going to take

228
00:09:18,519 --> 00:09:19,859
action based on who
is in sync, right?

229
00:09:19,859 --> 00:09:21,419
So there's a little
bit wiggle room there.

230
00:09:21,419 --> 00:09:23,339
And so let's say

231
00:09:23,339 --> 00:09:27,195
that this one down here
is considered n sync.

232
00:09:27,195 --> 00:09:29,170
By the leader.

233
00:09:29,170 --> 00:09:32,169
And that's based on
this follower is

234
00:09:32,169 --> 00:09:33,649
doing a pretty good
job of keeping up

235
00:09:33,649 --> 00:09:35,669
with the messages that
are up here, right?

236
00:09:35,669 --> 00:09:37,070
And it doesn't have
to be perfect,

237
00:09:37,070 --> 00:09:38,190
but the leader
says, Okay, you're

238
00:09:38,190 --> 00:09:39,909
good enough you're
in sync, right?

239
00:09:39,909 --> 00:09:42,769
And so what I'm going to do
here is I'm going to say,

240
00:09:42,769 --> 00:09:44,850
let's say we have
some messages here.

241
00:09:44,850 --> 00:09:51,250
We have A B C and D. And
then the follower down here.

242
00:09:51,250 --> 00:09:56,809
Let's say this one has a B

243
00:09:56,809 --> 00:10:04,230
C. And then the one down
here has Let's just say AB.

244
00:10:04,850 --> 00:10:08,549
Right. And so we
want to say which

245
00:10:08,549 --> 00:10:11,889
of these messages are
committed, right?

246
00:10:11,889 --> 00:10:14,809
Because the producer
sent us the message.

247
00:10:14,809 --> 00:10:17,350
And maybe that producer

248
00:10:17,350 --> 00:10:18,989
is part of some
application actually,

249
00:10:18,989 --> 00:10:21,290
show something to
the user, right?

250
00:10:21,290 --> 00:10:22,949
If it's like a whatsap message,

251
00:10:22,949 --> 00:10:24,269
maybe I wrote it,
and then it will

252
00:10:24,269 --> 00:10:25,690
pop up and say, Okay, it's safe.

253
00:10:25,690 --> 00:10:27,429
There's a check mark by
or something like that.

254
00:10:27,429 --> 00:10:30,340
Or maybe if it doesn't
that Mark has committed,

255
00:10:30,340 --> 00:10:31,499
I might like hold on to

256
00:10:31,499 --> 00:10:32,940
the message and
retry later, right?

257
00:10:32,940 --> 00:10:38,339
So we ought to know, when can
we tell us like the sender,

258
00:10:38,339 --> 00:10:41,899
the producer, that a given
message is safe, right?

259
00:10:41,899 --> 00:10:44,520
And when it's safe,

260
00:10:44,520 --> 00:10:46,519
what we're thinking
about is, you know,

261
00:10:46,519 --> 00:10:47,780
replicas could die, and in

262
00:10:47,780 --> 00:10:49,059
particular, the
leader could die.

263
00:10:49,059 --> 00:10:51,439
The leader dying is the
worst worst case, right?

264
00:10:51,439 --> 00:10:53,640
So I want to say, Hey,
for a given message,

265
00:10:53,640 --> 00:10:56,619
if it dies, is that
message safe, right?

266
00:10:56,619 --> 00:10:59,479
And, um, Whoever is

267
00:10:59,479 --> 00:11:01,020
the leader has the authority

268
00:11:01,020 --> 00:11:03,219
on what message is at
each position, right?

269
00:11:03,219 --> 00:11:04,639
So, you know, if we

270
00:11:04,639 --> 00:11:06,960
somehow elected this
follower down here,

271
00:11:06,960 --> 00:11:10,179
we would have lost
C and D, right?

272
00:11:10,179 --> 00:11:11,879
And so if this follower down

273
00:11:11,879 --> 00:11:13,900
here is a candidate
for being the leader,

274
00:11:13,900 --> 00:11:16,479
then and this one's
dragging behind this.

275
00:11:16,479 --> 00:11:18,559
It's going to be really hard
to commit anything, right?

276
00:11:18,559 --> 00:11:20,639
And so the rule, right?

277
00:11:20,639 --> 00:11:23,079
The rule is that

278
00:11:23,079 --> 00:11:32,420
sync replicas are
candidates for leadership.

279
00:11:40,140 --> 00:11:42,999
Right? And kind of what
this means, right?

280
00:11:42,999 --> 00:11:44,379
Since the leader based on

281
00:11:44,379 --> 00:11:46,300
some metrics decides who's sync,

282
00:11:46,300 --> 00:11:47,719
then the leader is
really saying, Well,

283
00:11:47,719 --> 00:11:49,479
these are the other
nodes that could

284
00:11:49,479 --> 00:11:51,779
take over for me if I crash,

285
00:11:51,779 --> 00:11:53,219
and that information is stored

286
00:11:53,219 --> 00:11:54,659
in a separate system, right?

287
00:11:54,659 --> 00:11:55,580
So even though the leader

288
00:11:55,580 --> 00:11:57,379
decides that if the leader dies,

289
00:11:57,379 --> 00:11:59,480
we can kind of look
at those notes,

290
00:11:59,480 --> 00:12:00,599
and we can figure out, k, this

291
00:12:00,599 --> 00:12:02,360
is the one that is eligible.

292
00:12:02,360 --> 00:12:04,079
And so the problem here, right,

293
00:12:04,079 --> 00:12:06,200
is that if this sync follower

294
00:12:06,200 --> 00:12:08,119
becomes a leader and it
doesn't have message D,

295
00:12:08,119 --> 00:12:09,859
then D would have
been lost, right?

296
00:12:09,859 --> 00:12:13,499
So what this means is that
D is not committed, right?

297
00:12:13,499 --> 00:12:16,299
This is not committed because

298
00:12:16,780 --> 00:12:19,160
because one of the candidates

299
00:12:19,160 --> 00:12:21,779
for leadership doesn't
have it, right?

300
00:12:21,779 --> 00:12:23,060
And so when I think sync,

301
00:12:23,060 --> 00:12:24,499
I think candidate for
leadership, right?

302
00:12:24,499 --> 00:12:25,639
It's kind of a
funny word for it,

303
00:12:25,639 --> 00:12:27,919
but that's what I'm really
thinking to reason about it.

304
00:12:27,919 --> 00:12:30,659
Right? But this one
is committed, right?

305
00:12:32,980 --> 00:12:35,559
Alright. And so that's
the fundamental thing

306
00:12:35,559 --> 00:12:36,780
about how the system works.

307
00:12:36,780 --> 00:12:38,839
Now, there's this other detail

308
00:12:38,839 --> 00:12:41,439
about the men Sync
replicas, right?

309
00:12:41,439 --> 00:12:43,919
And when I hear that yc,

310
00:12:43,919 --> 00:12:45,559
just based on the name, I think,

311
00:12:45,559 --> 00:12:47,139
I and most people think, Oh,

312
00:12:47,139 --> 00:12:50,019
that's about kind of, you know,

313
00:12:50,019 --> 00:12:51,839
having some kind of minimum
replication factor,

314
00:12:51,839 --> 00:12:53,060
and it does that too.

315
00:12:53,060 --> 00:12:54,960
But The concern here,

316
00:12:54,960 --> 00:12:56,679
right is that if the
leaders going ahead and

317
00:12:56,679 --> 00:12:59,919
all the followers are kind
of starting to fall behind,

318
00:12:59,919 --> 00:13:01,559
right, then eventually
there will be

319
00:13:01,559 --> 00:13:03,699
no candidates for
leadership, right?

320
00:13:03,699 --> 00:13:05,879
If all the followers
get too far behind.

321
00:13:05,879 --> 00:13:07,400
And at some point, if the leader

322
00:13:07,400 --> 00:13:08,900
keeps taking all these messages,

323
00:13:08,900 --> 00:13:10,200
we're going to have a
worse and worse problem.

324
00:13:10,200 --> 00:13:11,919
So what the leader should
eventually do is send

325
00:13:11,919 --> 00:13:14,379
basically what's called a
back off message that says,

326
00:13:14,379 --> 00:13:17,360
Don't send me more
messages for a while.

327
00:13:17,360 --> 00:13:18,980
Lots of systems have
that webservers,

328
00:13:18,980 --> 00:13:20,499
for example, have like a 429.

329
00:13:20,499 --> 00:13:22,559
We see four oh four,
not available.

330
00:13:22,559 --> 00:13:24,359
Web servers have
429, which says,

331
00:13:24,359 --> 00:13:27,410
Hey, back off, don't retry
again for for a while.

332
00:13:27,410 --> 00:13:29,109
The producers are
expected to respect that.

333
00:13:29,109 --> 00:13:31,149
And so the Mint sinc
means that hey,

334
00:13:31,149 --> 00:13:31,709
like, we don't have

335
00:13:31,709 --> 00:13:33,569
as many followers that are
keep input as we want.

336
00:13:33,569 --> 00:13:35,530
Stop sending me
messages for a while,

337
00:13:35,530 --> 00:13:37,569
so they can catch up, right?

338
00:13:37,569 --> 00:13:40,409
So that detail is not so
much about correctness.

339
00:13:40,409 --> 00:13:42,549
It's more about, you know,

340
00:13:42,549 --> 00:13:44,390
we don't want the system
to get too far behind.

341
00:13:44,390 --> 00:13:47,690
You can imagine throwing away
that tail about me Ncinc.

342
00:13:47,690 --> 00:13:49,449
And then it would just
kind of, like, you

343
00:13:49,449 --> 00:13:50,989
know, run away, right?

344
00:13:50,989 --> 00:13:52,410
We would never
elect a bad leader,

345
00:13:52,410 --> 00:13:53,369
but eventually, there might be

346
00:13:53,369 --> 00:13:54,910
no candidates for leadership.

347
00:13:54,910 --> 00:13:55,570
That makes sense.

348
00:13:55,570 --> 00:13:57,089
The Mint inc is about
making sure we have

349
00:13:57,089 --> 00:14:00,470
enough candidates for
future leadership.

350
00:14:00,470 --> 00:14:09,349
Follow. Yeah. Like
message she sort of

351
00:14:09,349 --> 00:14:18,639
committed and she was
left followed Mm hm.

352
00:14:19,720 --> 00:14:23,339
Okay, great. So you're saying
that this leader dies,

353
00:14:23,339 --> 00:14:27,919
and now this follower becomes
the new leader, right?

354
00:14:27,919 --> 00:14:29,760
And then you're
saying the original

355
00:14:29,760 --> 00:14:32,019
leader comes back, right?

356
00:14:32,019 --> 00:14:34,779
Yeah. And first of all,

357
00:14:34,779 --> 00:14:35,940
have you said what happens to D,

358
00:14:35,940 --> 00:14:38,799
and the simple answer
is, it's gone, right?

359
00:14:38,799 --> 00:14:40,199
This one that's
now the leader is

360
00:14:40,199 --> 00:14:42,599
the authority on what
is in the log, right?

361
00:14:42,599 --> 00:14:44,839
So D is lost forever, right?

362
00:14:44,839 --> 00:14:46,920
Okay. Now, I mean,
there's a whole bunch of

363
00:14:46,920 --> 00:14:48,339
other details that
we kind of glossed

364
00:14:48,339 --> 00:14:49,819
over because, you know,

365
00:14:49,819 --> 00:14:51,979
I guess if this were like a you

366
00:14:51,979 --> 00:14:54,059
can imagine a similar class
be like distribute systems,

367
00:14:54,059 --> 00:14:55,379
and we focus more
on those details.

368
00:14:55,379 --> 00:14:57,239
We're trying to focus more
on the big data aspect,

369
00:14:57,239 --> 00:14:58,160
but it is interesting.

370
00:14:58,160 --> 00:14:59,899
L, what would happen if
that other one comes back,

371
00:14:59,899 --> 00:15:01,459
and then they both

372
00:15:01,459 --> 00:15:03,380
think they're the leader
what could happen there?

373
00:15:03,380 --> 00:15:06,239
There's techniques people
have for that, for example,

374
00:15:06,239 --> 00:15:08,340
you can have something
called a lease

375
00:15:08,340 --> 00:15:09,800
where you can say, like, Oh,

376
00:15:09,800 --> 00:15:11,459
like, you are the leader for

377
00:15:11,459 --> 00:15:13,699
the next 10 seconds, guaranteed.

378
00:15:13,699 --> 00:15:14,579
And if you kind of, like,

379
00:15:14,579 --> 00:15:15,959
are offline for a while
and you come back,

380
00:15:15,959 --> 00:15:17,239
you'll know if your
lease expired,

381
00:15:17,239 --> 00:15:18,979
and so you have to go
out to system and say,

382
00:15:18,979 --> 00:15:21,399
can I renew this lease, right?

383
00:15:21,399 --> 00:15:24,839
So it might be the
lease time where we

384
00:15:24,839 --> 00:15:29,320
cannot fully make the
new follow the leader,

385
00:15:29,320 --> 00:15:31,140
but there are techniques
to make sure they aren't

386
00:15:31,140 --> 00:15:32,440
both trying to be the leader

387
00:15:32,440 --> 00:15:34,080
at the same time, if
that makes sense.

388
00:15:34,080 --> 00:15:36,900
Yeah. So anyway, so the new
leader is the authority.

389
00:15:36,900 --> 00:15:39,460
It doesn't matter that the old
leader had extra messages.

390
00:15:39,460 --> 00:15:40,999
Those are lost forever, which is

391
00:15:40,999 --> 00:15:42,700
fine because we never
said they were committed.

392
00:15:42,700 --> 00:15:45,460
Right. It's okay to lose
something that's not committed.

393
00:15:45,460 --> 00:15:46,959
Yeah, lots of great questions.

394
00:15:46,959 --> 00:15:48,979
Yeah, the are
questions people have.

395
00:15:52,090 --> 00:15:54,890
Yeah, right back here.

396
00:15:55,370 --> 00:16:00,309
Planet. Yeah. So the
general question is,

397
00:16:00,309 --> 00:16:01,449
like, can we like, you know,

398
00:16:01,449 --> 00:16:04,189
how does the planet
algorithm work?

399
00:16:04,189 --> 00:16:08,869
So the planet algorithm is
for decision trees, right?

400
00:16:08,869 --> 00:16:10,569
Maybe I should just
bring up some slides

401
00:16:10,569 --> 00:16:11,669
and we can kind of
go over it very

402
00:16:11,669 --> 00:16:15,330
quickly if that
would be helpful.

403
00:16:15,330 --> 00:16:17,169
Let me

404
00:16:40,620 --> 00:16:43,179
Was it this one?

405
00:16:49,060 --> 00:16:52,099
Yeah, yeah, here it was.

406
00:16:52,820 --> 00:16:55,359
So, generally, what
are we trying to do?

407
00:16:55,359 --> 00:16:58,679
Like, we want to build a
decision tree like this,

408
00:16:58,679 --> 00:17:00,259
and every node in the tree

409
00:17:00,259 --> 00:17:01,999
asked a question about
the data, like, you know,

410
00:17:01,999 --> 00:17:04,019
is x greater than five,

411
00:17:04,019 --> 00:17:06,280
if it's a numeric thing or maybe

412
00:17:06,280 --> 00:17:09,720
is y equal to a, if
it's categorical.

413
00:17:09,720 --> 00:17:12,720
And so as we're building this
tree at any given point,

414
00:17:12,720 --> 00:17:14,239
I hope nobody can see it, they?

415
00:17:14,239 --> 00:17:16,199
Yeah, feel free to
just, you know,

416
00:17:16,199 --> 00:17:19,359
shout out if I'm ever
not showing stuff.

417
00:17:19,359 --> 00:17:22,040
At A given point, we have
a partially complete tree.

418
00:17:22,040 --> 00:17:24,240
What we want to do is, we
finalize the top parts,

419
00:17:24,240 --> 00:17:26,680
and we keep growing it down

420
00:17:26,680 --> 00:17:30,520
until we have relatively
few rows at each each node.

421
00:17:30,520 --> 00:17:32,379
There might be other
stopping conditions, right?

422
00:17:32,379 --> 00:17:34,739
And so one of the key
characteristics of

423
00:17:34,739 --> 00:17:37,699
this is it's hybrid, right?

424
00:17:37,699 --> 00:17:42,390
Sometimes a given node
doesn't have very many rows.

425
00:17:42,390 --> 00:17:44,449
And we have few enough
rows that they could all

426
00:17:44,449 --> 00:17:46,649
fit into memory on
one machine, right?

427
00:17:46,649 --> 00:17:49,110
And the classic decision
tree training algorithm,

428
00:17:49,110 --> 00:17:51,469
it just works in memory
on one machine, right?

429
00:17:51,469 --> 00:17:52,649
And so when that happens, when I

430
00:17:52,649 --> 00:17:53,830
have a few rows in one place,

431
00:17:53,830 --> 00:17:56,549
I want to bring
together all the rows

432
00:17:56,549 --> 00:17:58,989
for the same node, right?

433
00:17:58,989 --> 00:18:01,850
And so just looking at
this picture over here,

434
00:18:03,500 --> 00:18:05,699
The way we'll do that is we will

435
00:18:05,699 --> 00:18:07,279
hash partition our data, right?

436
00:18:07,279 --> 00:18:08,520
Whenever you hash
partition your data,

437
00:18:08,520 --> 00:18:09,860
you bring together related data.

438
00:18:09,860 --> 00:18:11,179
The interesting
question is, well,

439
00:18:11,179 --> 00:18:13,599
what is the key that
we're hashing over?

440
00:18:13,599 --> 00:18:16,019
And that is what node
you're in, right?

441
00:18:16,019 --> 00:18:17,539
So I can look at a given row,

442
00:18:17,539 --> 00:18:19,100
and given the decision tree,

443
00:18:19,100 --> 00:18:21,084
I can say, Oh, this is a node.

444
00:18:21,084 --> 00:18:24,869
F. Oh, that row is
a node A, right?

445
00:18:24,869 --> 00:18:28,189
I can do that. And then
when I has partition it,

446
00:18:28,189 --> 00:18:29,669
I can say, Well,
what is the hash

447
00:18:29,669 --> 00:18:32,069
of F? I get some number.

448
00:18:32,069 --> 00:18:33,670
If I want like four partitions,

449
00:18:33,670 --> 00:18:35,169
and I'll mod that
number by four,

450
00:18:35,169 --> 00:18:37,010
and I can bring together
all the related data.

451
00:18:37,010 --> 00:18:39,110
Once I bring together
all the related data,

452
00:18:39,110 --> 00:18:40,770
then I can run

453
00:18:40,770 --> 00:18:43,089
the classic decision
tree algorithm, right?

454
00:18:43,089 --> 00:18:44,529
So that was one piece.
The other piece of

455
00:18:44,529 --> 00:18:46,869
the hybrid one is when
we have Big nodes.

456
00:18:46,869 --> 00:18:51,050
And when we have big
nodes, First off,

457
00:18:51,050 --> 00:18:52,349
we don't want to
shuffle all that

458
00:18:52,349 --> 00:18:54,369
data over the network because

459
00:18:54,369 --> 00:18:58,310
it's expensive to move all
these kind of all these rows.

460
00:18:58,310 --> 00:18:59,889
There's a lot of them
by definition, right?

461
00:18:59,889 --> 00:19:02,289
Even if we do move
them over the network,

462
00:19:02,289 --> 00:19:04,269
the reason I'd want to
do that would be to

463
00:19:04,269 --> 00:19:06,010
bring together all the ones
that are in the same node,

464
00:19:06,010 --> 00:19:07,069
but there's no machine that has

465
00:19:07,069 --> 00:19:08,429
enough memory for it, right?

466
00:19:08,429 --> 00:19:09,989
And so what we have to
somehow do is we have to

467
00:19:09,989 --> 00:19:11,869
look at all these big
nodes, and we have to say,

468
00:19:11,869 --> 00:19:14,829
is there a way to have a
good split point that I can

469
00:19:14,829 --> 00:19:18,190
calculate without actually
shuffling it around?

470
00:19:18,190 --> 00:19:20,109
And so way we do that is we

471
00:19:20,109 --> 00:19:22,809
compute some statistics based
on each of them, right?

472
00:19:22,809 --> 00:19:24,389
So rather than actually
sending the rows,

473
00:19:24,389 --> 00:19:27,109
we send some summary
statistics, right?

474
00:19:27,109 --> 00:19:30,079
And, In general, like,

475
00:19:30,079 --> 00:19:31,920
what we're trying to do
is we're trying to choose

476
00:19:31,920 --> 00:19:35,020
a split point that
reduces impurity.

477
00:19:35,020 --> 00:19:36,479
And impurity could
be something like

478
00:19:36,479 --> 00:19:39,259
variance or there's other
metrics like entropy.

479
00:19:39,259 --> 00:19:41,779
What we want to do is, if
it's like categorical,

480
00:19:41,779 --> 00:19:42,979
where I'm predicting yes or no,

481
00:19:42,979 --> 00:19:44,019
I want to have one branch of

482
00:19:44,019 --> 00:19:45,119
the tree where I
have all the yes,

483
00:19:45,119 --> 00:19:47,219
another branch of the tree
where I have all the nose.

484
00:19:47,219 --> 00:19:49,099
And so what we will do

485
00:19:49,099 --> 00:19:51,580
is we will consider every
possible split point.

486
00:19:51,580 --> 00:19:53,134
Right? A split point is

487
00:19:53,134 --> 00:19:55,269
combination of a
variable like X one,

488
00:19:55,269 --> 00:19:57,709
x2x3 plus some threshold.

489
00:19:57,709 --> 00:19:59,470
The thresholds are not 012,

490
00:19:59,470 --> 00:20:01,030
but I've just assigned indexes

491
00:20:01,030 --> 00:20:02,589
to those thresholds, right?

492
00:20:02,589 --> 00:20:05,230
So for every possible
split point,

493
00:20:05,230 --> 00:20:07,049
I can compute some
stats about that.

494
00:20:07,049 --> 00:20:08,749
And I get partial stats

495
00:20:08,749 --> 00:20:11,749
across all of these different
partitions of the data,

496
00:20:11,749 --> 00:20:13,529
I can sum all of
those up together,

497
00:20:13,529 --> 00:20:15,069
and then I can say,

498
00:20:15,069 --> 00:20:17,169
Well, given those stats about

499
00:20:17,169 --> 00:20:20,129
any possible split point,
which one is best, right?

500
00:20:20,129 --> 00:20:21,749
So I can say, I want to have

501
00:20:21,749 --> 00:20:24,349
a new split point without

502
00:20:24,349 --> 00:20:26,150
actually having to
shuffle the data around.

503
00:20:26,150 --> 00:20:28,549
So that kind of the big
overview you're looking for?

504
00:20:28,549 --> 00:20:30,149
Yeah. People have any
follow up questions

505
00:20:30,149 --> 00:20:32,389
on that or other questions.

506
00:20:43,020 --> 00:20:45,299
Right here.

507
00:20:50,500 --> 00:21:04,819
Class

508
00:21:04,819 --> 00:21:06,139
right now.

509
00:21:07,300 --> 00:21:11,120
Yeah. Yeah. So the question
is about threads and locks.

510
00:21:11,120 --> 00:21:14,419
Okay. So context I shot context.

511
00:21:14,419 --> 00:21:16,079
We're done talking
about plan right

512
00:21:16,079 --> 00:21:18,579
now we're talking
about reads and locks.

513
00:21:18,900 --> 00:21:23,119
The rule with Locks
is that I can't have

514
00:21:23,119 --> 00:21:24,579
two different threads holding

515
00:21:24,579 --> 00:21:27,899
the same lock at the
same time, right?

516
00:21:27,899 --> 00:21:29,879
And that's all you
get. Sometimes people

517
00:21:29,879 --> 00:21:31,839
think that locks are
doing more than that,

518
00:21:31,839 --> 00:21:33,599
but you should just,
like, remember that.

519
00:21:33,599 --> 00:21:34,899
I can't have two threads

520
00:21:34,899 --> 00:21:36,279
holding the same lock
at the same time.

521
00:21:36,279 --> 00:21:39,099
That's all we get.
So for example,

522
00:21:39,099 --> 00:21:43,380
if one thread is holding a lock,

523
00:21:43,380 --> 00:21:45,319
but maybe like the
other thread is buggy,

524
00:21:45,319 --> 00:21:48,060
and it doesn't hold a lock,
it could inter leave.

525
00:21:48,060 --> 00:21:49,989
It could run at
the same same time

526
00:21:49,989 --> 00:21:51,669
because only one of them is
holding the lock, right?

527
00:21:51,669 --> 00:21:53,449
The code is only going
to work if they are

528
00:21:53,449 --> 00:21:56,370
both if they both try
to acquire a lock.

529
00:21:56,370 --> 00:21:58,489
You know, I could have
different locks, right?

530
00:21:58,489 --> 00:22:00,189
So in that case,
I'd really want to

531
00:22:00,189 --> 00:22:01,870
make sure I can
context switch away

532
00:22:01,870 --> 00:22:03,930
from the current
thread because maybe

533
00:22:03,930 --> 00:22:05,270
the other threads
are doing things

534
00:22:05,270 --> 00:22:06,849
that are touching
different variables.

535
00:22:06,849 --> 00:22:07,929
Maybe they don't
need a lock because

536
00:22:07,929 --> 00:22:09,189
they're doing
something unrelated to

537
00:22:09,189 --> 00:22:10,449
shared data structures or

538
00:22:10,449 --> 00:22:12,489
maybe they're touching
different stuff, right?

539
00:22:12,489 --> 00:22:14,889
So holding a lock
does not prevent you

540
00:22:14,889 --> 00:22:16,349
from context switching or

541
00:22:16,349 --> 00:22:17,929
running something else
from at the same time.

542
00:22:17,929 --> 00:22:20,569
It just prevents you from
having two pieces of

543
00:22:20,569 --> 00:22:21,970
code from holding that lock

544
00:22:21,970 --> 00:22:23,689
at the same time. That's
the only thing we get.

545
00:22:23,689 --> 00:22:25,970
Does that make sense?
Yeah, great question.

546
00:22:25,970 --> 00:22:27,829
Yeah, a lot of people
get thrown off on that.

547
00:22:27,829 --> 00:22:29,969
Threat and lock stuff is
definitely very tricky.

548
00:22:29,969 --> 00:22:32,149
Yeah, are questions people have.

549
00:22:32,149 --> 00:22:34,630
Yeah, right here.

550
00:22:44,400 --> 00:22:46,539
Oh, okay. Great question.

551
00:22:46,539 --> 00:22:48,899
So the question is about
dictionary and toting.

552
00:22:48,899 --> 00:22:50,579
And we learned about

553
00:22:50,579 --> 00:22:52,239
dictionary and toting
kind of at the end.

554
00:22:52,239 --> 00:22:55,439
A little bit of the history
here was that there were

555
00:22:55,439 --> 00:22:58,999
a few there were a few
formats. All right.

556
00:22:58,999 --> 00:23:00,759
And so the format,

557
00:23:00,759 --> 00:23:02,439
you kind of like draw
a little picture over

558
00:23:02,439 --> 00:23:04,779
here that happened
at Dugal, right?

559
00:23:04,779 --> 00:23:06,320
And so, you know, first,

560
00:23:06,320 --> 00:23:09,439
they had a Column Mo at Dugal,

561
00:23:09,439 --> 00:23:12,300
and they used that with
the Dremel engine.

562
00:23:12,300 --> 00:23:13,859
Does you remeber why
Dremel is important?

563
00:23:13,859 --> 00:23:17,740
Like what is Dremel used
inside of Big query Excellent.

564
00:23:17,740 --> 00:23:19,499
So Dremel is the SQL
engine that they ended up,

565
00:23:19,499 --> 00:23:21,840
you know, kind of packaging
up Iseling is big query.

566
00:23:21,840 --> 00:23:25,239
And so this at Google
inspired the public format,

567
00:23:25,239 --> 00:23:26,979
which is Park, right?

568
00:23:26,979 --> 00:23:30,180
And inspired Park, which
we've been using a bunch.

569
00:23:30,180 --> 00:23:31,879
And then eventually, right,

570
00:23:31,879 --> 00:23:33,080
it evolved at Google into

571
00:23:33,080 --> 00:23:34,599
something called the
Capacitor format.

572
00:23:34,599 --> 00:23:37,339
So capacitor format.

573
00:23:37,339 --> 00:23:39,359
And, you know, a couple
of the features.

574
00:23:39,359 --> 00:23:40,500
I'm sure they did
a bunch of stuff,

575
00:23:40,500 --> 00:23:42,639
but a couple of the
features I know about

576
00:23:42,639 --> 00:23:48,359
are dictionary and Tading
and run length Tading.

577
00:23:49,670 --> 00:23:52,609
Those are the two
totings that they do.

578
00:23:52,609 --> 00:23:54,449
And these are
independent, right?

579
00:23:54,449 --> 00:23:57,609
You could have one or the
other or both or neither.

580
00:23:57,609 --> 00:24:00,349
And so let me just try to
talk about what they do.

581
00:24:00,349 --> 00:24:03,589
Dictionary tooting is
really useful if I have,

582
00:24:03,589 --> 00:24:08,009
some large strings or
maybe if I have bites,

583
00:24:08,009 --> 00:24:09,009
maybe like the bytes are

584
00:24:09,009 --> 00:24:10,529
for images or
something like that.

585
00:24:10,529 --> 00:24:12,269
And so not only do I have,

586
00:24:12,269 --> 00:24:14,460
kind of these long values,

587
00:24:14,460 --> 00:24:15,879
but they are repeated, right?

588
00:24:15,879 --> 00:24:17,480
So maybe I have this
long string that shows

589
00:24:17,480 --> 00:24:19,379
up many different
different times, right?

590
00:24:19,379 --> 00:24:21,419
And so that's a little
bit wasteful, right?

591
00:24:21,419 --> 00:24:23,279
To kind of have these big
strings that are repeated.

592
00:24:23,279 --> 00:24:25,939
The data is bigger, you know,

593
00:24:25,939 --> 00:24:28,539
I might not fit into a
CPU cash as well, right?

594
00:24:28,539 --> 00:24:30,019
And so the idea
of dictionary and

595
00:24:30,019 --> 00:24:32,560
toting is that for
each unique value,

596
00:24:32,560 --> 00:24:33,979
put it as a value
in a dictionary,

597
00:24:33,979 --> 00:24:37,399
and then assigned it like a
numeric lookup value, right?

598
00:24:37,399 --> 00:24:40,560
So, maybe maybe like the string,

599
00:24:40,560 --> 00:24:43,440
Madison, Wisconsin, appears a
lot of times in my dataset.

600
00:24:43,440 --> 00:24:45,509
I'll say that, you know,

601
00:24:45,509 --> 00:24:48,340
Tad five is Madison, Wisconsin,

602
00:24:48,340 --> 00:24:49,679
and five is short, and so I can

603
00:24:49,679 --> 00:24:51,699
have five in a bunch
of places, right?

604
00:24:51,699 --> 00:24:56,799
So that would be an example
of dictionary toting, right?

605
00:24:56,799 --> 00:25:00,940
Run length and toting
happens is may be useful,

606
00:25:00,940 --> 00:25:02,319
especially when my
data is sorted,

607
00:25:02,319 --> 00:25:03,940
right if I am
looking at my data,

608
00:25:03,940 --> 00:25:06,320
and it's like, you
know, five, five, five,

609
00:25:06,320 --> 00:25:10,640
five, seven, seven,
seven, 77, seven,

610
00:25:10,640 --> 00:25:12,480
rather than repeating
all those values,

611
00:25:12,480 --> 00:25:14,320
I could say something like
there's like four, five,

612
00:25:14,320 --> 00:25:18,139
so there are six, seven,
something like that, right?

613
00:25:18,139 --> 00:25:20,440
And so you can imagine,

614
00:25:20,920 --> 00:25:23,459
Is five an actual value,

615
00:25:23,459 --> 00:25:25,139
or is five an entry in

616
00:25:25,139 --> 00:25:27,339
a dictionary either
would be fine, right?

617
00:25:27,339 --> 00:25:29,039
So you can use these features in

618
00:25:29,039 --> 00:25:31,060
combination or you can use
them each individually.

619
00:25:31,060 --> 00:25:33,939
Does that make sense?
Yeah, question.

620
00:25:33,939 --> 00:25:36,639
Yeah. Other questions
people have.

621
00:25:36,680 --> 00:25:39,239
Yeah, right here.

622
00:25:43,920 --> 00:25:49,719
Semester Yeah.

623
00:25:49,719 --> 00:25:52,340
Exam two for this
semester, question 11,

624
00:25:52,340 --> 00:26:01,959
and that's version one
of the exam or science.

625
00:26:02,240 --> 00:26:07,660
I'm curious like to
speak of the details.

626
00:26:07,660 --> 00:26:11,259
Oh, per cluster

627
00:26:11,259 --> 00:26:19,000
per file.

628
00:26:19,000 --> 00:26:21,399
Okay, great. This
one right here.

629
00:26:21,399 --> 00:26:22,980
So what granularity can the user

630
00:26:22,980 --> 00:26:25,600
specify the block size in HDFS?

631
00:26:25,600 --> 00:26:29,860
And the answer is per file.

632
00:26:29,860 --> 00:26:31,600
And there's not a
fundamental reason.

633
00:26:31,600 --> 00:26:33,799
It's just like we the
people who built HDFS,

634
00:26:33,799 --> 00:26:37,139
that's that's what
they did, right?

635
00:26:37,139 --> 00:26:38,880
You could have imagined

636
00:26:38,880 --> 00:26:40,100
that they could have
just said, Hey,

637
00:26:40,100 --> 00:26:41,440
you create this
cluster, you choose

638
00:26:41,440 --> 00:26:42,699
a replication for everything.

639
00:26:42,699 --> 00:26:45,159
I mean, it's kind of
nice that they make it p

640
00:26:45,159 --> 00:26:49,399
file because You know,

641
00:26:49,399 --> 00:26:50,979
there are good reasons
why I might want to have

642
00:26:50,979 --> 00:26:52,900
files with different
replication factors,

643
00:26:52,900 --> 00:26:54,979
and it's nice that I can
just put them all on

644
00:26:54,979 --> 00:26:56,859
the same HS cluster instead of

645
00:26:56,859 --> 00:26:59,440
having to create
different HDFS clusters.

646
00:26:59,440 --> 00:27:01,720
So for example, if I just
have some data that's

647
00:27:01,720 --> 00:27:04,099
time sitting there long term,

648
00:27:04,099 --> 00:27:05,559
three is a common choice, right?

649
00:27:05,559 --> 00:27:08,660
Maybe I want to
have three copies

650
00:27:08,660 --> 00:27:11,079
of all that for all
those files there.

651
00:27:11,079 --> 00:27:12,539
Now, I might have some special

652
00:27:12,539 --> 00:27:13,740
case where I want more or less.

653
00:27:13,740 --> 00:27:17,100
L, what if I am based on
that original data set?

654
00:27:17,100 --> 00:27:18,760
What if I have a
derivative data set,

655
00:27:18,760 --> 00:27:20,400
for example, by derivative,

656
00:27:20,400 --> 00:27:21,920
I mean that it's just like, Hey,

657
00:27:21,920 --> 00:27:23,759
I do some computation
on this original thing

658
00:27:23,759 --> 00:27:25,420
to produce the second data set.

659
00:27:25,420 --> 00:27:27,300
Maybe maybe like
the secondary data

660
00:27:27,300 --> 00:27:28,539
set that's derivative is like

661
00:27:28,539 --> 00:27:31,919
the first dataset where I'm
applying some kind of filter.

662
00:27:31,919 --> 00:27:34,540
For that data,
maybe it's a little

663
00:27:34,540 --> 00:27:36,439
wasteful to have three
time replication factor

664
00:27:36,439 --> 00:27:37,860
because if I lose the data,

665
00:27:37,860 --> 00:27:39,399
I can just recompute it,

666
00:27:39,399 --> 00:27:40,659
right from the source, right?

667
00:27:40,659 --> 00:27:42,180
So maybe there I decide h,

668
00:27:42,180 --> 00:27:43,499
like, two or one
is enough, right?

669
00:27:43,499 --> 00:27:45,009
So it's kind of nice when I have

670
00:27:45,009 --> 00:27:46,309
that derivative
dataset that doesn't

671
00:27:46,309 --> 00:27:47,510
need as high a
replication factor,

672
00:27:47,510 --> 00:27:49,509
I can just have it
in the same cluster

673
00:27:49,509 --> 00:27:54,609
or maybe like this data
is super valuable, right?

674
00:27:54,609 --> 00:27:55,970
I'm very paranoid
about it, maybe

675
00:27:55,970 --> 00:27:57,529
I have a higher
replication factor,

676
00:27:57,529 --> 00:28:00,849
or maybe the data
is really popular.

677
00:28:00,849 --> 00:28:02,789
Like People are reading
it so much that I

678
00:28:02,789 --> 00:28:05,110
don't want to just have
three data nodes overloaded.

679
00:28:05,110 --> 00:28:07,349
I want to have like a ten
times replication factor,

680
00:28:07,349 --> 00:28:08,869
so there's more nodes that

681
00:28:08,869 --> 00:28:10,909
can help service
reads to it, right?

682
00:28:10,909 --> 00:28:14,040
So it's nice that they
let me do it a profile,

683
00:28:14,040 --> 00:28:16,819
and, you know, just kind
of what they chose.

684
00:28:16,819 --> 00:28:18,280
Now, what about a key space?

685
00:28:18,280 --> 00:28:20,679
So a key space is not
a concept in HDFS.

686
00:28:20,679 --> 00:28:22,759
That's a concept in Cassandra.

687
00:28:22,759 --> 00:28:26,200
And a keyspace is a
collection of tables.

688
00:28:26,200 --> 00:28:28,180
And in Cassandra, they specify

689
00:28:28,180 --> 00:28:29,879
the replication factor at

690
00:28:29,879 --> 00:28:33,119
the granularity of
the keyspace, right?

691
00:28:33,119 --> 00:28:34,699
And there as well, right?

692
00:28:34,699 --> 00:28:36,779
That's just kind of, like
an arbitrary decision

693
00:28:36,779 --> 00:28:38,559
they made. You could imagine.

694
00:28:38,559 --> 00:28:39,799
I mean, it would be
an improvement to

695
00:28:39,799 --> 00:28:41,199
Cassandra if you
could start studying

696
00:28:41,199 --> 00:28:42,759
the replication factor per

697
00:28:42,759 --> 00:28:44,439
table per key space, but, like,

698
00:28:44,439 --> 00:28:47,299
the people building these
systems just decide you know,

699
00:28:47,299 --> 00:28:49,259
how much complexity
they want to build and

700
00:28:49,259 --> 00:28:52,159
how much flexibility comes
with that complexity.

701
00:28:52,159 --> 00:28:52,654
Right?

702
00:28:52,654 --> 00:28:54,629
Yeah, thanks for asking
other questions people

703
00:28:54,629 --> 00:28:55,789
have.

704
00:29:04,430 --> 00:29:07,070
Yeah, go ahead.

705
00:29:20,940 --> 00:29:27,919
A two. Yeah.

706
00:29:27,919 --> 00:29:29,959
Okay, let's talk about
this a little bit

707
00:29:29,959 --> 00:29:31,079
broadly and I can hear

708
00:29:31,079 --> 00:29:33,259
your thoughts. I'll
come back to that.

709
00:29:33,340 --> 00:29:36,180
So first off, you said that hey,

710
00:29:36,180 --> 00:29:38,019
these two kind of have the
data in the same format,

711
00:29:38,019 --> 00:29:41,620
but you said this one has
two copies of the data,

712
00:29:41,620 --> 00:29:43,519
and this one has one
copy of the data, right?

713
00:29:43,519 --> 00:29:45,379
This one has copies in
different machines.

714
00:29:45,379 --> 00:29:46,919
That's just kind of a
naming standard, right.

715
00:29:46,919 --> 00:29:49,339
There's three different
modes that I asked to

716
00:29:49,339 --> 00:29:50,379
do remember the semester and

717
00:29:50,379 --> 00:29:51,759
each of them come
in pairs, right?

718
00:29:51,759 --> 00:29:54,159
It's like the two or
not, there's six total.

719
00:29:54,159 --> 00:30:01,059
Okay. Maybe before we talk
about the load balance aspect,

720
00:30:01,300 --> 00:30:06,119
Can they remind me
what the other two L,

721
00:30:06,119 --> 00:30:08,099
instead of memory only,
what were the other two

722
00:30:08,099 --> 00:30:12,020
that we learned the semester?

723
00:30:15,740 --> 00:30:18,420
Yeah, one with SCR,

724
00:30:18,420 --> 00:30:20,079
that's short for
sterilization, right?

725
00:30:20,079 --> 00:30:22,380
And the difference there is
that when it's memory only,

726
00:30:22,380 --> 00:30:24,579
it has, like, all these
JVM types because,

727
00:30:24,579 --> 00:30:27,240
um, because Spark is built

728
00:30:27,240 --> 00:30:30,400
on Scala and Scala
compiles to the JVM code.

729
00:30:30,400 --> 00:30:32,400
And, you know, these job

730
00:30:32,400 --> 00:30:34,199
JVM types are
notoriously bloated,

731
00:30:34,199 --> 00:30:35,659
like strings are bloated.

732
00:30:35,659 --> 00:30:38,059
You know, integers maybe have

733
00:30:38,059 --> 00:30:39,279
this big overhead if

734
00:30:39,279 --> 00:30:41,120
it's like the object
instead of the primitive.

735
00:30:41,120 --> 00:30:43,579
And so what they
want to do is they

736
00:30:43,579 --> 00:30:46,279
want to serialize it to a
very compact byte format,

737
00:30:46,279 --> 00:30:47,540
that doesn't have
all this waste.

738
00:30:47,540 --> 00:30:50,059
But then all the scala
code compute over.

739
00:30:50,059 --> 00:30:51,680
So with the serialized version,

740
00:30:51,680 --> 00:30:54,879
maybe it might be like four
or five times smaller,

741
00:30:54,879 --> 00:30:56,979
but then I have to do extra
compute to switch it back.

742
00:30:56,979 --> 00:30:58,820
X. That was one of
the other ones.

743
00:30:58,820 --> 00:31:00,659
What was the other
one that we have?

744
00:31:00,659 --> 00:31:03,400
So we have memory memory only

745
00:31:03,400 --> 00:31:07,059
serialized and disc
only excellent, right?

746
00:31:07,059 --> 00:31:09,080
And so, in that case, if
I'm really tight on memory,

747
00:31:09,080 --> 00:31:10,520
right, I might write
it to local disk,

748
00:31:10,520 --> 00:31:12,439
that's still going to be
faster to access than say,

749
00:31:12,439 --> 00:31:15,039
like going through
HDFS again, right?

750
00:31:15,039 --> 00:31:17,619
Or maybe doing a bunch of
computation to get that.

751
00:31:17,619 --> 00:31:19,080
All right. So those are
the three different ones.

752
00:31:19,080 --> 00:31:21,359
And for each of those, it
can be just a single copy,

753
00:31:21,359 --> 00:31:24,019
or it can be two copies, right?

754
00:31:24,019 --> 00:31:25,960
And then what is load?

755
00:31:25,960 --> 00:31:27,339
I guess it just load is like,

756
00:31:27,339 --> 00:31:29,620
work that these
machines are doing.

757
00:31:29,620 --> 00:31:31,480
And I guess when you were
asked me a question,

758
00:31:31,480 --> 00:31:32,739
you were kind of
frame it as like,

759
00:31:32,739 --> 00:31:35,120
Well, you could
argue that there's

760
00:31:35,120 --> 00:31:37,799
more load if there's
more copies, right?

761
00:31:37,799 --> 00:31:39,980
But I guess I'm not quite
asking about total load.

762
00:31:39,980 --> 00:31:41,539
I'm asking about balance, right?

763
00:31:41,539 --> 00:31:43,619
So I'm asking how evenly is

764
00:31:43,619 --> 00:31:46,679
work shared across these
different dif machines, right?

765
00:31:46,679 --> 00:31:48,260
If everybody's doing
a similar amount

766
00:31:48,260 --> 00:31:49,499
of work, it's more balanced.

767
00:31:49,499 --> 00:31:51,159
If there's like one node

768
00:31:51,159 --> 00:31:51,979
that's doing all the work

769
00:31:51,979 --> 00:31:53,280
and all the other ones are idle,

770
00:31:53,280 --> 00:31:54,959
then it's imbalanced, right?

771
00:31:54,959 --> 00:31:56,959
And so what I

772
00:31:56,959 --> 00:31:58,779
was really interested in
here, I mean, I guess,

773
00:31:58,779 --> 00:32:01,870
like the When I'm
thinking about load,

774
00:32:01,870 --> 00:32:03,589
I think about like something's
actually executing.

775
00:32:03,589 --> 00:32:04,529
Not just that it's like

776
00:32:04,529 --> 00:32:05,629
sitting there in
the cache, right?

777
00:32:05,629 --> 00:32:07,729
I mean, we can talk
about like, you know,

778
00:32:07,729 --> 00:32:09,270
memory usage or storage band.

779
00:32:09,270 --> 00:32:10,249
So I'm thinking about load like,

780
00:32:10,249 --> 00:32:11,570
what's actually executing there?

781
00:32:11,570 --> 00:32:14,829
And when Spark tries to
execute on this data,

782
00:32:14,829 --> 00:32:17,130
Israel say, I have to
do some execution,

783
00:32:17,130 --> 00:32:18,590
and it's on this
partition of data,

784
00:32:18,590 --> 00:32:20,870
Israel look at all these
workers and say, well,

785
00:32:20,870 --> 00:32:23,569
that partition is on
this specific machine.

786
00:32:23,569 --> 00:32:24,870
It's not on other machines.

787
00:32:24,870 --> 00:32:26,609
And so then Spark will say,

788
00:32:26,609 --> 00:32:28,189
I can run it on this machine,

789
00:32:28,189 --> 00:32:29,680
and there's no network I owe.

790
00:32:29,680 --> 00:32:31,230
Or I run a different machine,

791
00:32:31,230 --> 00:32:33,329
I have to send that data
over the network, right?

792
00:32:33,329 --> 00:32:34,249
So Spark is always going

793
00:32:34,249 --> 00:32:35,609
to choose to run
it on the machine,

794
00:32:35,609 --> 00:32:37,669
where it doesn't have to
do network io, right?

795
00:32:37,669 --> 00:32:39,590
And so if there's only
one copy of the data,

796
00:32:39,590 --> 00:32:41,490
then whenever I do
computation on that data,

797
00:32:41,490 --> 00:32:44,129
it always goes to the
same machine every time.

798
00:32:44,129 --> 00:32:46,890
Even if that machine is
overloaded, if it's overloaded,

799
00:32:46,890 --> 00:32:48,529
the other ones are IDO, so
it keep sending it there,

800
00:32:48,529 --> 00:32:49,910
so it doesn't have
to do network io.

801
00:32:49,910 --> 00:32:53,289
If it has two different machines
where it has that data,

802
00:32:53,289 --> 00:32:54,629
then Spark can look at it.

803
00:32:54,629 --> 00:32:56,850
I can try to figure out
which machine is less busy,

804
00:32:56,850 --> 00:32:58,569
and it can run run it there.

805
00:32:58,569 --> 00:33:00,590
So it'll help Spark
balance the load a little

806
00:33:00,590 --> 00:33:02,729
bit better if we have
multiple copies,

807
00:33:02,729 --> 00:33:04,810
because we have more choices
about where we run things,

808
00:33:04,810 --> 00:33:06,970
and we will run things
so as to better

809
00:33:06,970 --> 00:33:09,560
balance the load. Yeah.
Excellent question.

810
00:33:09,560 --> 00:33:11,939
Yeah, other questions
people have.

811
00:33:13,500 --> 00:33:22,540
Yeah, right here. Spark
Streaming modes Oh, yeah.

812
00:33:23,740 --> 00:33:27,359
Excellent. Okay.
Spark Streaming,

813
00:33:27,359 --> 00:33:28,339
we have these three modes.

814
00:33:28,339 --> 00:33:31,920
There's a pen update
and complete.

815
00:33:31,920 --> 00:33:34,580
And with a pen,

816
00:33:34,580 --> 00:33:36,779
that means that as
I have new inputs,

817
00:33:36,779 --> 00:33:39,239
I produce more outputs,

818
00:33:39,239 --> 00:33:41,879
but I never change

819
00:33:41,879 --> 00:33:44,719
anything that I
previously said, right?

820
00:33:44,719 --> 00:33:47,420
So if I produce some
output with the Pen mood,

821
00:33:47,420 --> 00:33:49,439
that means it's final, I
can never change it, right?

822
00:33:49,439 --> 00:33:51,579
Because the Pen means that
I keep writing to the end,

823
00:33:51,579 --> 00:33:54,959
but leave the original
stuff intact, right?

824
00:33:54,959 --> 00:33:56,840
And so in a pen mood,

825
00:33:56,840 --> 00:33:58,899
there's some things
computations I

826
00:33:58,899 --> 00:34:01,019
can do and some that I cannot.

827
00:34:01,019 --> 00:34:02,640
So, for example, if I
have some data coming

828
00:34:02,640 --> 00:34:04,880
in and I'm just like
filtering it in some way,

829
00:34:04,880 --> 00:34:08,669
then any output I have
will never change, right?

830
00:34:08,669 --> 00:34:11,289
So a pen mode makes sense if
I'm just filtering or doing

831
00:34:11,289 --> 00:34:12,669
something like
that because while

832
00:34:12,669 --> 00:34:14,349
I have new rows coming in,

833
00:34:14,349 --> 00:34:15,769
I have some new rows coming out,

834
00:34:15,769 --> 00:34:18,489
that doesn't change what I've
already outputed, right?

835
00:34:18,489 --> 00:34:19,989
Now, there's some
things that just

836
00:34:19,989 --> 00:34:21,649
don't work with the pen mode,

837
00:34:21,649 --> 00:34:23,049
for example, if I'm

838
00:34:23,049 --> 00:34:25,089
doing like a group by
with a count, right?

839
00:34:25,089 --> 00:34:26,749
Because let's say I'm
counting animals and I

840
00:34:26,749 --> 00:34:29,729
say there are five sharks,
and I output that.

841
00:34:29,729 --> 00:34:31,449
That means I can never change

842
00:34:31,449 --> 00:34:33,149
that if I'm doing
a pen mode, right?

843
00:34:33,149 --> 00:34:35,009
So then if I see another shark,

844
00:34:35,009 --> 00:34:36,930
I can't say six sharks

845
00:34:36,930 --> 00:34:38,469
that contradict what
I said earlier.

846
00:34:38,469 --> 00:34:40,369
Pen mode means that once
you output something,

847
00:34:40,369 --> 00:34:42,389
that's final, right?
Because that's a pen mode.

848
00:34:42,389 --> 00:34:45,009
That's maybe the simplest one.

849
00:34:45,009 --> 00:34:48,789
The complete mode recognizes

850
00:34:48,789 --> 00:34:51,729
the fact that like
an output I had,

851
00:34:51,729 --> 00:34:53,030
when I say there five sharks,

852
00:34:53,030 --> 00:34:55,189
recognize that I
can change, right?

853
00:34:55,189 --> 00:34:57,029
So previously output rows.

854
00:34:57,029 --> 00:34:58,230
It's not that I just keep

855
00:34:58,230 --> 00:34:59,669
adding rows, but I
change things, right?

856
00:34:59,669 --> 00:35:01,289
That's complete.
So complete means

857
00:35:01,289 --> 00:35:03,549
that anytime I'm
producing output again,

858
00:35:03,549 --> 00:35:07,969
I'm going to produce my
incomplete results set, right?

859
00:35:07,969 --> 00:35:10,889
Even maybe if I
just saw a shark,

860
00:35:10,889 --> 00:35:12,489
I'm going I say, Okay,
there's six sharks,

861
00:35:12,489 --> 00:35:15,330
I also say there's three
dolphins before I output

862
00:35:15,330 --> 00:35:18,609
the whole thing
every time, right?

863
00:35:18,609 --> 00:35:21,189
And so that gets around
the problem with a pen.

864
00:35:21,189 --> 00:35:23,829
And in some cases it's
kind of reasonable, right?

865
00:35:23,829 --> 00:35:25,469
If the results set is small,

866
00:35:25,469 --> 00:35:29,429
it's fine to stump out the
whole thing every time, right?

867
00:35:29,429 --> 00:35:31,909
Now, sometimes it might
be inefficient, right?

868
00:35:31,909 --> 00:35:33,489
Like, I like let's say

869
00:35:33,489 --> 00:35:35,350
there's like a let's
say it wasn't animals,

870
00:35:35,350 --> 00:35:37,069
I was like, I don't know,
bacteria or whatever.

871
00:35:37,069 --> 00:35:39,490
And let's say there's like
100,000 different kinds.

872
00:35:39,490 --> 00:35:41,549
And then I'm outputting
all that again,

873
00:35:41,549 --> 00:35:43,430
just because I saw
like a new sample.

874
00:35:43,430 --> 00:35:45,129
That would be kind
of wasteful, right?

875
00:35:45,129 --> 00:35:48,839
And so the update
mode means that Hey,

876
00:35:48,839 --> 00:35:51,499
I can put a current count
out or whatever sat,

877
00:35:51,499 --> 00:35:53,439
and then later I can change what

878
00:35:53,439 --> 00:35:55,939
my previous stat was, right?

879
00:35:55,939 --> 00:35:58,159
I can modify it.

880
00:35:58,159 --> 00:36:00,340
Now, there's some systems

881
00:36:00,340 --> 00:36:01,580
that I can do that for
it and some I cannot.

882
00:36:01,580 --> 00:36:03,300
Like if I'm writing Parke files,

883
00:36:03,300 --> 00:36:04,880
Parke files are compressed,

884
00:36:04,880 --> 00:36:06,619
and we talked earlier
in the semester about,

885
00:36:06,619 --> 00:36:08,339
if you have some
compressed data,

886
00:36:08,339 --> 00:36:10,989
I can't row in and just
make a small change, right?

887
00:36:10,989 --> 00:36:12,989
Be compression is
based on kind of

888
00:36:12,989 --> 00:36:15,410
redundancy and kind of
not repeating patterns.

889
00:36:15,410 --> 00:36:17,149
And if maybe I kind
of broke that, right?

890
00:36:17,149 --> 00:36:19,870
So Park files, I can't just
throw updated in the middle.

891
00:36:19,870 --> 00:36:21,829
So the update mode,

892
00:36:21,829 --> 00:36:23,810
is not trying to work
with Park files.

893
00:36:23,810 --> 00:36:26,349
But if Spark Streaming was, say,

894
00:36:26,349 --> 00:36:28,010
updating some stuff in a MQL

895
00:36:28,010 --> 00:36:29,269
database or something like that,

896
00:36:29,269 --> 00:36:30,789
it is smart enough it can do

897
00:36:30,789 --> 00:36:33,709
a query that will update
the results there.

898
00:36:33,709 --> 00:36:35,229
That makes sense or Any of those

899
00:36:35,229 --> 00:36:37,070
you want to clarify
in more detail?

900
00:36:37,070 --> 00:36:41,089
Fina. Yeah, update would

901
00:36:41,089 --> 00:36:43,049
often be used for
aggregates, right?

902
00:36:43,049 --> 00:36:46,029
I think that that Complete and

903
00:36:46,029 --> 00:36:49,069
update are ones
that I would well,

904
00:36:49,069 --> 00:36:50,289
first off, I said there was like

905
00:36:50,289 --> 00:36:52,049
a problem with a Pen, right?

906
00:36:52,049 --> 00:36:56,890
And then complete and update
both solve that problem.

907
00:36:56,890 --> 00:36:59,170
Update is what I would usually

908
00:36:59,170 --> 00:37:02,210
prefer because it's just
inherently more efficient,

909
00:37:02,210 --> 00:37:03,989
except not every place

910
00:37:03,989 --> 00:37:05,529
I can write my data
supports it, right?

911
00:37:05,529 --> 00:37:08,030
Some places I can write
my data support update,

912
00:37:08,030 --> 00:37:09,429
and some do not.

913
00:37:09,429 --> 00:37:11,390
Right? So both
update and complete,

914
00:37:11,390 --> 00:37:14,080
solve the problem
with a Pen, Depending

915
00:37:14,080 --> 00:37:15,159
on where I'm writing to update

916
00:37:15,159 --> 00:37:16,259
may or may not be an option.

917
00:37:16,259 --> 00:37:18,060
I would probably prefer
it if it is an option.

918
00:37:18,060 --> 00:37:20,320
That makes sense? Yeah,
thanks for asking.

919
00:37:20,320 --> 00:37:22,919
Yeah, other questions
people have.

920
00:37:25,240 --> 00:37:28,079
Yeah, right over here.

921
00:37:29,840 --> 00:37:31,404
Question.

922
00:37:31,404 --> 00:37:34,229
Walking Oh, yeah.

923
00:37:34,229 --> 00:37:35,550
Does anybody have any particular

924
00:37:35,550 --> 00:37:36,769
numbers for walking the ring,

925
00:37:36,769 --> 00:37:38,229
or at least we could always

926
00:37:38,229 --> 00:37:40,689
make up an example, too, right?

927
00:37:43,450 --> 00:37:46,109
I'll just try to flip
through here and see.

928
00:37:46,109 --> 00:37:48,649
Is there anything with
walking the ring?

929
00:37:51,210 --> 00:37:54,149
I guess here we have a ring.

930
00:37:54,149 --> 00:37:57,289
Can you Can you what is that?

931
00:37:57,289 --> 00:38:01,530
Oh, B I'm on the Here's the dom.

932
00:38:04,250 --> 00:38:07,489
Yeah. Okay, here we have a ring.

933
00:38:07,489 --> 00:38:10,689
And then I have the
token map, right?

934
00:38:10,689 --> 00:38:14,689
So We eventually saw

935
00:38:14,689 --> 00:38:17,270
that we want to have a
single physical node,

936
00:38:17,270 --> 00:38:19,529
owning multiple
parts of the ring

937
00:38:19,529 --> 00:38:22,629
because then when
new nodes join,

938
00:38:22,629 --> 00:38:24,629
we can pass off, you know,

939
00:38:24,629 --> 00:38:26,749
the work at a finer
granularity, right?

940
00:38:26,749 --> 00:38:28,469
It's not that we have
to transfer as much.

941
00:38:28,469 --> 00:38:31,630
So here what I see is that
node one only has one V node.

942
00:38:31,630 --> 00:38:33,669
So it only owns one
range of the ring,

943
00:38:33,669 --> 00:38:36,589
and then node two and node
three have multiple v nodes.

944
00:38:36,589 --> 00:38:37,889
So the first thing
I might do is I m

945
00:38:37,889 --> 00:38:40,169
annotate this, right?
This is node one.

946
00:38:40,169 --> 00:38:50,579
And then node two is
here, and also here.

947
00:38:50,579 --> 00:38:57,879
Great. And then node three
is four and negative two.

948
00:38:58,560 --> 00:39:00,919
Yeah. Okay.

949
00:39:02,240 --> 00:39:04,459
Alright, great. And then

950
00:39:04,459 --> 00:39:05,960
we're assuming two
times replication.

951
00:39:05,960 --> 00:39:07,619
So which nodes are
responsible for

952
00:39:07,619 --> 00:39:10,559
Row token negative five,

953
00:39:10,559 --> 00:39:12,819
assuming the
following token map.

954
00:39:12,819 --> 00:39:14,679
So I'm gonna start at
negative five here,

955
00:39:14,679 --> 00:39:16,419
and then I start walking, right?

956
00:39:16,419 --> 00:39:18,479
And I'm going to walk until I

957
00:39:18,479 --> 00:39:21,159
get two different
physical nodes, right?

958
00:39:21,159 --> 00:39:23,339
I'm going to walk all
the way up until here.

959
00:39:23,339 --> 00:39:24,919
And so in this case,
I'm going to have

960
00:39:24,919 --> 00:39:27,399
node two and three.

961
00:39:27,399 --> 00:39:28,699
Right? So I'm trying
to think what

962
00:39:28,699 --> 00:39:30,019
we want to remember, right?

963
00:39:30,019 --> 00:39:31,439
So first, I draw

964
00:39:31,439 --> 00:39:34,179
a picture of where the V
nodes are on the token ring.

965
00:39:34,179 --> 00:39:37,959
And then Once you have your row,

966
00:39:37,959 --> 00:39:39,879
right, figure out where that
is on the token, right?

967
00:39:39,879 --> 00:39:42,399
Maybe I'll just tell you
what the token is or maybe

968
00:39:42,399 --> 00:39:43,499
you'll have to look
it up if I have

969
00:39:43,499 --> 00:39:45,219
some kind of table,
figure out where that is.

970
00:39:45,219 --> 00:39:48,139
And then, um When I
started that token ring,

971
00:39:48,139 --> 00:39:50,779
we have an exact match,
we include it, right?

972
00:39:50,779 --> 00:39:53,039
So it's inclusive, and then

973
00:39:53,039 --> 00:39:54,779
I keep walking to
the right until I

974
00:39:54,779 --> 00:39:58,299
get whatever replication
factor I want it, right?

975
00:39:58,299 --> 00:39:59,439
If it's two, then
I have to get two

976
00:39:59,439 --> 00:40:00,879
of them or however many.

977
00:40:00,879 --> 00:40:04,000
And then that's like
the main algorithm.

978
00:40:04,000 --> 00:40:07,239
And the only two tricky
things on that are

979
00:40:07,239 --> 00:40:10,859
that I might walk off the
end on the right hand side,

980
00:40:10,859 --> 00:40:12,839
and I just wrap around to
the left hand side again.

981
00:40:12,839 --> 00:40:14,459
That's why we call it
the wrapping range.

982
00:40:14,459 --> 00:40:15,419
That's why we call it a ring

983
00:40:15,419 --> 00:40:16,839
instead of a number line, right?

984
00:40:16,839 --> 00:40:18,560
That was one of
the tricky things.

985
00:40:18,560 --> 00:40:21,199
And then the other tricky
thing is that given

986
00:40:21,199 --> 00:40:24,249
these are V nodes, right?

987
00:40:24,249 --> 00:40:26,409
I'm trying to find V
nodes for my data,

988
00:40:26,409 --> 00:40:28,349
but I don't want to
have two V nodes on

989
00:40:28,349 --> 00:40:30,589
the same machine because
if that machine dies,

990
00:40:30,589 --> 00:40:32,509
then I lost both those replicas.

991
00:40:32,509 --> 00:40:33,949
There's not a lot of
benefits of having

992
00:40:33,949 --> 00:40:36,270
two copies of my data
on the same machine.

993
00:40:36,270 --> 00:40:37,989
So as we're walking the ring,

994
00:40:37,989 --> 00:40:40,949
sometimes we will
skip some V nodes,

995
00:40:40,949 --> 00:40:42,229
right? I'm trying
to find two, right?

996
00:40:42,229 --> 00:40:44,089
And if I don't like
the second one I find,

997
00:40:44,089 --> 00:40:45,329
I'll keep going and I'll

998
00:40:45,329 --> 00:40:46,989
consider it maybe like
the third one, right?

999
00:40:46,989 --> 00:40:48,249
And so the simple case,

1000
00:40:48,249 --> 00:40:49,750
like all they do is they skip

1001
00:40:49,750 --> 00:40:51,810
multiple V nodes on
the same machine.

1002
00:40:51,810 --> 00:40:53,850
You could plug in more
complicated policies

1003
00:40:53,850 --> 00:40:55,569
where they might say, Hey,

1004
00:40:55,569 --> 00:40:59,830
I'm worried about like a
whole zone in the cloud.

1005
00:40:59,830 --> 00:41:01,389
Failing, right?
Because those things

1006
00:41:01,389 --> 00:41:02,549
share not working in power.

1007
00:41:02,549 --> 00:41:03,289
And so you can have

1008
00:41:03,289 --> 00:41:04,649
more complicated
policies where I say,

1009
00:41:04,649 --> 00:41:05,949
Oh, I have this V node.

1010
00:41:05,949 --> 00:41:07,449
The next V node is
in the same zone.

1011
00:41:07,449 --> 00:41:08,549
Som skip it, right?

1012
00:41:08,549 --> 00:41:11,989
So skipping policies that
you can plug in help you

1013
00:41:11,989 --> 00:41:13,609
avoid having multiple copies of

1014
00:41:13,609 --> 00:41:16,389
your data in the same
fault domains, right?

1015
00:41:16,389 --> 00:41:20,450
A domain is some collection

1016
00:41:20,450 --> 00:41:22,209
of machines or
places where things

1017
00:41:22,209 --> 00:41:24,749
could fail together because
they share something.

1018
00:41:24,749 --> 00:41:26,189
And then, you know,

1019
00:41:26,189 --> 00:41:28,229
the fault is just anything
that can go wrong, right?

1020
00:41:28,229 --> 00:41:30,269
Like machine dying or power

1021
00:41:30,269 --> 00:41:33,249
going out to a data center or
a tornado, anything, right?

1022
00:41:33,249 --> 00:41:35,889
Does that answer the question
about walking the ring?

1023
00:41:35,889 --> 00:41:37,349
Yes.

1024
00:41:42,160 --> 00:41:44,479
What's that?

1025
00:41:45,600 --> 00:41:51,140
Two age Exactly.

1026
00:41:51,140 --> 00:41:52,479
If I hit in two twice,

1027
00:41:52,479 --> 00:41:53,999
I would skip the
second one and keep

1028
00:41:53,999 --> 00:41:55,959
going until I find
something else.

1029
00:41:55,959 --> 00:41:59,439
Yeah, exactly. Yeah.
And then I guess,

1030
00:42:00,680 --> 00:42:03,700
Like after we identify
these replicas,

1031
00:42:03,700 --> 00:42:05,559
remind me like,
what happens next?

1032
00:42:05,559 --> 00:42:07,099
Like if I'm reading
or writing data,

1033
00:42:07,099 --> 00:42:08,619
what was the other big piece

1034
00:42:08,619 --> 00:42:10,959
of Cassandra that
we learned about?

1035
00:42:16,220 --> 00:42:19,559
Oh, yes, that was
what I had in mind,

1036
00:42:19,559 --> 00:42:21,339
but that's another big
piece of the costs, right?

1037
00:42:21,339 --> 00:42:22,980
So, all the nodes

1038
00:42:22,980 --> 00:42:25,079
need to know what the other
nodes are in the ring.

1039
00:42:25,079 --> 00:42:26,939
And so they do that
with the cos up, right,

1040
00:42:26,939 --> 00:42:28,859
because since they all have

1041
00:42:28,859 --> 00:42:32,979
that token map right that
tells us which nodes are wear,

1042
00:42:32,979 --> 00:42:35,419
we need to keep it in
sync on all of them,

1043
00:42:35,419 --> 00:42:37,319
but there could be some
machines down, right?

1044
00:42:37,319 --> 00:42:39,140
If the machine is down,
I add a new machine.

1045
00:42:39,140 --> 00:42:41,140
I don't want to have to
wait until all the machines

1046
00:42:41,140 --> 00:42:42,579
are up to add the new machine.

1047
00:42:42,579 --> 00:42:44,220
It's like gossip each
other. So quickly,

1048
00:42:44,220 --> 00:42:45,919
all have the same view
of the token map.

1049
00:42:45,919 --> 00:42:47,479
That was another
component, right?

1050
00:42:47,479 --> 00:42:48,859
And then we're kind of going

1051
00:42:48,859 --> 00:42:50,759
back to this though.
So we walk the ring.

1052
00:42:50,759 --> 00:42:52,619
And then let's say
they find like

1053
00:42:52,619 --> 00:42:55,820
the two or three or however
many nodes are involved.

1054
00:42:55,900 --> 00:43:00,639
What would we do if we want
to write data to those?

1055
00:43:00,639 --> 00:43:04,019
How will we determine if
that's successful or not?

1056
00:43:06,780 --> 00:43:11,259
So I guess here, we identified
nodes two and three.

1057
00:43:11,259 --> 00:43:12,859
I'm trying to write some data.

1058
00:43:12,859 --> 00:43:14,379
I'm trying to write
some row there.

1059
00:43:14,379 --> 00:43:15,899
How will I decide if my right

1060
00:43:15,899 --> 00:43:18,299
to those was successful or not?

1061
00:43:20,660 --> 00:43:22,859
Yeah, we have to have Xs, right?

1062
00:43:22,859 --> 00:43:24,880
So if I get an ac, that
means it was successful,

1063
00:43:24,880 --> 00:43:26,819
or maybe I don't
get an C, right?

1064
00:43:26,819 --> 00:43:29,739
And if the system is not
available at the moment,

1065
00:43:29,739 --> 00:43:31,499
I might not get an C. And so

1066
00:43:31,499 --> 00:43:33,719
there are ways we can t
to tune the availability.

1067
00:43:33,719 --> 00:43:35,119
Does you remember
what are some of

1068
00:43:35,119 --> 00:43:37,780
the variables involved
in that process?

1069
00:43:42,430 --> 00:43:44,869
So what I'm thinking of is like

1070
00:43:44,869 --> 00:43:47,669
the read and write
quorums, right?

1071
00:43:47,669 --> 00:43:50,469
So that's not talking
about it here,

1072
00:43:50,469 --> 00:43:52,770
but another component
of the system.

1073
00:43:52,770 --> 00:43:55,089
We know that the
replication factor here,

1074
00:43:55,089 --> 00:43:58,529
the replication factor
was two, right?

1075
00:43:58,529 --> 00:43:59,369
And then there might be

1076
00:43:59,369 --> 00:44:01,169
someil details that are
not part of this problem.

1077
00:44:01,169 --> 00:44:03,789
What is the how many
do I have to write to

1078
00:44:03,789 --> 00:44:06,869
to consider a success and how
many do I have to read to?

1079
00:44:06,869 --> 00:44:09,749
If this W is two,

1080
00:44:09,749 --> 00:44:11,389
and the replication
factor is two,

1081
00:44:11,389 --> 00:44:13,049
that means I can't
write unless all of

1082
00:44:13,049 --> 00:44:15,830
the nodes are currently working.

1083
00:44:15,830 --> 00:44:18,250
So let's imagine this
was one, for example.

1084
00:44:18,250 --> 00:44:19,709
In that case, I'm
going to try to

1085
00:44:19,709 --> 00:44:21,789
write two node two
and node three.

1086
00:44:21,789 --> 00:44:23,929
But as long as it works
on at least one of them,

1087
00:44:23,929 --> 00:44:25,049
I'm going to say, Hey,

1088
00:44:25,049 --> 00:44:26,770
it worked your right
was successful.

1089
00:44:26,770 --> 00:44:29,469
So that's something
you could tune, right?

1090
00:44:29,469 --> 00:44:31,969
And then what would
I set R two here?

1091
00:44:31,969 --> 00:44:33,490
If I want to make
sure that anybody

1092
00:44:33,490 --> 00:44:35,564
reading will see that right.

1093
00:44:35,564 --> 00:44:38,539
Excellent, right? And
so the formula that

1094
00:44:38,539 --> 00:44:41,439
we can remember is
that we usually want.

1095
00:44:41,439 --> 00:44:44,019
And this is usually because
maybe you have some game

1096
00:44:44,019 --> 00:44:44,719
or something where you

1097
00:44:44,719 --> 00:44:46,959
want availability
over consistently,

1098
00:44:46,959 --> 00:44:55,039
C. Usually want R plus W
greater than R F, right?

1099
00:44:55,039 --> 00:45:00,340
Greater than R F.
So for example,

1100
00:45:00,340 --> 00:45:01,759
let's say I have these
two nodes, right?

1101
00:45:01,759 --> 00:45:03,219
I guess it was in this case,

1102
00:45:03,219 --> 00:45:07,539
it's like node two
and node three.

1103
00:45:07,900 --> 00:45:10,959
If I'm writing and I just
write to one of them,

1104
00:45:10,959 --> 00:45:13,279
I say, Okay, well,
that was good, right?

1105
00:45:13,279 --> 00:45:15,799
Write equals one. And
then when I read,

1106
00:45:15,799 --> 00:45:17,099
if I only read from one, I

1107
00:45:17,099 --> 00:45:18,359
might read the
wrong data, right?

1108
00:45:18,359 --> 00:45:22,899
So if I do this, then I
could have read equals two.

1109
00:45:23,090 --> 00:45:26,270
Right? So that was those
were of the main pieces,

1110
00:45:26,270 --> 00:45:28,069
like, you need to know
how to walk the ring.

1111
00:45:28,069 --> 00:45:30,790
And then when we walk
the ring to identify

1112
00:45:30,790 --> 00:45:34,050
some number of nodes that
are part of the operation.

1113
00:45:34,050 --> 00:45:35,470
And then you need to understand,

1114
00:45:35,470 --> 00:45:37,910
well, how to read
and write quorums,

1115
00:45:37,910 --> 00:45:40,809
determine whether or not it

1116
00:45:40,809 --> 00:45:42,150
was successful or determine

1117
00:45:42,150 --> 00:45:43,829
where the data gets
read or read in.

1118
00:45:43,829 --> 00:45:45,789
Right? There's a couple
of big pieces there.

1119
00:45:45,789 --> 00:45:46,989
You can td break down

1120
00:45:46,989 --> 00:45:48,669
and have these skills
independently.

1121
00:45:48,669 --> 00:45:51,009
Yeah, there are
questions people have.

1122
00:45:51,250 --> 00:45:53,769
Yeah, right here.

1123
00:45:56,220 --> 00:45:59,799
You said question
was 16 on this one.

1124
00:45:59,799 --> 00:46:02,699
Was this this right here?

1125
00:46:02,699 --> 00:46:05,459
Oh, the final review.

1126
00:46:05,459 --> 00:46:08,299
Oh, that was, like,
a PDF, right?

1127
00:46:08,299 --> 00:46:10,139
Okay, yeah, sure. I
can pull that up.

1128
00:46:10,139 --> 00:46:11,899
Yeah, the first semester
I ever talked this.

1129
00:46:11,899 --> 00:46:14,499
I didn't have any old
old exams, right?

1130
00:46:14,499 --> 00:46:16,979
So I created this
final review document,

1131
00:46:16,979 --> 00:46:21,739
which is S 23 final
review. Okay, great.

1132
00:46:21,739 --> 00:46:25,339
And you said et
Question 16, right?

1133
00:46:27,840 --> 00:46:31,359
All right. Great. So
then you can all see it.

1134
00:46:31,359 --> 00:46:34,859
Okay, so replication
factor is five for Kafka.

1135
00:46:34,859 --> 00:46:37,559
So we have RF for
kafka and Cassandra.

1136
00:46:37,559 --> 00:46:40,599
And the minimum number of
sync replicas is three.

1137
00:46:40,599 --> 00:46:42,299
And there are currently four

1138
00:46:42,299 --> 00:46:44,240
sync replicas with one lagging.

1139
00:46:44,240 --> 00:46:48,519
Okay, great. A message is
read in to three replicas.

1140
00:46:48,519 --> 00:46:51,779
So the leader and two
of the followers,

1141
00:46:51,779 --> 00:46:54,279
and is it committed?

1142
00:46:54,279 --> 00:46:57,019
And the answer is no.

1143
00:46:57,019 --> 00:46:59,719
It's not committed 'cause
our data is not safe.

1144
00:46:59,719 --> 00:47:03,399
Can somebody tell me what
is something bad that could

1145
00:47:03,399 --> 00:47:08,489
happen where I could lose
this data? Right here.

1146
00:47:08,489 --> 00:47:11,279
The ser breaks down

1147
00:47:11,279 --> 00:47:17,659
the head 46 replica
that doesn't have that.

1148
00:47:18,130 --> 00:47:20,709
Excellent. So I'll
just repeat that.

1149
00:47:20,709 --> 00:47:22,409
So if the leader breaks down,

1150
00:47:22,409 --> 00:47:24,849
and then the fourth
encyc replica

1151
00:47:24,849 --> 00:47:26,929
that doesn't have the
message that is elected,

1152
00:47:26,929 --> 00:47:28,849
it's lost, right? So the
data is not committed.

1153
00:47:28,849 --> 00:47:31,269
We can't say it's committed yet.

1154
00:47:31,269 --> 00:47:32,749
So at this point in time, at

1155
00:47:32,749 --> 00:47:34,330
this moment in time
it's not committed,

1156
00:47:34,330 --> 00:47:35,749
now, as time goes forward,

1157
00:47:35,749 --> 00:47:37,849
there's two things that
could happen, right?

1158
00:47:37,849 --> 00:47:41,229
One is that and I
guess the good case

1159
00:47:41,229 --> 00:47:42,929
is that the fourth nyc replica

1160
00:47:42,929 --> 00:47:44,369
will get a copy of that data,

1161
00:47:44,369 --> 00:47:46,069
and then it's safe, right?

1162
00:47:46,069 --> 00:47:47,729
And then we'll say
it's committed.

1163
00:47:47,729 --> 00:47:48,909
That might take some time.

1164
00:47:48,909 --> 00:47:52,545
The other thing is that
this encyc replica

1165
00:47:52,545 --> 00:47:56,759
is maybe in the process of
becoming like, not in sync.

1166
00:47:56,759 --> 00:47:58,720
Maybe it's starting
to lag behind.

1167
00:47:58,720 --> 00:48:00,839
So if we wait a while,

1168
00:48:00,839 --> 00:48:02,539
the producer is not going to

1169
00:48:02,539 --> 00:48:03,639
have to wait forever
for the act.

1170
00:48:03,639 --> 00:48:05,219
Because eventually, the
leader is going to say,

1171
00:48:05,219 --> 00:48:06,399
Well, this one was in sync,

1172
00:48:06,399 --> 00:48:07,719
but I'm going to
write out it's not

1173
00:48:07,719 --> 00:48:09,459
in sync anymore. Lagging behind.

1174
00:48:09,459 --> 00:48:11,619
At that point we can
say, Okay, well,

1175
00:48:11,619 --> 00:48:14,960
I eliminated it as a candidate
for future leadership,

1176
00:48:14,960 --> 00:48:17,759
and now our data is on all the
candidates for leadership.

1177
00:48:17,759 --> 00:48:19,839
Let's call it Clo Dred.

1178
00:48:19,839 --> 00:48:20,939
Yeah, great question.

1179
00:48:20,939 --> 00:48:22,259
Yeah, all the
questions people have.

1180
00:48:22,259 --> 00:48:23,839
Yeah, right here.

1181
00:48:32,130 --> 00:48:35,529
Yeah. Yeah, in this case,

1182
00:48:35,529 --> 00:48:36,589
let's say that this
one that was in

1183
00:48:36,589 --> 00:48:37,930
sync keeps lagging behind.

1184
00:48:37,930 --> 00:48:39,809
So then the leader will say,

1185
00:48:39,809 --> 00:48:41,990
Okay, it's not in sync anymore.

1186
00:48:41,990 --> 00:48:44,449
And then at this
point, we see, well,

1187
00:48:44,449 --> 00:48:49,139
there are three the men
sync replicas is three.

1188
00:48:49,139 --> 00:48:51,099
And so we're say Okay,
good enough, right?

1189
00:48:51,099 --> 00:48:53,059
Now there's only three,
and they all have it.

1190
00:48:53,059 --> 00:48:54,919
We're gonna call it
Dread. Like, what if

1191
00:48:54,919 --> 00:48:57,379
men in sync replicas was four?

1192
00:48:57,379 --> 00:49:01,119
If it was four and we
lost that follower,

1193
00:49:01,119 --> 00:49:02,199
then we would actually go back

1194
00:49:02,199 --> 00:49:03,339
to the producer and say, Hey,

1195
00:49:03,339 --> 00:49:05,939
we're having trouble keeping
up. I don't have enough.

1196
00:49:05,939 --> 00:49:07,079
Followers keeping
up, but we would

1197
00:49:07,079 --> 00:49:08,479
just like reject it, right?

1198
00:49:08,479 --> 00:49:09,859
So it's not that like

1199
00:49:09,859 --> 00:49:11,259
waiting infinitely
for an act to say,

1200
00:49:11,259 --> 00:49:13,939
Hey, like, I can't you're
sending me too many rights.

1201
00:49:13,939 --> 00:49:15,319
My followers can't keep up with

1202
00:49:15,319 --> 00:49:18,499
all the rights you're sending
me. That makes sense?

1203
00:49:18,989 --> 00:49:21,070
All right, Awesome questions,

1204
00:49:21,070 --> 00:49:22,509
everybody else people
are trying to pack up.

1205
00:49:22,509 --> 00:49:24,289
So just feel Pred up
and chat if you have

1206
00:49:24,289 --> 00:49:27,550
have more questions and
dad luck on Friday.
